pdf_text
"Journal of Arti cial In telligence Researc h Submitted published Bac ktrac kingMatthew L . Ginsb erg ginsber g University of Or e gon ,Eugene , OR USAAbstractBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree , existingbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc hproblem . In this pap er , w e presen t a metho d b y whic h bac ktrac k p oin ts can b e mo v eddeep er in the searc h space , thereb y a v oiding this di cult y . The tec hnique dev elop ed isa v arian t of dep endency direc ted bac ktrac king that uses only p olynomial space while stillpro viding useful con trol information and retaining the completeness guaran tees pro videdb y earlier approac hes . . In tro ductionImagine that y ou are trying to solv e some constrain t satisfaction problem , or csp . In thein terests of de niteness , I will supp ose that the csp in question in v olv es coloring a map ofthe United States sub ject to the restriction that adjacen t states b e colored di eren tly .Imagine w e b egin b y coloring the states along the Mississippi , thereb y splitting theremaining problem in t w o . W e no w b egin to color the states in the w estern half of thecoun try , coloring p erhaps half a dozen of them b efore deciding that w e are lik ely to b e ableto color the rest . Supp ose also that the last state colored w as Arizona .A t this p oin t , w e c hange our fo cus to the eastern half of the coun try . After all , if w e can tcolor the eastern half b ecause of our coloring c hoices for the states along the Mississippi ,there is no p oin t in w asting time completing the coloring of the w estern states .W e successfully color the eastern states and then return to the w est . Unfortunately , w ecolor New Mexico and Utah and then get stuc k , unable to color sa y Nev ada . What s more ,bac ktrac king do esn t help , at least in the sense that c hanging the colors for New Mexicoand Utah alone do es not allo w us to pro ceed farther . Depth rst searc h w ould no w ha v eus bac ktrac k to the eastern states , trying a new color for sa y New Y ork in the v ain hop ethat this w ould solv e our problems out W est .This is ob viously p oin tless the blo c k ade along the Mississippi mak es it imp ossible forNew Y ork to ha v e an y impact on our attempt to color Nev ada or other w estern states .What s more , w e are lik ely to examine ev ery p ossible coloring of the eastern states b eforeaddressing the problem that is actually the source of our di culties .The solutions that ha v e b een prop osed to this in v olv e nding w a ys to bac ktrac k directlyto some state that migh t actually allo w us to mak e progress , in this case Arizona or earlier .Dep endency directed bac ktrac king Stallman Sussman , in v olv es a direct bac ktrac kto the source of the di cult y bac kjumping Gasc hnig , a v oids the computational o v er head of this tec hnique b y using syn tactic metho ds to estimate the p oin t to whic h bac ktrac kis necessary .c AI Access F oundation and Morgan Kaufmann Publishers . All righ ts reserv ed .Ginsber gIn b oth cases , ho w ev er , note that although w e bac ktrac k to the source of the problem ,w e bac ktrac k over our successful solution to half of the original problem , discarding oursolution to the problem of coloring the states in the East . And once again , the problem isw orse than this after w e recolor Arizona , w e are in danger of solving the East y et againb efore realizing that our new c hoice for Arizona needs to b e c hanged after all . W e w on texamine ev ery p ossible coloring of the eastern states , but w e are in danger of redisco v eringour successful coloring an exp onen tial n um b er of times .This hardly seems sensible a h uman problem solv er w orking on this problem w ouldsimply ignore the East if p ossible , returning directly to Arizona and pro ceeding . Only if thestates along the Mississippi needed new colors w ould the East b e reconsidered and ev enthen only if no new coloring could b e found for the Mississippi that w as consisten t with theeastern solution .In this pap er w e formalize this tec hnique , presen ting a mo di cation to con v en tionalsearc h tec hniques that is capable of bac ktrac king not only to the most recen tly expandedno de , but also directly to a no de elsewhere in the searc h tree . Because of the dynamic w a yin whic h the searc h is structured , w e refer to this tec hnique as dynamic b acktr acking .A more sp eci c outline is as follo ws W e b egin in the next section b y in tro ducing av ariet y of notational con v en tions that allo w us to cast b oth existing w ork and our newideas in a uniform computational setting . Section discusses bac kjumping , an in termediateb et w een simple c hronological bac ktrac king and our ideas , whic h are themselv es presen tedin Section . An example of the dynamic bac ktrac king algorithm in use app ears in Section and an exp erimen tal analysis of the tec hnique in Section . A summary of our results andsuggestions for future w ork are in Section . All pro ofs ha v e b een deferred to an app endixin the in terests of con tin uit y of exp osition . . PreliminariesDe nition . By a constrain t satisfaction problem I V we wil l me an a set I of vari ables for e ach i I , ther e is a set Vi of p ossible values for the variable i . is a set ofc onstr aints , e ach a p air J P wher e J j . . . jk is an or der e d subset of I and P is asubset of Vj Vjk .A solution to the csp is a set vi of values for e ach of the variables in I such that vi Vifor e ach i and for every c onstr aint J P of the ab ove form in , vj . . . vjk P .In the example of the in tro duction , I is the set of states and Vi is the set of p ossiblecolors for the state i . F or eac h constrain t , the rst part of the constrain t is a pair of adjacen tstates and the second part is a set of allo w able color com binations for these states .Our basic plan in this pap er is to presen t formal v ersions of the searc h algorithmsdescrib ed in the in tro duction , b eginning with simple depth rst searc h and pro ceeding tobac kjumping and dynamic bac ktrac king . As a start , w e mak e the follo wing de nition of apartial solution to a csp De nition . L et I V b e a csp . By a partial solution to the csp we me an an or der e dsubset J I and an assignment of a value to e ach variable in J . ynamic Ba cktra ckingWe wil l denote a p artial solution by a tuple of or der e d p airs , wher e e ach or der e d p air i v assigns the value v to the variable i . F or a p artial solution P , we wil l denote by P theset of variables assigne d values by P .Constrain t satisfa ction problems are solv ed in practice b y taking partial solutions andextending them b y assigning v alues to new v ariables . In general , of course , not an y v alue canb e assigned to a v ariable b ecause some are inconsisten t with the constrain ts . W e thereforemak e the follo wing de nition De nition . Given a p artial solution P to a csp , an eliminating explanation for avariable i is a p air v S wher e v Vi and S P . The intende d me aning is that ic annot take the value v b e c ause of the values alr e ady assigne d by P to the variables in S .A n elimination mec hanism for a csp is a function that ac c epts as ar guments a p artialsolution P , and a variable i P . The function r eturns a p ossibly empty set P i ofeliminating explanations for i .F or a set E of eliminating explanations , w e will denote b y bE the v alues that ha v e b eeniden ti ed as eliminated , ignoring the reasons giv en . W e therefore denote b y b P i the setof v alues eliminated b y elemen ts of P i .Note that the ab o v e de nition is somewhat exible with regard to the amoun t of w orkdone b y the elimination mec hanism all v alues that violate completed constrain ts migh tb e eliminated , or some amoun t of lo ok ahead migh t b e done . W e will , ho w ev er , mak e thefollo wing assumptions ab out all elimination mec hanisms . They are c orr e ct . F or a partial solution P , if the v alue vi b P i , then ev eryconstrain t S T in with S P f i g is satis ed b y the v alues in the partial solutionand the v alue vi for i . These are the constrain ts that are complete after the v alue viis assigned to i . . They are c omplete . Supp ose that P is a partial solution to a csp , and there is somesolution that extends P while assigning the v alue v to i . If P an extension of Pwith v E P i , thenE P BnZr P In other w ords , whenev er P can b e successfully extended after assigning v to i butP b e , at least one elemen t of P BnZr P is iden ti ed as a p ossible reason for theproblem . . They are c oncise . F or a partial solution P , v ariable i and eliminated v alue v , thereis at most a single elemen t of the form v E P i . Only one reason is giv en wh ythe v ariable i cannot ha v e the v alue v .Lemma . L et b e a c omplete elimination me chanism for a csp , let P b e a p artial solu tion to this csp and let i P . Now if P c an b e suc c essful ly extende d to a c omplete solutionafter assigning i the value v , then v b P i .I ap ologize for the sw arm of de nitions , but they allo w us to giv e a clean description ofdepth rst searc h gAlgorithm . Depth rst searc h Given as inputs a c onstr aint satisfaction pr oblemand an elimination me chanism . Set P . P is a p artial solution to the csp . Set Ei for e ach i I Ei is theset of values that have b e en eliminate d for the variable i . . If P I , so that P assigns a value to every element in I , it is a solution to theoriginal pr oblem . R eturn it . Otherwise , sele ct a variable i I BnZr P . Set Ei b P i ,the values that have b e en eliminate d as p ossible choic es for i . . Set S Vi BnZr Ei , the set of r emaining p ossibilities for i . If S is nonempty , cho ose anelement v S . A dd i v to P , ther eby setting i s value to v , and r eturn to step . . If S is empty , let j vj b e the last entry in P if ther e is no such entry , r eturn failur e .R emove j vj fr om P , add vj to Ej , set i j and r eturn to step .W e ha v e written the algorithm so that it returns a single answ er to the csp the mo di cation to accum ulate all suc h answ ers is straigh tforw ar d .The problem with Algorithm . is that it lo oks v ery little lik e con v en tional depth rstsearc h , since instead of recording the unexpanded c hildren of an y particular no de , w e arek eeping trac k of the faile d siblings of that no de . But w e ha v e the follo wing Lemma . A t any p oint in the exe cution of A lgorithm . , if the last element of the p artialsolution P assigns a value to the variable i , then the unexplor e d siblings of the curr ent no dear e those that assign to i the values in Vi BnZr Ei .Prop osition . A lgorithm . is e quivalent to depth rst se ar ch and ther efor e c omplete .As w e ha v e remark ed , the basic di erence b et w een Algorithm . and a more con v en tional description of depth rst searc h is the inclusion of the eliminatio n sets Ei . Thecon v en tional description exp ects no des to include p oin ters bac k to their paren ts the sib lings of a giv en no de are found b y examining the c hildren of that no de s paren t . Since w ewill b e reorganizing the space as w e searc h , this is impractical in our framew ork .It migh t seem that a more natural solution to this di cult y w ould b e to record not thev alues that ha v e b een eliminate d for a v ariable i , but those that remain to b e considered .The tec hnical reason that w e ha v e not done this is that it is m uc h easier to main tainelimination information as the searc h progresses . T o understand this at an in tuitiv e lev el ,note that when the searc h bac ktrac ks , the conclusion that has implicitly b een dra wn isthat a particular no de fails to expand to a solution , as opp osed to a conclusion ab out thecurren tly unexplored p ortion of the searc h space . It should b e little surprise that the moste cien t w a y to manipulate this information is b y recording it in appro ximately this form . . Bac kjumpingHo w are w e to describ e dep endency directed bac ktrac king or bac kjumping in this setting ?In these cases , w e ha v e a partial solution and ha v e b een forced to bac ktrac k these moresophisticated bac ktrac king mec hanisms use information ab out the r e ason for the failure toiden tify bac ktrac k p oin ts that migh t allo w the problem to b e addressed . As a start , w e needto mo dify Algorithm . to main tain the explanations for the eliminated v alues ynamic Ba cktra ckingAlgorithm . Given as inputs a c onstr aint satisfaction pr oblem and an elimination me ch anism . Set P Ei for e ach i I . Ei is a set of eliminating explanations for i . . If P I , r eturn P . Otherwise , sele ct a variable i I BnZr P . Set Ei P i . Set S Vi BnZr bEi . If S is nonempty , cho ose an element v S . A dd i v to P andr eturn to step . . If S is empty , let j vj b e the last entry in P if ther e is no such entry , r eturn failur e .R emove j vj fr om P . We must have bEi Vi , so that every value for i has b e eneliminate d let E b e the set of al l variables app e aring in the explanations for e acheliminate d value . A dd vj E BnZr f j g to Ej , set i j and r eturn to step .Lemma . L et P b e a p artial solution obtaine d during the exe cution of A lgorithm . ,and let i P b e a variable assigne d a value by P . Now if P P c an b e suc c essful lyextende d to a c omplete solution after assigning i the value v but v E Ei , we must haveE P BnZr P In other w ords , the assignmen t of a v alue to some v ariable in P BnZr P correctly iden ti edas the source of the problem .Note that in step of the algorithm , w e could ha v e added vj E P instead of vj E BnZrf j g to Ej either w a y , the idea is to remo v e from E an y v ariables that are no longer assignedv alues b y P .In bac kjumping , w e no w simply c hange our bac ktrac k metho d instead of remo ving asingle en try from P and returning to the v ariable assigned a v alue prior to the problematicv ariable i , w e return to a v ariable that has actually had an impact on i . In other w ords , w ereturn to some v ariable in the set E .Algorithm . Bac kjumping Given as inputs a c onstr aint satisfaction pr oblem and anelimination me chanism . Set P Ei for e ach i I . . If P I , r eturn P . Otherwise , sele ct a variable i I BnZr P . Set Ei P i . Set S Vi BnZr bEi . If S is nonempty , cho ose an element v S . A dd i v to P andr eturn to step . . If S is empty , we must have bEi Vi . L et E b e the set of al l variables app e aring inthe explanations for e ach eliminate d value . . If E , r eturn failur e . Otherwise , let j vj b e the last entry in P such that j E .R emove fr om P this entry and any entry fol lowing it . A dd vj E P to Ej , set i jand r eturn to step . gIn step , w e add vj E P to Ej , remo ving from E an y v ariables that are no longerassigned v alues b y P .Prop osition . Backjumping is c omplete and always exp ands fewer no des than do es depth rst se ar ch .Let us ha v e a lo ok at this in our map coloring example . If w e ha v e a partial coloringP and are lo oking at a sp eci c state i , supp ose that w e denote b y C the set of colors thatare ob viously illegal for i b ecause they con ict with a color already assigned to one of i sneigh b ors .One p ossible elimination mec hanism returns as P i a list of c P for eac h colorc C that has b een used to color a neigh b or of i . This repro duces depth rst searc h , sincew e gradually try all p ossible colors but ha v e no idea what w en t wrong when w e need tobac ktrac k since ev ery colored state is included in P . A far more sensible c hoice w ould tak e P i to b e a list of c f n g where n is a neigh b or that is already colored c . This w ouldensure that w e bac kjump to a neigh b or of i if no coloring for i can b e found .If this causes us to bac kjump to another state j , w e will add i s neigh b ors to the elim inating explanation for j s original color , so that if w e need to bac ktrac k still further , w econsider neigh b ors of either i or j . This is as it should b e , since c hanging the color of one ofi s other neigh b ors migh t allo w us to solv e the coloring problem b y rev erting to our originalc hoice of color for the state j .W e also ha v e Prop osition . The amount of sp ac e ne e de d by b ackjumping is o i , wher e i j I j isthe numb er of variables in the pr oblem and v is the numb er of values for that variable withthe lar gest value set Vi .This result con trasts sharply with an approac h to csp s that relies on truth main tenancetec hniques to main tain a list of nogo o ds de Kleer , . There , the n um b er of nogo o dsfound can gro w linearly with the time tak en for the analysis , and this will t ypically b eexp onen tial in the size of the problem . Bac kjumping a v oids this problem b y resetting theset Ei of eliminating explanations in step of Algorithm . .The description that w e ha v e giv en is quite similar to that dev elop ed in Bruyno oghe , . The explanations there are somewhat coarser than ours , listing all of the v ariablesthat ha v e b een in v olv ed in any eliminating explanation for a particular v ariable in the csp ,but the idea is essen tially the same . Bruyno oghe s eliminating explanations can b e storedin o i space instead of o i , but the asso ciated loss of information mak es the tec hniqueless e ectiv e in practice . This earlier w ork is also a description of bac kjumping only , sincein termediate information is erased as the searc h pro ceeds . . Dynamic bac ktrac kingW e nally turn to new results . The basic problem with Algorithm . is not that it bac k jumps to the wrong place , but that it needlessly erases a great deal of the w ork that hasb een done th us far . A t the v ery least , w e can retain the v alues selected for v ariables thatare bac kjump ed o v er , in some sense mo ving the bac kjump v ariable to the end of the partial ynamic Ba cktra ckingsolution in order to replace its v alue without mo difying the v alues of the v ariables thatfollo w ed it .There is an additional mo di cation that will probably b e clearest if w e return to theexample of the in tro duction . Supp ose that in this example , w e color only some of the easternstates b efore returning to the w estern half of the coun try . W e reorder the v ariables in orderto bac ktrac k to Arizona and ev en tually succeed in coloring the W est without disturbing thecolors used in the East .Unfortunately , when w e return East bac ktrac king is required and w e nd ourselv esneeding to c hange the coloring on some of the eastern states with whic h w e dealt earlier .The ideas that w e ha v e presen ted will allo w us to a v oid erasing our solution to the problemsout W est , but if the searc h through the eastern states is to b e e cien t , w e will need toretain the information w e ha v e ab out the p ortion of the East s searc h space that has b eeneliminated . After all , if w e ha v e determined that New Y ork cannot b e colored y ello w , ourc hanges in the W est will not rev erse this conclusion the Mississippi really do es isolate onesection of the coun try from the other .The mac hinery needed to capture this sort of reasoning is already in place . When w ebac kjump o v er a v ariable k , w e should retain not only the c hoice of v alue for k , but also k selimination set . W e do , ho w ev er , need to remo v e from this elimination set an y en try thatin v olv es the ev en tual bac ktrac k v ariable j , since these en tries are no longer v alid theydep end on the assumption that j tak es its old v alue , and this assumption is no w false .Algorithm . Dynamic bac ktrac king I Given as inputs a c onstr aint satisfaction pr ob lem and an elimination me chanism . Set P Ei for e ach i I . . If P I , r eturn P . Otherwise , sele ct a variable i I BnZr P . Set Ei Ei P i . . Set S Vi BnZr bEi . If S is nonempty , cho ose an element v S . A dd i v to P andr eturn to step . . If S is empty , we must have bEi Vi let E b e the set of al l variables app e aring in theexplanations for e ach eliminate d value . . If E , r eturn failur e . Otherwise , let j vj b e the last entry in P such that j E .R emove j vj fr om P and , for e ach variable k assigne d a value after j , r emove fr omEk any eliminating explanation that involves j . SetEj Ej P j f vj E P g so that vj is eliminate d as a value for j b e c ause of the values taken by variables inE P . The inclusion of the term P j inc orp or ates new information fr om variablesthat have b e en assigne d values sinc e the original assignment of vj to j . Now set i jand r eturn to step .Theorem . Dynamic b acktr acking always terminates and is c omplete . It c ontinues tosatisfy Pr op osition . and c an b e exp e cte d to exp and fewer no des than b ackjumping pr ovide dthat the go al no des ar e distribute d r andomly in the se ar ch sp ac e . gThe essen tial di erence b et w een dynamic and dep endency directed bac ktrac king is thatthe structure of our eliminating explanations means that w e only sa v e nogo o d informationbased on the curren t v alues of assigned v ariables if a nogo o d dep ends on outdated infor mation , w e drop it . By doing this , w e a v oid the need to retain an exp onen tial amoun t ofnogo o d information . What mak es this tec hnique v aluable is that as stated in the theorem termination is still guaran teed .There is one trivial mo di cation that w e can mak e to Algorithm . that is quite usefulin practice . After remo ving the curren t v alue for the bac ktrac k v ariable j , Algorithm . replaces it with another . But there is no real reason to do this w e couldinstead pic k a v alue for an en tirely di eren t v ariable Algorithm . Dynamic bac ktrac king Given as inputs a c onstr aint satisfaction pr ob lem and an elimination me chanism . Set P Ei for e ach i I . . If P I , r eturn P . Otherwise , sele ct a variable i I BnZr P . Set Ei Ei P i . . Set S Vi BnZr bEi . If S is nonempty , cho ose an element v S . A dd i v to P andr eturn to step . . If S is empty , we must have bEi Vi let E b e the set of al l variables app e aring in theexplanations for e ach eliminate d value . . If E , r eturn failur e . Otherwise , let j vj b e the last entry in P that binds avariable app e aring in E . R emove j vj fr om P and , for e ach variable k assigne da value after j , r emove fr om Ek any eliminating explanation that involves j . A dd vj E P to Ej and r eturn to step . . An exampleIn order to mak e Algorithm . a bit clearer , supp ose that w e consider a small map coloring problem in detail . The map is sho wn in Figure and consists of v e coun tries Albania , Bulgaria , Czec hoslo v akia , Denmark and England . W e will assume wrongly ! thatthe coun tries b order eac h other as sho wn in the gure , where coun tries are denoted b y no desand b order one another if and only if there is an arc connecting them .In coloring the map , w e can use the three colors red , y ello w and blue . W e will t ypicallyabbreviate the coun try names to single letters in the ob vious w a y .W e b egin our searc h with Albania , deciding sa y to color it red . When w e no w lo ok atBulgaria , no colors are eliminated b ecause Albania and Bulgaria do not share a b order w edecide to color Bulgaria y ello w . This is a mistak e . W e no w go on to consider Czec hoslo v akia since it b orders Albania , the color red iseliminated . W e decide to color Czec hoslo v akia blue and the situation is no w this ynamic Ba cktra ckingss s s s BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr Albania DenmarkEngland BulgariaCzec hoslo v akiaFigure A small map coloring problemcoun try color red y ello w blueAlbania redBulgaria y ello wCzec hoslo v akia blue ADenmarkEnglandF or eac h coun try , w e indicate its curren t color and the eliminating explanations that meanit cannot b e colored eac h of the three colors when suc h explanations exist . W e no w lo okat Denmark .Denmark cannot b e colored red b ecause of its b order with Albania and cannot b e coloredy ello w b ecause of its b order with Bulgaria it m ust therefore b e colored blue . But no wEngland cannot b e colored an y color at all b ecause of its b orders with Albania , Bulgariaand Denmark , and w e therefore need to bac ktrac k to one of these three coun tries . A t thisp oin t , the elimination lists are as follo ws coun try color red y ello w blueAlbania redBulgaria y ello wCzec hoslo v akia blue ADenmark blue A BEngland A B DW e bac ktrac k to Denmark b ecause it is the most recen t of the three p ossibilities , andb egin b y remo ving an y eliminating explanation in v olving Denmark from the ab o v e table toget gcoun try color red y ello w blueAlbania redBulgaria y ello wCzec hoslo v akia blue ADenmark A BEngland A BNext , w e add to Denmark s elimination list the pair blue f A B g This indicates correctly that b ecause of the curren t colors for Albania and Bulgaria , Den mark cannot b e colored blue b ecause of the subsequen t dead end at England . Since ev erycolor is no w eliminated , w e m ust bac ktrac k to a coun try in the set f A B g . ChangingCzec hoslo v akia s color w on t help and w e m ust deal with Bulgaria instead . The eliminationlists are no w coun try color red y ello w blueAlbania redBulgariaCzec hoslo v akia blue ADenmark A B A ,BEngland A BW e remo v e the eliminating explanations in v olving Bulgaria and also add to Bulgaria s elim ination list the pair y ello w A indicating correctly that Bulgaria cannot b e colored y ello w b ecause of the curren t c hoice ofcolor for Albania red .The situation is no w coun try color red y ello w blueAlbania redCzec hoslo v akia blue ABulgaria ADenmark AEngland AW e ha v e mo v ed Bulgaria past Czec hoslo v akia to re ect the searc h reordering in the algo rithm . W e can no w complete the problem b y coloring Bulgaria red , Denmark either y ello wor blue , and England the color not used for Denmark .This example is almost trivially simple , of course the thing to note is that when w ec hanged the color for Bulgaria , w e retained b oth the blue color for Czec hoslo v akia and theinformation indicating that none of Czec hoslo v akia , Denmark and England could b e red .In more complex examples , this information ma y b e v ery hard w on and retaining it ma ysa v e us a great deal of subsequen t searc h e ort .Another feature of this sp eci c example and of the example of the in tro duction asw ell is that the computational b ene ts of dynamic bac ktrac king are a consequence of ynamic Ba cktra ckingthe automatic realization that the problem splits in to disjoin t subproblems . Other authorsha v e also discussed the idea of applying divide and conquer tec hniques to csp s Seidel , Zabih , , but their metho ds su er from the disadv an tage that they constrain the order inwhic h unassigned v ariables are assigned v alues , p erhaps at o dds with the common heuristicof assigning v alues rst to those v ariables that are most tigh tly constrained . Dynamicbac ktrac king can also b e exp ected to b e of use in situations where the problem in questiondo es not split in to t w o or more disjoin t subproblems . . Exp erimen tationDynamic bac ktrac king has b een incorp orated in to the crossw ord puzzle generation programdescrib ed in Ginsb erg , F rank , Halpin , T orrance , , and leads to signi can t p erfor mance impro v em en ts in that restricted domain . More sp eci cally , the metho d w as testedon the problem of generating puzzles of sizes ranging from to eac h puzzlew as attempted times using b oth dynamic bac ktrac king and simple bac kjumping . Thedictionary w as sh u ed b et w een solution attempts and a maxim um of bac ktrac ks w erep ermitted b efore the program w as deemed to ha v e failed .In b oth cases , the algorithms w ere extended to include iterativ e broadening Ginsb erg Harv ey , , the c heap est rst heuristic and forw ard c hec king . Cheap est rst hasalso b een called most constrained rst and selects for instan tiation that v ariable withthe few est n um b er of remaining p ossibilities i .e . , that v ariable for whic h it is c heap est toen umerate the p ossible v alues Smith Genesereth , . F orw ard c hec king prunes theset of p ossibilities for crossing w ords whenev er a new w ord is en tered and constitutes ourexp erimen tal c hoice of elimination mec hanism at an y p oin t , w ords for whic h there is no legalcrossing w ord are eliminated . This ensures that no w ord will b e en tered in to the crossw ordif the w ord has no p oten tial crossing w ords at some p oin t . The c heap est rst heuristicw ould iden tify the problem at the next step in the searc h , but forw ard c hec king reducesthe n um b er of bac ktrac ks substan tially . The least constraining heuristic Ginsb erg et al . , w as not used this heuristic suggests that eac h w ord slot b e lled with the w ord thatminimall y constrains the subsequen t searc h . The heuristic w as not used b ecause it w ouldin v alidate the tec hnique of sh u ing the dictionary b et w een solution attempts in order togather useful statistics .The table in Figure indicates the n um b er of successful solution attempts out of for eac h of the t w o metho ds on eac h of the crossw ord frames . Dynamic bac ktrac king ismore successful in six cases and less successful in none .With regard to the n um b er of no des expanded b y the t w o metho ds , consider the datapresen ted in Figure , where w e graph the a v erage n um b er of bac ktrac ks needed b y thet w o metho ds . initially comparable , dynamic bac ktrac king pro vides increasingcomputational sa vings as the problems b ecome more di cult . A somewhat broader set ofexp erimen ts is describ ed in Jonsson Ginsb erg , and leads to similar conclusions .There are some examples in Jonsson Ginsb erg , where dynamic bac ktrac kingleads to p erformance degradation , ho w ev er a t ypical case app ears in Figure . this . I am indebted to Da vid McAllester for these observ ations . . Only p oin ts are sho wn b ecause no p oin t is plotted where bac kjumping w as unable to solv e the problem . . The w orst p erformance degradation observ ed w as a factor of appro ximately . gDynamic DynamicF rame bac ktrac king Bac kjumping F rame bac ktrac king Bac kjumping Num b er of problems solv ed successfully kjumping dynamicbac ktrac king r r r r r r r r r r r r r r r rFigure Num b er of bac ktrac ks needed ynamic Ba cktra ckingss s s BnZr BnZr BnZr BnZr BnZr BnZr BnZr BnZr aaaaaaaaaaaaaaaaaaa B Region AFigure A di cult problem for dynamic bac ktrac king gure , w e rst color A , then B , then the coun tries in region , and then get stuc k in region .W e no w presumably bac ktrac k directly to B , lea ving the coloring of region alone . Butthis ma y w ell b e a mistak e the colors in region will restrict our c hoices for B , p erhapsmaking the subproblem consisting of A , B and region more di cult than it migh t b e . Ifregion w ere easy to color , w e w ould ha v e b een b etter o erasing it ev en though w e didn tneed to .This analysis suggests that dep endency directed bac ktrac king should also fare w orseon those coloring problems where dynamic bac ktrac king has trouble , and w e are curren tlyextending the exp erimen ts of Jonsson Ginsb erg , to con rm this . If this conjectureis b orne out , a v ariet y of solutions come to mind . W e migh t , for example , record ho wman y bac ktrac ks are made to a no de suc h as B in the ab o v e gure , and then use this todetermine that exibilit y at B is more imp ortan t than retaining the c hoices made in region . The di cult y of nding a coloring for region can also b e determined from the n um b erof bac ktrac ks in v olv ed in the searc h . . Summary . Wh y it w orksThere are t w o separate ideas that w e ha v e exploited in the dev elopmen t of Algorithm . the others leading up to it . The rst , and easily the most imp ortan t , is the notionthat it is p ossible to mo dify v ariable order on the y in a w a y that allo ws us to retain theresults of earlier w ork when bac ktrac king to a v ariable that w as assigned a v alue early inthe searc h . gThis reordering should not b e confused with the w ork of authors who ha v e suggested adynamic c hoice among the v ariables that r emain to b e assigned v alues Dec h ter Meiri , Ginsb erg et al . , P . Purdom Rob ertson , Zabih McAllester , w eare instead reordering the v ariables that ha v e b e en assigned v alues in the searc h th us far .Another w a y to lo ok at this idea is that w e ha v e found a w a y to erase the v alue giv ento a v ariable directly as opp osed to bac ktrac king to it . This idea has also b een exploredb y Min ton et .al . in Min ton , Johnston , Philips , Laird , and b y Selman et .al . in Selman , Lev esque , Mitc hell , these authors also directly replace v alues assignedto v ariables in satis abilit y problems . Unfortunately , the heuristic repair metho d used isincomplete b ecause no dep endency information is retained from one state of the problemsolv er to the next .There is a third w a y to view this as w ell . The space that w e are examining is really agraph , as opp osed to a tree w e reac h the same p oin t b y coloring Albania blue and thenBulgaria red as if w e color them in the opp osite order . When w e decide to bac kjump from aparticular no de in the searc h space , w e kno w that w e need to bac k up un til some particularprop ert y of that no de ceases to hold and the k ey idea is that b y bac ktrac king along apath other than the one b y whic h the no de w as generated , w e ma y b e able to bac ktrac konly sligh tly when w e w ould otherwise need to retreat a great deal . This observ ation isin teresting b ecause it ma y w ell apply to problems other than csp s . Unfortunately , it is notclear ho w to guaran tee completeness for a searc h that disco v ers a no de using one path andbac ktrac ks using another .The other idea is less no v el . As w e ha v e already remark ed , our use of eliminatingexplanations is quite similar to the use of nogo o ds in the a tms comm unit y the principaldi erence is that w e attac h the explanations to the v ariables they impact and drop themwhen they cease to b e relev an t . They migh t b ecome relev an t again later , of course . Thisa v oids the prohibitiv e space requiremen ts of systems that p ermanen tly cac he the results oftheir nogo o d calculations this observ ation also ma y b e extensible b ey ond the domain ofcsp s sp eci cally . Again , there are other w a ys to view this Gashnig s notion of b ackmarking Gasc hnig , records similar information ab out the reason that particular p ortions of asearc h space are kno wn not to con tain solutions . . F uture w orkThere are a v ariet y of w a ys in whic h the tec hniques w e ha v e presen ted can b e extended inthis section , w e sk etc h a few of the more ob vious ones . . . Ba cktra cking to older culpritsOne extension to our w ork in v olv es lifting the restriction in Algorithm . that the v ariableerased alw a ys b e the most recen tly assigned mem b er of the set E .In general , w e cannot do this while retaining the completeness of the searc h . Considerthe follo wing example Imagine that our csp in v olv es three v ariables , x , y and z , that can eac h tak e the v alue . F urther , supp ose that this csp has no solutions , in that after w e pic k an y t w o v aluesfor x and for y , w e realize that there is no suitable c hoice for z . ynamic Ba cktra ckingW e b egin b y taking x y when w e realize the need to bac ktrac k , w e in tro duce thenogo o dx y and replace the v alue for y with y .This fails , to o , but no w supp ose that w e w ere to decide to bac ktrac k to x , in tro ducingthe new nogo o dy x W e c hange x s v alue to and erase .This also fails . W e decide that y is the problem and c hange its v alue to , in tro ducingthe nogo o dx y erasing . And when this fails , w e are in danger of returning to x y , whic h w eeliminated at the b eginning of the example . This lo op ma y cause a mo di ed v ersion of thedynamic bac ktrac king algorithm to fail to terminate .In terms of the pro of of Theorem . , the nogo o ds disco v ered already include informationab out all assigned v ariables , so there is no di erence b et w een and . When w e drop in fa v or of , w e are no longer in a p osition to reco v er .W e can deal with this b y placing conditions on the v ariables to whic h w e c ho ose tobac ktrac k the conditions need to b e de ned so that the pro of of Theorem . con tin ues tohold . erimen tation indicates that lo ops of the form w e ha v e describ ed are extremelyrare in practice it ma y also b e p ossible to detect them directly and thereb y retain moresubstan tial freedom in the c hoice of bac ktrac k p oin t .This freedom of bac ktrac k raises an imp ortan t question that has not y et b een addressedin the literature When bac ktrac king to a v oid a di cult y of some sort , to where should onebac ktrac k ?Previous w ork has b een constrained to bac ktrac k no further than the most recen t c hoicethat migh t impact the problem in question an y other decision w ould b e b oth incomplete andine cien t . Although an extension of Algorithm . need not op erate under this restriction ,w e ha v e giv en no indication of ho w the bac ktrac k p oin t should b e selected .There are sev eral easily iden ti ed factors that can b e exp ected to b ear on this c hoice .The rst is that there remains a reason to exp ect bac ktrac king to c hronologically recen tc hoices to b e the most e ectiv e these c hoices can b e exp ected to ha v e con tributed tothe few est eliminating explanations , and there is ob vious adv an tage to retaining as man yeliminating explanations as p ossible from one p oin t in the searc h to the next . It is p os sible , ho w ev er , to simply iden tify that bac ktrac k p oin t that a ects the few est n um b er ofeliminating explanations and to use that .Alternativ ely , it migh t b e imp ortan t to bac ktrac k to the c hoice p oin t for whic h therewill b e as man y new c hoices as p ossible as an extreme example , if there is a v ariable ifor whic h ev ery v alue other than its curren t one has already b een eliminated for otherreasons , bac ktrac king to i is guaran teed to generate another bac ktrac k immediately andshould probably b e a v oided if p ossible . . Another solution app ears in McAllester , . gFinally , there is some measure of the directness with whic h a v ariable b ears on aproblem . If w e are unable to nd a v alue for a particular v ariable i , it is probably sensibleto bac ktrac k to a second v ariable that shares a constrain t with i itself , as opp osed to somev ariable that a ects i only indirectly .Ho w are these comp eting considerations to b e w eighed ? I ha v e no idea . But the frame w ork w e ha v e dev elop ed is in teresting b ecause it allo ws us to w ork on this question . Inmore basic terms , w e can no w debug partial solutions to csp s directly , mo ving laterallythrough the searc h space in an attempt to remain as close to a solution as p ossible . Thissort of lateral mo v emen t seems cen tral to h uman solution of di cult searc h problems , andit is encouraging to b egin to understand it in a formal w a y . . . Dependency pr uningIt is often the case that when one v alue for a v ariable is eliminated while solving a csp ,others are eliminated as w ell . As an example , in solving a sc heduling problem a particularc hoice of time sa y t ma y b e eliminated for a task A b ecause there then isn t enoughtime b et w een A and a subsequen t task B in this case , all later times can ob viously b eeliminated for A as w ell .F ormalizing this can b e subtle after all , a later time for A isn t uniformly w orse than anearlier time b ecause there ma y b e other tasks that need to precede A and making A latermak es that part of the sc hedule easier . It s the problem with B alone that forces A to b eearlier once again , the analysis dep ends on the abilit y to main tain dep endency informationas the searc h pro ceeds .W e can formalize this as follo ws . Giv en a csp I V , supp ose that the v alue v hasb een assigned to some i I . No w w e can construct a new csp I V in v olving theremaining v ariables I I BnZr f i g , where the new set V not men tion the p ossible v aluesVi for i , and where generated from b y mo difying the constrain ts to indicate that ihas b een assigned the v alue v . W e also mak e the follo wing de nition De nition . Given a csp , supp ose that i is a variable that has two p ossible values u andv . We wil l say that v is stricter than u if every c onstr aint in the csp induc e d by assigningu to i is also a c onstr aint in the csp induc e d by assigning i the value v .The p oin t , of course , is that if v is stricter than u is , there is no p oin t to trying asolution in v olving v once u has b een eliminated . After all , nding suc h a solution w ouldin v olv e satisfying all of the constrain ts in the v restriction , these are a sup erset of those inthe u restriction , and w e w ere unable to satisfy the constrain ts in the u restriction originally .The example with whic h w e b egan this section no w generalizes to the follo wing Prop osition . Supp ose that a csp involves a set S of variables , and that we have ap artial solution that assigns values to the variables in some subset P S . Supp ose furtherthat if we extend this p artial solution by assigning the value u to a variable i P , ther e isno further extension to a solution of the entir e csp . Now c onsider the csp involving thevariables in S BnZr P that is induc e d by the choic es of values for variables in P . If v is stricterthan u as a choic e of value for i in this pr oblem , the original csp has no solution that b othassigns v to i and extends the given p artial solution on P . ynamic Ba cktra ckingThis prop osition isn t quite enough in the earlier example , the c hoice of t for Awill not b e stricter than t if there is an y task that needs to b e sc heduled b efore A is .W e need to record the fact that B whic h is no longer assigned a v alue is the source of thedi cult y . T o do this , w e need to augmen t the dep endency information with whic h w e arew orking .More precisely , when w e sa y that a set of v ariables f xi g eliminates a v alue v for a v ariablex , w e mean that our searc h to date has allo w ed us to conclude that v x vk xk v xwhere the vi are the curren t c hoices for the xi . W e can ob viously rewrite this as v x vk xk v x F where F indicates that the csp in question has no solution .Let s b e more sp eci c still , indicating in exactly which csp has no solution v x vk xk v x F I where I is the set of v ariables in the complete csp .No w w e can address the example with whic h w e b egan this section the csp that iskno wn to fail in an expression suc h as is not the en tire problem , but only a subset of it .In the example , w e are considering , the subproblem in v olv es only the t w o tasks A and B .In general , w e can augmen t our nogo o ds to include information ab out the subproblems onwhic h they fail , and then measure strictness with resp ect to these restricted subproblemsonly . In our example , this will indeed allo w us to eliminate t from consideration as ap ossible time for A .The additional information stored with the nogo o ds doubles their size w e ha v e to store asecond subset of the v ariables in the csp , and the v ariable sets in v olv ed can b e manipulatedeasily as the searc h pro ceeds . The cost in v olv ed in emplo ying this tec hnique is therefore thatof the strictness computation . This ma y b e substan tial giv en the data structures curren tlyused to represen t csp s whic h t ypically supp ort the need to c hec k if a constrain t has b eenviolated but little more , but it seems lik ely that compile time mo di cations to these datastructures can b e used to mak e the strictness question easier to answ er . In sc hedulingproblems , preliminary exp erimen tal w ork sho ws that the idea is an imp ortan t one here ,to o , there is m uc h to b e done .The basic lesson of dynamic bac ktrac king is that b y retaining only those nogo o ds thatare still relev an t giv en the partial solution with whic h w e are w orking , the storage di cultiesencoun tered b y full dep endency directed metho ds can b e alleviated . This is what mak esall of the ideas w e ha v e prop osed p ossible erasing v alues , selecting alternate bac ktrac kp oin ts , and dep endency pruning . There are surely man y other e ectiv e uses for a practicaldep endency main tenance system as w ell .Ac kno wledgemen tsThis w ork has b een supp orted b y the Air F orce O ce of Scien ti c Researc h under gran tn um b er and b y D ARP A Rome Labs under gran t n um b er F C . I gw ould lik e to thank Rina Dec h ter , Mark F o x , Don Geddis , Will Harv ey , Vipin Kumar ,Scott Ro y and Narinder Singh for helpful commen ts on these ideas . Ari Jonsson andDa vid McAllester pro vided me in v aluable assistance with the exp erimen tation and pro ofsresp ectiv ely .A . Pro ofsLemma . L et b e a c omplete elimination me chanism for a csp , let P b e a p artial solutionto this csp and let i P . Now if P c an b e suc c essful ly extende d to a c omplete solution afterassigning i the value v , then v b P i .Pro of . Supp ose otherwise , so that v E P i . It follo ws directly from the completenessof thatE P BnZr P a con tradiction .Lemma . A t any p oint in the exe cution of A lgorithm . , if the last element of the p artialsolution P assigns a value to the variable i , then the unexplor e d siblings of the curr ent no dear e those that assign to i the values in Vi BnZr Ei .Pro of . W e rst note that when w e decide to assign a v alue to a new v ariable i in step the algorithm , w e tak e Ei b P i so that Vi BnZr Ei is the set of allo w ed v alues for thisv ariable . The lemma therefore holds in this case . The fact that it con tin ues to hold througheac h rep etition of the lo op in steps and is no w a simple induction at eac h p oin t , w eadd to Ei the no de that has just failed as a p ossible v alue to b e assigned to i .Prop osition . A lgorithm . is e quivalent to depth rst se ar ch and ther efor e c omplete .Pro of . This is an easy consequence of the lemma . P artial solutions corresp ond to no desin the searc h space .Lemma . L et P b e a p artial solution obtaine d during the exe cution of A lgorithm . , andlet i P b e a variable assigne d a value by P . Now if P P c an b e suc c essful ly extende dto a c omplete solution after assigning i the value v but v E Ei , we must haveE P BnZr P Pro of . As in the pro of of Lemma . , w e sho w that no step of Algorithm . can causeLemma . to b ecome false .That the lemma holds after step , where the searc h is extended to consider a newv ariable , is an immediat e consequence of the assumption that the elimination mec hanismis complete .In step , when w e add vj E BnZr f j g to the set of eliminating explanations for j , w eare simply recording the fact that the searc h for a solution with j set to vj failed b ecausew e w ere unable to extend the solution to i . It is a consequence of the inductiv e h yp othesisthat as long as no v ariable in E BnZr f j g c hanges , this conclusion will remain v alid .Prop osition . Backjumping is c omplete and always exp ands fewer no des than do es depth rst se ar ch . ynamic Ba cktra ckingPro of . That few er no des are examined is clear for completeness , it follo ws from Lemma . that the bac ktrac k to some elemen t of E in step will alw a ys b e necessary if a solutionis to b e found .Prop osition . The amount of sp ac e ne e de d by b ackjumping is o i , wher e i j I j isthe numb er of variables in the pr oblem and v is the numb er of values for that variable withthe lar gest value set Vi .Pro of . The amoun t of space needed is dominated b y the storage requiremen ts of the elim ination sets Ej there are i of these . Eac h one migh t refer to eac h of the p ossible v alues fora particular v ariable j the space needed to store the reason that the v alue j is eliminatedis at most j I j , since the reason is simply a list of v ariables that ha v e b een assigned v alues .There will nev er b e t w o eliminating explanations for the same v ariable , since is conciseand w e nev er rebind a v ariable to a v alue that has b een eliminated .Theorem . Dynamic b acktr acking always terminates and is c omplete . It c ontinues tosatisfy Pr op osition . and c an b e exp e cte d to exp and fewer no des than b ackjumping pr ovide dthat the go al no des ar e distribute d r andomly in the se ar ch sp ac e .Pro of . There are four things w e need to sho w That dynamic bac ktrac king needs o i space , that it is complete , that it can b e exp ected to expand few er no des than bac kjumping ,and that it terminates . W e pro v e things in this order .Space This is clear the amoun t of space needed con tin ues to b e b ounded b y the structureof the eliminating explanations .Completeness This is also clear , since b y Lemma . , all of the eliminating explanationsretained in the algorithm are ob viously still v alid . The new explanations added in arealso ob viously correct , since they indicate that j cannot tak e the v alue vj as in bac kjumpingand that j also cannot tak e an y v alues that are eliminated b y the v ariables b eing bac kjump edo v er .E ciency T o see that w e exp e ct to expand few er no des , supp ose that the subproblemin v olving only the v ariables b eing jump ed o v er has s solutions in total , one of whic h is giv enb y the existing v ariable assignmen ts . Assuming that the solutions are distributed randomlyin the searc h space , there is at least a s c hance that this particular solution leads to asolution of the en tire csp if so , the reordered searc h whic h considers this solution earlierthan the other will sa v e the exp ense of either assigning new v alues to these v ariables orrep eating the searc h that led to the existing c hoices . The reordered searc h will also b ene tfrom the information in the nogo o ds that ha v e b een retained for the v ariables b eing jump edo v er .T ermination This is the most di cult part of the pro of .As w e w ork through the algorithm , w e will b e generating and then discarding a v ariet yof eliminating explanations . Supp ose that e is suc h an explanation , sa ying that j cannottak e the v alue vj b ecause of the v alues curren tly tak en b y the v ariables in some set eV .W e will denote the v ariables in eV b y x . . . xk and their curren t v alues b y v . . . vk . Indeclarativ e terms , the eliminating explanation is telling us that x v xk vk j vj gDep endency directed bac ktrac king w ould ha v e us accum ulate all of these nogo o ds dynamicbac ktrac king allo ws us to drop an y particular instance of for whic h the an teceden t is nolonger v alid .The reason that dep endency dir e cte d bac ktrac king is guaran teed to terminate is thatthe set of accum ulated nogo o ds eliminates a monotonically increasing amoun t of the searc hspace . Eac h nogo o d eliminates a new section of the searc h space b ecause the nature of thesearc h pro cess is suc h that an y no de examined is consisten t with the nogo o ds that ha v e b eenaccum ulated th us far the pro cess is monotonic b ecause all nogo o ds are retained throughoutthe searc h . These argumen ts cannot b e applied to dynamic bac ktrac king , since nogo o ds areforgotten as the searc h pro ceeds . But w e can mak e an analogous argumen t .T o do this , supp ose that when w e disco v er a nogo o d lik e , w e record with it all of thev ariables that precede the v ariable j in the partial order , together with the v alues curren tlyassigned to these v ariables . Th us an eliminating explanation b ecomes essen tially a nogo o dn of the form together with a set S of v ariable v alue pairs .W e no w de ne a mapping n S that c hanges the an teceden t of to include assump tions ab out al l the v ariables b ound in S , so that if S f si vi g , n S s v sl vl j vj A t an y p oin t in the execution of the algorithm , w e denote b y N the conjunction of themo di ed nogo o ds of the form .W e no w mak e the follo wing claims . F or an y eliminating explanation n S , n j n S so that n S is v alid for theproblem at hand . . F or an y new eliminating explanation n S , n S is not a consequence of N . . The deductiv e consequences of N gro w monotonically as the dynamic bac ktrac kingalgorithm pro ceeds .The theorem will follo w from these three observ ations , since w e will kno w that N is a v alidset of conclusions for our searc h problem and that w e are once again making monotonicprogress to w ard eliminating the en tire searc h space and concluding that the problem isunsolv able .That n S is a consequence of n S is clear , since the mo di cation used to obtain from in v olv es strengthening that an teceden t of . It is also clear that n S isnot a consequence of the nogo o ds already obtained , since w e ha v e added to the an teceden tonly conditions that hold for the no de of the searc h space curren tly under examination . If n S w ere a consequence of the nogo o ds w e had obtained th us far , this no de w ould notb e b eing considered .The last observ ation dep ends on the follo wing lemma Lemma A . Supp ose that x is a variable assigne d a value by our p artial solution and thatx app e ars in the ante c e dent of the no go o d n in the p air n S . Then if S the set ofvariables assigne d values no later than x , S S . ynamic Ba cktra ckingPro of . Consider a y S , and supp ose that it w ere not in S . W e cannot ha v e y x , sincey w ould then b e men tioned in the nogo o d n and therefore in S . So w e can supp ose thaty is actually assigned a v alue e arlier than x is . No w when n S w as added to the set ofeliminating explanations , it m ust ha v e b een the case that x w as assigned a v alue since itapp ears in the an teceden t of n but that y w as not . But w e also kno w that there w as alater time when y w as assigned a v alue but x w as not , since y precedes x in the curren tpartial solution . This means that x m ust ha v e c hanged v alue at some p oin t after n S w asadded to the set of eliminating explanations but n S w ould ha v e b een deleted when thishapp ened . This con tradiction completes the pro of .Returning to the pro of the Theorem . , supp ose that w e ev en tually drop n S fromour collection of nogo o ds and that when w e do so , the new nogo o d b eing added is n S . Itfollo ws from the lemma that S S . Since xi vi is a clause in the an teceden t of n S , itfollo ws that n S will imply the negation of the an teceden t of n S and will thereforeimply n S itself . Although w e drop n S when w e drop the nogo o d n S , n S con tin ues to b e en tailed b y the mo di ed set N , the consequences of whic h are seen to b egro wing monotonically .ReferencesBruyno oghe , M . . Solving com binatorial searc h problems b y in telligen t bac ktrac king .Information Pr o c essing L etters , , .de Kleer , J . . An assumption based truth main tenance system . A rti cial Intel ligenc e , , .Dec h ter , R . , Meiri , I . . Exp erimen tal ev aluation of prepro cessing tec hniques inconstrain t satisfaction problems . In Pr o c e e dings of the Eleventh International JointConfer enc e on A rti cial Intel ligenc e , pp . .Gasc hnig , J . . P erformance measuremen t and analysis of certain searc h algorithms .T ec h . rep . CMU CS , Carnegie Mellon Univ ersit y .Ginsb erg , M . L . , F rank , M . , Halpin , M . P . , T orrance , M . C . . Searc h lessons learnedfrom crossw ord puzzles . In Pr o c e e dings of the Eighth National Confer enc e on A rti cialIntel ligenc e , pp . .Ginsb erg , M . L . , Harv ey , W . D . . Iterativ e broadening . A rti cial Intel ligenc e , , .Jonsson , A . K . , Ginsb erg , M . L . . Exp erimen ting with new systematic and non systematic searc h tec hniques . In Pr o c e e dings of the AAAI Spring Symp osium on AIand NP Har d Pr oblems Stanford , California .McAllester , D . A . . P artial order bac ktrac king . Journal of A rti cial Intel ligenc eR ese ar ch , . Submitted .Min ton , S . , Johnston , M . D . , Philips , A . B . , Laird , P . . Solving large scale con strain t satisfaction and sc heduling problems using a heuristic repair metho d . In Pr o c e e dings of the Eighth National Confer enc e on A rti cial Intel ligenc e , pp . . gP . Purdom , C . B . , Rob ertson , E . . Bac ktrac king with m ulti lev el dynamic searc hrearrangemen t . A cta Informatic a , , .Seidel , R . . A new metho d for solving constrain t satisfaction problems . In Pr o c e e dingsof the Seventh International Joint Confer enc e on A rti cial Intel ligenc e , pp . .Selman , B . , Lev esque , H . , Mitc hell , D . . A new metho d for solving hard satis abilit yproblems . In Pr o c e e dings of the T enth National Confer enc e on A rti cial Intel ligenc e .Smith , D . E . , Genesereth , M . R . . Ordering conjunctiv e queries . A rti cial Intel li genc e , , .Stallman , R . M . , Sussman , G . J . . F orw ard reasoning and dep endency directedbac ktrac king in a system for computer aided circuit analysis . A rti cial Intel ligenc e , , .Zabih , R . . Some applications of graph bandwidth to constrain t satisfaction problems .In Pr o c e e dings of the Eighth National Confer enc e on A rti cial Intel ligenc e , pp . .Zabih , R . , McAllester , D . A . . A rearrangemen t searc h strategy for determiningprop ositional satis abilit y . In Pr o c e e dings of the Seventh National Confer enc e onA rti cial Intel ligenc e , pp . . "
"Journal of Arti cial In telligence Researc h Submitted published Mark et Orien ted Programming En vironmen t and itsApplication to Distributed Multicommo dit y Flo w ProblemsMic hael P . W ellman wellman of Michigan , Dept . of Ele ctric al Engine ering and Computer Scienc e ,A nn A rb or , MI USAAbstractMark et price systems constitute a w ell understo o d class of mec hanisms that undercertain conditions pro vide e ectiv e decen tralization of decision making with minim al com m unication o v erhead . In a market oriente d pr o gr amming approac h to distributed problemsolving , w e deriv e the activities and resource allo cations for a set of computational agen tsb y computing the comp etitiv e equilibrium of an arti cial econom y . W alras pro vides basicconstructs for de ning computational mark et structures , and proto cols for deriving theircorresp onding price equilibria . In a particular realization of this approac h for a form ofm ulticomm o dit y o w problem , w e see that careful construction of the decision pro cess ac cording to economic principles can lead to e cien t distributed resource allo cation , and thatthe b eha vior of the system can b e meaningfully analyzed in economic terms . . Distributed Planning and EconomicsIn a distribute d or m ultiagen t planning system , the plan for the system as a whole is a com p osite of plans pro duced b y its constituen t agen ts . These plans ma y in teract signi can tly inb oth the resources required b y eac h of the agen ts activities preconditions and the pro d ucts resulting from these activities p ostconditions . Despite these in teractions , it is oftenadv an tageous or necessary to distribute the planning pro cess b ecause agen ts are separatedgeographically , ha v e di eren t information , p ossess distinct capabilities or authorit y , or ha v eb een designed and implemen ted separately . In an y case , b ecause eac h agen t has limitedcomp etence and a w areness of the decisions pro duced b y others , some sort of co ordination isrequired to maximize the p erformance of the o v erall system . Ho w ev er , allo cating resourcesvia cen tral con trol or extensiv e comm unication is deemed infeasible , as it violates whatev erconstrain ts dictated distribution of the planning task in the rst place .The task facing the designer of a distributed planning system is to de ne a computa tionally e cien t co ordination mec hanism and its realization for a collection of agen ts . Theagen t con guration ma y b e giv en , or ma y itself b e a design parameter . By the term agent ,I refer to a mo dule that acts within the mec hanism according to its o wn kno wledge andin terests . The capabilities of the agen ts and their organization in an o v erall decision makingstructure determine the b eha vior of the system as a whole . Because it concerns the collec tiv e b eha vior of self in terested decision mak ers , the design of this decen tralized structure isfundamen tally an exercise in economics or incen tiv e engineering . The problem of dev elopingarc hitectures for distributed planning ts within the framew ork of me chanism design Hur wicz , Reiter , , and man y ideas and results from economics are directly applicable .In particular , the class of mec hanisms based on price systems and comp etition has b eendeeply in v estigated b y economists , who ha v e c haracterized the conditions for its e ciencyc AI Access F oundation and Morgan Kaufmann Publishers . All righ ts reserv ed .Wellmanand compatibilit y with other features of the econom y . When applicable , the comp etitiv emec hanism ac hiev es co ordination with minimal comm unication requiremen ts in a precisesense related to the dimensionalit y of messages transmitted among agen ts Reiter , .The theory of gener al e quilibrium Hilden brand Kirman , pro vides the founda tion for a general approac h to the construction of distributed planning systems based onprice mec hanisms . In this approac h , w e regard the constituen t planning agen ts as consumersand pro ducers in an arti cial econom y , and de ne their individual activities in terms of pro duction and consumption of commo dities . In teractions among agen ts are cast as exc hanges ,the terms of whic h are mediated b y the underlying economic mec hanism , or proto col . Bysp ecifying the univ erse of commo dities , the con guration of agen ts , and the in teractionproto col , w e can ac hiev e a v ariet y of in teresting and often e ectiv e decen tralized b eha viors .F urthermore , w e can apply economic theory to the analysis of alternativ e arc hitectures , andth us exploit a w ealth of existing kno wledge in the design of distributed planners .I use the phrase market oriente d pr o gr amming to refer to the general approac h of de riving solutions to distributed resource allo cation problems b y computing the comp etitiv eequilibrium of an arti cial econom y . the follo wing , I describ e this general approac hand a primitiv e programming en vironmen t supp orting the sp eci cation of computationalmark ets and deriv ation of equilibrium prices . An example problem in distributed trans p ortation planning demonstrates the feasibilit y of decen tralizing a problem with non trivialin teractions , and the applicabilit y of economic principles to distributed problem solving . . W ALRAS A Mark et Orien ted Programming En vironmen tT o explore the use of mark et mec hanisms for the co ordination of distributed planning mo d ules , I ha v e dev elop ed a protot yp e en vironmen t for sp ecifying and sim ulating computationalmark ets . The system is called w alras , after the cen tury F renc h economist L eon W al ras , who w as the rst to en vision a system of in terconnected mark ets in price equilibrium .W alras pro vides basic mec hanisms implemen ting v arious sorts of agen ts , auctions , andbidding proto cols . T o sp ecify a computational econom y , one de nes a set of go o ds andinstan tiates a collection of agen ts that pro duce or consume those go o ds . Dep ending on thecon text , some of the go o ds or agen ts ma y b e xed exogenously , for example , they could cor resp ond to real w orld go o ds or agen ts participating in the planning pro cess . Others migh tb e completely arti cial ones in v en ted b y the designer to decen tralize the problem solvingpro cess in a particular w a y . Giv en a mark et con guration , w alras then runs these agen tsto determine an equilibrium allo cation of go o ds and activities . This distribution of go o dsand activities constitutes the mark et solution to the planning problem . . The name w as inspired b y Shoham s use of agent orient e d pr o gr amming to refer to a sp ecializati on ofob ject orien ted programming where the en tities are describ ed in terms of agen t concepts and in teractvia sp eec h acts Shoham , . Mark et orien ted programming is an analogous sp ecializati on , where theen tities are economic agen ts that in teract according to mark et concepts of pro duction and exc hange . Thephrase has also b een in v ok ed b y La v oie , Baetjer , and T ulloh to refer to real mark ets in soft w arecomp onen ts . Oriented Pr ogramming . General EquilibriumThe w alras framew ork is patterned directly after general equilib rium theory . A brief exp o sition , glossing o v er man y ne p oin ts , follo ws for elab oration see an y text on micro economictheory e .g . , V arian , .W e start with k go o ds and n agen ts . Agen ts fall in t w o general classes . Consumers canbuy , sell , and consume go o ds , and their preferences for consuming v arious com binations orbund les of go o ds are sp eci ed b y their utility function . If agen t i is a consumer , then itsutilit y function , ui k ! , ranks the v arious bundles of go o ds according to preference .Consumers ma y also start with an initial allo cation of some go o ds , termed their endow ment . Let ei j denote agen t i s endo wmen t of go o d j , and xi j the amoun t of go o d j that iultimately consumes . The ob jectiv e of consumer i is to c ho ose a feasible bundle of go o ds , xi xi k rendered in v ector notation as xi , so as to maximize its utilit y . A bundleis feasible for consumer i if its total cost at the going prices do es not exceed the v alue ofi s endo wmen t at these prices . The consumer s c hoice can b e expressed as the follo wingconstrained optimization problem maxxi ui xi s .t . p xi p ei where p p pk is the v ector of prices for the k go o ds .Agen ts of the second t yp e , pr o duc ers , can transform some sorts of go o ds in to someothers , according to their te chnolo gy . The tec hnology sp eci es the feasible com binations ofinputs and outputs for the pro ducer . Let us consider the sp ecial case where there is oneoutput go o d , indexed j , and the remaining go o ds are p oten tial inputs . In that case , thetec hnology for pro ducer i can b e describ ed b y a pr o duction function ,yi BnZr xi j fi xi xi j BnZr xi j xi k sp ecifying the maxim um output pro ducible from the giv en inputs . When a go o d is aninput in its o wn pro duction , the pro duction function c haracterizes net output . In thiscase , the pro ducer s ob jectiv e is to c ho ose a pro duction plan that maximizes pro ts sub jectto its tec hnology and the going price of its output and input go o ds . This in v olv es c ho osing apro duction lev el , yi , along with the lev els of inputs that can pro duce yi at the minim um cost .Let xi and p denote the consumption and prices , resp ectiv ely , of the input go o ds . Thenthe corresp onding constrained optimization problem is to maximize pro ts , the di erenceb et w een rev en ues and costs maxyi pj yi BnZr minxi p xi s .t . yi fi xi or equiv alen tly ,minxi p xi s .t . BnZr xi j fi xi An agen t acts c omp etitively when it tak es prices as giv en , neglecting an y impact of itso wn b eha vior on prices . The ab o v e form ulation implicitly assumes p erfect comp etition , inthat the prices are parameters of the agen ts constrained optimization problems . P erfectcomp etition realistically re ects individual rationalit y when there are n umerous agen ts , eac hsmall with resp ect to the en tire econom y . Ev en when this is not the case , ho w ev er , w e can t comp etitiv e b eha vior in individual agen ts if w e so c ho ose . The implications ofthe restriction to p erfect comp etition are discussed further b elo w .A pair p x of a price v ector and v ector of demands for eac h agen t constitutes ac omp etitive e quilibrium for the econom y if and only if . F or eac h agen t i , xi is a solution to its constrained optimization problem or at prices p , and . the net amoun t of eac h go o d pro duced and consumed equals the total endo wmen t ,nXi xi j nXi ei j for j k In other w ords , the total amoun t consumed equals the total amoun t pro duced coun tedas negativ e quan tities in the consumption bundles of pro ducers , plus the total amoun tthe econom y started out with the endo wmen ts .Under certain classical assumptions essen tially con tin uit y , monotonicit y , and conca v it y of the utilit y and pro duction functions see , e .g . , Hilden brand Kirman , V arian , , comp etitiv e equilibria exist , and are unique giv en strictness of these conditions .F rom the p ersp ectiv e of mec hanism design , comp etitiv e equilibria p ossess sev eral desirableprop erties , in particular , the t w o fundamen tal w elfare theorems of general equilibrium the ory all comp etitiv e equilibria are Par eto optimal no agen t can do b etter without someother doing w orse , and any feasible P areto optim um is a comp etitiv e equilibriu m forsome initial allo cation of the endo wmen ts . These prop erties seem to o er exactly whatw e need a b ound on the qualit y of the solution , plus the prosp ect that w e can ac hiev ethe most desired b eha vior b y carefully engineering the con guration of the computationalmark et . Moreo v er , in equilibrium , the prices re ect exactly the information required fordistributed agen ts to optimally ev aluate p erturbations in their b eha vior without resortingto comm unication or reconsideration of their full set of p ossibilities Ko opmans , . . Computing Comp etitiv e EquilibriaComp etitiv e equilibria are also computable , and algorithms based on xed p oin t meth o ds Scarf , and optimization tec hniques Nagurney , ha v e b een dev elop ed . Bothsorts of algorithms in e ect op erate b y collecting and solving the sim ultaneous equilib rium equations , , and . Without an expressly distributed form ulation , ho w ev er ,these tec hniques ma y violate the decen tralization considerations underlying our distributedproblem solving con text . This is quite acceptable for the purp oses these algorithms w ereoriginally designed , namely to analyze existing decen tralized structures , suc h as transp orta tion industries or ev en en tire economies Sho v en Whalley , . But b ecause our purp oseis to implement a distributed system , w e m ust ob ey c omputational distributivit y constrain tsnot relev an t to the usual purp oses of applied general equilibri um analysis . In general , ex plicitly examining the space of commo dit y bundle allo cations in the searc h for equilibriumundercuts our original motiv e for decomp osing complex activities in to consumption andpro duction of separate go o ds . Oriented Pr ogrammingAnother imp ortan t constrain t is that in ternal details of the agen ts state suc h as utilit yor pro duction functions and bidding p olicy should b e considered priv ate in order to maxi mize mo dularit y and p ermit inclusion of agen ts not under the designers direct con trol . Aconsequence of this is that computationally exploiting global prop erties arising from sp e cial features of agen ts w ould not generally b e p ermissible for our purp oses . F or example ,the constrain t that pro ts b e zero is a consequence of comp etitiv e b eha vior and constan t returns pro duction tec hnology . Since information ab out the form of the tec hnology andbidding p olicy is priv ate to pro ducer agen ts , it could b e considered c heating to em b ed thezero pro t condition in to the equilibrium deriv ation pro cedure .W alras s pro cedure is a decen tralized relaxation metho d , akin to the mec hanism oftatonnement originally sk etc hed b y L eon W alras to explain ho w prices migh t b e deriv ed .In the basic tatonnemen t metho d , w e b egin with an initial v ector of prices , p . The agen tsdetermine their demands at those prices b y solving their corresp onding constrained op timization problems , and rep ort the quan tities demanded to the auctioneer . Based onthese rep orts , the auctioneer iterativ ely adjusts the prices up or do wn as there is an excessof demand or supply , resp ectiv ely . F or instance , an adjustmen t prop ortional to the excesscould b e mo deled b y the di erence equationpt pt nXi xi BnZr nXi ei If the sequence p p con v erges , then the excess demand in eac h mark et approac hes zero ,and the result is a comp etitiv e equilibrium . It is w ell kno wn , ho w ev er , that tatonnemen tpro cesses do not con v erge to equilibrium in general Scarf , . The class of economies inwhic h tatonnemen t w orks are those with so called stable equilibria Hic ks , . A su cien tcondition for stabilit y is gr oss substitutability Arro w Hurwicz , that if the pricefor one go o d rises , then the net demands for the other go o ds do not decrease . In tuitiv ely ,gross substitutabilit y will b e violated when there are c omplementarities in preferences ortec hnologies suc h that reduced consumption for one go o d will cause reduced consumptionin others as w ell Sam uelson , . . W ALRAS Bidding Proto colThe metho d emplo y ed b y w alras successiv ely computes an equilibrium price in eac h sep arate mark et , in a manner detailed b elo w . Lik e tatonnemen t , it in v olv es an iterativ e ad justmen t of prices based on reactions of the agen ts in the mark et . Ho w ev er , it di ers fromtraditional tatonnemen t pro cedures in that agen ts submit supply and demand curvesrather than single p oin t quan tities for a particular price , and the auction adjusts in dividual prices to clear , rather than adjusting the en tire price v ector b y some incremen t usually a function of summary statistics suc h as excess demand . alras asso ciates an auction with eac h distinct go o d . Agen ts act in the mark et b ysubmitting bids to auctions . In w alras , bids sp ecify a corresp ondence b et w een prices and . This general approac h is called pr o gr essive e quilibr ation b y Dafermos and Nagurney , who appliedit to a particular transp ortation net w ork equilibriu m problem . Although this mo del of mark et dynamicsdo es not app ear to ha v e b een in v estigated v ery extensiv ely in general equil ib riu m theory , it do es seemto matc h the kind of price adjustmen t pro cess en visioned b y Hic ks in his pioneering study of dynamicsand stabilit y Hic ks , . tities of the go o d that the agen t o ers to demand or supply . The bid for a particulargo o d corresp onds to one dimension of the agen t s optimal demand , whic h is parametrizedb y the prices for all relev an t go o ds . Let xi p b e the solution to equation or , asappropriate , for prices p . A w alras agen t bids for go o d j under the assumption that pricesfor the remaining go o ds are xed at their curren t v alues , p . F ormally , agen t i s bid forgo o d j is a function xi j ! , from prices to quan tities satisfyingxi j pj xi pj p j where the subscript j on the righ t hand side selects the quan tit y demanded of go o d j fromthe o v erall demand v ector . The agen t computes and sends this function enco ded in an y ofa v ariet y of formats to the auction for go o d j .Giv en bids from all in terested agen ts , the auction deriv es a mark et clearing price , atwhic h the quan tit y demanded balances that supplied , within some presp eci ed tolerance .This clearing price is simply the zero crossing of the aggr e gate demand function , whic h is thesum of the demands from all agen ts . Suc h a zero crossing will exist as long as the aggregatedemand is su cien tly w ell b eha v ed , in particular , if it is con tin uous and decreasing in price .Gross substitutabilit y , along with the classical conditions for existence of equilibrium , issu cien t to ensure the existence of a clearing price at an y stage of the bidding proto col .W alras calculates the zero crossing of the aggregate demand function via binary searc h .If aggregate demand is not w ell b eha v ed , the result of the auction ma y b e a non clearingprice .When the curren t price is clearing with resp ect to the curren t bids , w e sa y the mark etfor that commo dit y is in equilibrium . W e sa y that an agen t is in equilibrium if its set ofoutstanding bids corresp onds to the solution of its optimization problem at the going prices .If all the agen ts and commo dit y mark ets are in equilibriu m , the allo cation of go o ds dictatedb y the auction results is a comp etitiv e equilibriu m .Figure presen ts a sc hematic view of the w alras bidding pro cess . There is an auctionfor eac h distinct go o d , and for eac h agen t , a link to all auctions in whic h it has an in terest .There is also a tote b oard of curren t prices , k ept up to date b y the v arious auctions . Inthe curren t implemen tation the tote b oard is a global data structure , ho w ev er , since pricec hange noti cations are explicitly transmitted to in terested agen ts , this cen tral informationcould b e easily disp ensed with .Eac h agen t main tains an agenda of bid tasks , sp ecifying the mark ets in whic h it m ustup date its bid or compute a new one . In Figure , agen t Ai has p ending tasks to submitbids to auctions G , G , and G . The bidding pro cess is highly distributed , in that eac hagen t need comm unicate directly only with the auctions for the go o ds of in terest those inthe domain of its utilit y or pro duction function , or for whic h it has nonzero endo wmen ts .Eac h of these in teractions concerns only a single go o d auctions nev er co ordinate with eac hother . Agen ts need not negotiate directly with other agen ts , nor ev en kno w of eac h other sexistence .As new bids are receiv ed at auction , the previously computed clearing price b ecomesobsolete . P erio dically , eac h auction computes a new clearing price if an y new or up datedbids ha v e b een receiv ed and p osts it on the tote b oard . When a price is up dated , thisma y in v alidate some of an agen t s outstanding bids , since these w ere computed under theassumption that prices for remaining go o ds w ere xed at previous v alues . On nding out Oriented Pr ogramming Gk Ai An Task Agenda , , pktote board Figure W alras s bidding pro cess . Gj denotes the auction for the j th go o d , and Ai thei th trading agen t . An item j on the task agenda denotes a p ending task tocompute and submit a bid for go o d j .ab out a price c hange , an agen t augmen ts its task agenda to include the p oten tially a ectedbids .A t all times , w alras main tains a v ector of going prices and quan tities that w ould b eexc hanged at those prices . While the agen ts ha v e nonempt y bid agendas or the auctions newbids , some or all go o ds ma y b e in disequilib rium . When all auctions clear and all agendasare exhausted , ho w ev er , the econom y is in comp etitiv e equilibriu m up to some n umerictolerance . Using a recen t result of Milgrom and Rob erts , Theorem , it can b esho wn that the condition su cien t for con v ergence of tatonnemen t gross substitutabilit y is also su cien t for con v ergence of w alras s price adjustmen t pro cess . The k ey observ ationis that in progressiv e equilibration sync hronous or not the price at eac h time is based onsome set of previous supply and demand bids .Although I ha v e no precise results to this e ect , the computational e ort required forcon v ergence to a xed tolerance seems highly sensitiv e to the n um b er of go o ds , and m uc hless so to the n um b er of agen ts . Eydeland and Nagurney ha v e analyzed in detailthe con v ergence pattern of progressiv e equilibration algorithms related to w alras for par ticular sp ecial cases , and found roughly linear gro wth in the n um b er of agen ts . Ho w ev er ,general conclusions are di cult to dra w as the cost of computing the equilibrium for a par ticular computational econom y ma y w ell dep end on the in terconnectedness and strength ofin teractions among agen ts and go o ds . . Mark et Orien ted ProgrammingAs describ ed ab o v e , w alras pro vides facilities for sp ecifying mark et con gurations andcomputing their comp etitiv e equilibriu m . W e can also view w alras as a programmingen vironmen t for decen tralized resource allo cation pro cedures . The en vironmen t pro videsconstructs for sp ecifying v arious sorts of agen ts and de ning their in teractions via their to common commo dities . After setting up the initial con guration , the mark etcan b e run to determine the equilibrium lev el of activities and distribution of resourcesthroughout the econom y .T o cast a distributed planning problem as a mark et , one needs to iden tify the go o dstraded , the agen ts trading , and the agen ts bidding b eha vior . These design stepsare serially dep enden t , as the de nition of what constitutes an exc hangeable or pro duciblecommo dit y sev erely restricts the t yp e of agen ts that it mak es sense to include . And asmen tioned ab o v e , sometimes w e ha v e to tak e as xed some real w orld agen ts and go o dspresen ted as part of the problem sp eci cation . Once the con guration is determined , itmigh t b e adv an tageous to adjust some general parameters of the bidding proto col . Belo w , Iillustrate the design task with a w alras form ulation of the m ulticommo dit y o w problem . . Implemen tationW alras is implemen ted in Common Lisp and the Common Lisp Ob ject System CLOS .The curren t v ersion pro vides basic infrastructure for running computational economies ,including the underlying bidding proto col and a library of CLOS classes implemen ting av ariet y of agen t t yp es . The ob ject orien ted implemen tation supp orts incremen tal dev elop men t of mark et con gurations . In particular , new t yp es of agen ts can often b e de ned assligh t v ariations on existing t yp es , for example b y mo difying isolated features of the demandb eha vior , bidding strategies e .g . , managemen t of task agenda , or bid format . W ang andSlagle presen t a detailed case for the use of ob ject orien ted languages to represen tgeneral equilibri um mo dels . Their prop osed system is similar to w alras with resp ect toform ulation , although it is designed as an in terface to con v en tional mo del solving pac k ages ,rather than to supp ort a decen tralized computation of equilibriu m directly .Although it mo dels a distributed system , w alras runs serially on a single pro cessor .Distribution constrain ts on information and comm unication are enforced b y programmingand sp eci cation con v en tions rather than b y fundamen tal mec hanisms of the soft w are en vironmen t . Async hron y is sim ulated b y randomizing the bidding sequences so that agen tsare called on unpredictably . Indeed , arti cial sync hronization can lead to an undesirableoscillation in the clearing prices , as agen ts collectiv ely o v ercomp ensate for im balances inthe preceding iteration . curren t exp erimen tal system runs transp ortation mo dels of the sort describ ed b e lo w , as w ell as some abstract exc hange and pro duction economies with parametrized utilit yand pro duction functions including the exp ository examples of Scarf and Sho v enand Whalley . Customized tuning of the basic bidding proto col has not b een nec essary . In the pro cess of getting w alras to run on these examples , I ha v e added somegenerically useful building blo c ks to the class libraries , but m uc h more is required to ll outa comprehensiv e taxonom y of agen ts , bidding strategies , and auction p olicies . . In some formal dynamic mo dels Hub erman , Kephart , Hogg , Hub erman , , homogeneousagen ts c ho ose instan taneousl y optimal p olicies without accoun ting for others that are sim ultaneousl ymaking the same c hoice . Since the v alue of a particular c hoice v aries in v ersely with the n um b er of agen tsc ho osing it , this dela y ed feedbac k ab out the others decisions leads to systematic errors , and henceoscillatio n . I ha v e also observ ed this phenomenon empirically in a sync hronized v ersion of W ALRAS .By eliminating the sync hronization , agen ts tend to w ork on di eren t mark ets at an y one time , and hencedo not su er as m uc h from dela y ed feedbac k ab out prices . Oriented Pr ogramming . Example Multicomm o dit y Flo wIn a simple v ersion of the m ulticommo dit y o w problem , the task is to allo cate a giv enset of cargo mo v emen ts o v er a giv en transp ortation net w ork . The transp ortation net w orkis a collection of lo cations , with links directed edges iden tifying feasible transp ortationop erations . Asso ciated with eac h link is a sp eci cation of the cost of mo ving cargo along it .W e supp ose further that the cargo is homogeneous , and that amoun ts of cargo are arbitrarilydivisible . A mo v emen t requiremen t asso ciates an amoun t of cargo with an origin destinationpair . The planning problem is to determine the amoun t to transp ort on eac h link in order tomo v e all the cargo at the minim um cost . This simpli cation ignores salien t asp ects of realtransp ortation planning . F or instance , this mo del is completely atemp oral , and is hencemore suitable for planning steady state o ws than for planning dynamic mo v emen ts .A distributed v ersion of the problem w ould decen tralize the resp onsibilit y for trans p orting separate cargo elemen ts . F or example , planning mo dules corresp onding to geo graphically or organizationally disparate units migh t arrange the transp ortation for cargowithin their resp ectiv e spheres of authorit y . Or decision making activit y migh t b e decom p osed along hierarc hical lev els of abstraction , gross functional c haracteristics , or accordingto an y other relev an t distinction . This decen tralization migh t result from real distributionof authorit y within a h uman organization , from inheren t informational asymmetries andcomm unication barriers , or from mo dularit y imp osed to facilitate soft w are engineering .Consider , for example , the abstract transp ortation net w ork of Figure , tak en fromHark er . There are four lo cations , with directed links as sho wn . Consider t w o mo v e men t requiremen ts . The rst is to transp ort cargo from lo cation to lo cation , and thesecond in the rev erse direction . Supp ose w e wish to decen tralize authorit y so that separateagen ts called shipp ers decide ho w to allo cate the cargo for eac h mo v emen t . The rst ship p er decides ho w to split its cargo units b et w een the paths ! ! and ! ! ! ,while the second gures the split b et w een paths ! ! and ! ! ! . Note thatthe latter paths for eac h shipp er share a common resource the link ! . A simple net w ork from Hark er .Because of their o v erlapping resource demands , the shipp ers decisions app ear to b enecessarily in tert wined . In a congested net w ork , for example , the cost for transp orting aunit of cargo o v er a link is increasing in the o v erall usage of the link . A shipp er planningits cargo mo v emen ts as if it w ere the only user on a net w ork w ould th us underestimate itscosts and p oten tially misallo cate transp ortation resources . or the analysis of net w orks suc h as this , transp ortation researc hers ha v e dev elop edequilibrium concepts describing the collectiv e b eha vior of the shipp ers . In a system e qui librium , the o v erall transp ortation of cargo pro ceeds as if there w ere an omniscien t cen tralplanner directing the mo v emen t of eac h shipmen t so as to minimize the total aggregatecost of meeting the requiremen ts . In a user e quilibrium , the o v erall allo cation of cargomo v emen ts is suc h that eac h shipp er minimizes its o wn total cost , sharing prop ortionatelythe cost of shared resources . The system equilibrium is th us a global optim um , while theuser equilibrium corresp onds to a comp osition of lo cally optimal solutions to subproblems .There are also some in termediate p ossibilities , corresp onding to game theoretic equilibriumconcepts suc h as the Nash equilibrium , where eac h shipp er b eha v es optimally giv en thetransp ortation p olicies of the remaining shipp ers Hark er , . rom our p ersp ectiv e as designer of the distributed planner , w e seek a decen tralizationmec hanism that will reac h the system equilibriu m , or come as close as p ossible giv en thedistributed decision making structure . In general , ho w ev er , w e cannot exp ect to deriv e asystem equilibrium or globally optimal solution without cen tral con trol . Limits on co ordi nation and comm unication ma y prev en t the distributed resource allo cation from exploitingall opp ortunities and inhibiting agen ts from acting at cross purp oses . But under certainconditions decision making can indeed b e decen tralized e ectiv ely via mark et mec hanisms .General equilibri um analysis can help us to recognize and tak e adv an tage of these opp ortu nities .Note that for the m ulticommo dit y o w problem , there is an e ectiv e distributed solutiondue to Gallager . One of the mark et structures describ ed b elo w e ectiv ely mimics thissolution , ev en though Gallager s algorithm w as not form ulated expressly in mark et terms .The p oin t here is not to crac k a hitherto unsolv ed distributed optimization problem thoughthat w ould b e nice , but rather to illustrate a general approac h on a simply describ ed y etnon trivial task . . W ALRAS T ransp ortation Mark etIn this section , I presen t a series of three transp ortation mark et structures implemen ted inw alras . The rst and simplest mo del comprises the basic transp ortation go o ds and shipp eragen ts , whic h are augmen ted in the succeeding mo dels to include other agen t t yp es . Com parativ e analysis of the three mark et structures rev eals the qualitativ ely distinct economicand computational b eha viors realized b y alternate w alras con gurations . . Basic Shipp er Mo delThe resource of primary in terest in the m ulticommo dit y o w problem is mo v emen t of cargo .Because the v alue and cost of a cargo mo v emen t dep ends on lo cation , w e designate as adistinct go o d the capacit y on eac h origin destination pair in the net w ork see Figure . T ocapture the cost or input required to mo v e cargo , w e de ne another go o d denoting generictransp ortation resources . In a more concrete mo del , these migh t consist of v ehicles , fuel ,lab or , or other factors con tributing to transp ortation . . In the Nash solution , shipp ers correctly an ticipate the e ect of their o wn cargo mo v emen ts on the a v eragecost on eac h link . The resulting equilibriu m con v erges to the user equilibri um as the n um b er of shipp ersincreases and the e ect of an y individu al s b eha vior on prices diminishes Haurie Marcotte , . Oriented Pr ogrammingT o decen tralize the decision making , w e iden tify eac h mo v emen t requiremen t with adistinct shipp er agen t . These shipp ers , or consumers , ha v e an in terest in mo ving v ariousunits of cargo b et w een sp eci ed origins and destinations .The in terconnectedness of agen ts and go o ds de nes the mark et con guration . Figure the w alras con guration for the basic shipp er mo del corresp onding to the examplenet w ork of Figure . In this mo del there are t w o shipp ers , S and S , where Si j denotesa shipp er with a requiremen t to mo v e go o ds from origin i to destination j . Shipp ers connectto go o ds that migh t serv e their ob jectiv es in this case , mo v emen t along links that b elong tosome simple path from the shipp er s origin to its destination . In the diagram , Gi j denotesthe go o d represen ting an amoun t of cargo mo v ed o v er the link i ! j . G denotes the sp ecialtransp ortation resource go o d . Notice that the only go o ds of in terest to b oth shipp ers areG , for whic h they b oth ha v e endo wmen ts , and G , transp ortation on the link servingb oth origin destination pairs . ,,, ,, ,,, , W alras basic shipp er mark et con guration for the example transp ortation net w ork .The mo del w e emplo y for transp ortation costs is based on a net w ork with congestion ,th us exhibiting diseconomies of scale . In other w ords , the marginal and a v erage costs interms of transp ortation resources required are b oth increasing in the lev el of service on alink . Using Hark er s data , w e tak e costs to b e quadratic . The quadratic cost mo del is p osedsimply for concreteness , and do es not represen t an y substan tiv e claim ab out transp ortationnet w orks . The imp ortan t qualitativ e feature of this mo del and the only one necessaryfor the example to w ork is that it exhibits decreasing returns , a de ning c haracteristic ofcongested net w orks . Note also that Hark er s mo del is in terms of monetary costs , whereasw e in tro duce an abstract input go o d .Let ci j x denote the cost in transp ortation resources go o d G required to transp ortx units of cargo on the link from i to j . The complete cost functions are c x c x c x c x x x c x c x c x x x Finally , eac h shipp er s ob jectiv e is to transp ort units of cargo from its origin to itsdestination . the basic shipp er mo del , w e assume that the shipp ers pa y prop ortionately in unitsof G for the total cost on eac h link . This amoun ts to a p olicy of a v erage cost pricing .W e tak e the shipp er s ob jectiv e to b e to ship as m uc h as p ossible up to its mo v emen trequiremen t in the least costly manner . Notice that this ob jectiv e is not expressible interms of the consumer s optimization problem , equation , and hence this mo del is nottec hnically an instance of the general equilib rium framew ork .Giv en a net w ork with prices on eac h link , the c heap est cargo mo v emen t corresp onds tothe shortest path in the graph , where distances are equated with prices . Th us , for a giv enlink , a shipp er w ould prefer to ship its en tire quota on the link if it is on the shortest path ,and zero otherwise . In the case of ties , it is indi eren t among the p ossible allo cations . T obid on link i j , the shipp er can deriv e the threshold price that determines whether the linkis on a shortest path b y taking the di erence in shortest path distance b et w een the net w orkswhere link i j s distance is set to zero and in nit y , resp ectiv ely .In incremen tally c hanging its bids , the shipp er should also consider its outstanding bidsand the curren t prices . The v alue of reserving capacit y on a particular link is zero if itcannot get service on the other links on the path . Similarly , if it is already committed toshipping cargo on a parallel path , it do es not gain b y obtaining more capacit y ev en at alo w er price un til it withdra ws these other bids . , the actual demand p olicy ofa shipp er is to sp end its uncommitted income on the p oten tial o w increase deriv ed frommaxim um o w calculations it could obtain b y purc hasing capacit y on the giv en link . It iswilling to sp end up to the threshold v alue of the link , as describ ed ab o v e . This determinesone p oin t on its demand curv e . If it has some unsatis ed requiremen t and uncommittedincome it also indicates a willingness to pa y a lo w er price for a greater amoun t of capacit y .Boundary p oin ts suc h as this serv e to b o otstrap the econom y from the initial conditions itis t ypically the case that no individual link con tributes to o v erall o w b et w een the shipp er sorigin and destination . Finally , the demand curv e is completed b y a smo othing op erationon these p oin ts .Details of the b oundary p oin ts and smo othing op eration are rather arbitrary , and Imak e no claim that this particular bidding p olicy is ideal or guaran teed to w ork for a broadclass of problems . This crude approac h app ears su cien t for the presen t example and somesimilar ones , as long as the shipp ers p olicies b ecome more accurate as the prices approac hequilibrium .W alras successfully computes the comp etitiv e equilibrium for this example , whic hin the case of the basic shipp er mo del corresp onds to a user equilibrium UE for thetransp ortation net w ork . In the UE for the example net w ork , eac h shipp er sends . unitsof cargo o v er the shared link ! , and the remaining cargo o v er the direct link fromlo cation to the destination . This allo cation is ine cien t , as its total cost is resource . Ev en if a shipp er could sim ultaneousl y up date its bids in all mark ets , it w ould not b e a go o d idea to doso here . A comp etitiv e shipp er w ould send all its cargo on the least costly path , neglecting the p ossibili t ythat this demand ma y increase the prices so that it is no longer c heap est . The outstanding bids pro videsome sensitivit y to this e ect , as they are functions of price . But they cannot resp ond to c hanges inman y prices at once , and th us the p olicy of up dating all bids sim ultaneousl y can lead to p erp etualoscillatio n . F or example , in the net w ork considered here , the unique comp etitiv e equilibriu m has eac hshipp er splitting its cargo b et w een t w o di eren t paths . P olicies allo cating all cargo to one path can nev erlead to this result , and hence con v ergence to comp etitiv e equilibri um dep ends on the incremen talit y ofbidding b eha vior . Oriented Pr ogrammingunits , whic h is somewhat greater than the global minim um cost solution of units . Ineconomic terms , the cause of the ine ciency is an externalit y with resp ect to usage of theshared link . Because the shipp ers are e ectiv ely c harged a v erage cost whic h in the caseof decreasing returns is b elo w marginal cost the price they face do es not re ect the fullincremen tal so cial cost of additional usage of the resource . In e ect , incremen tal usage ofthe resource b y one agen t is subsidized b y the other . The steep er the decreasing returns ,the more the agen ts ha v e an incen tiv e to o v erutilize the resource . is a simple exampleof the classic tr age dy of the c ommons .The classical remedy to suc h problems is to in ternalize the externalit y b y allo catingo wnership of the shared resource to some decision mak er who has the prop er incen tiv es touse it e cien tly . W e can implemen t suc h a solution in w alras b y augmen ting the mark etstructure with another t yp e of agen t . . Carrier Agen tsW e extend the basic shipp er mo del b y in tro ducing c arriers , agen ts of t yp e pro ducer whoha v e the capabilit y to transp ort cargo units o v er sp eci ed links , giv en v arying amoun tsof transp ortation resources . In the mo del describ ed here , w e asso ciate one carrier witheac h a v ailable link . The pro duction function for eac h carrier is simply the in v erse of thecost function describ ed ab o v e . T o ac hiev e a global mo v emen t of cargo , shipp ers obtaintransp ortation services from carriers in exc hange for the necessary transp ortation resources .Let Ci j denote the carrier that transp orts cargo from lo cation i to lo cation j . Eac hcarrier Ci j is connected to the auction for Gi j , its output go o d , along with G its inputin the pro duction pro cess . Shipp er agen ts are also connected to G , as they are endo w edwith transp ortation resources to exc hange for transp ortation services . Figure depicts thew alras mark et structure when carriers are included in the econom y . , C , ,,, ,, , , ,,,, , , , W alras mark et con guration for the example transp ortation net w ork in an econ om y with shipp ers and carriers . . Av erage cost pricing is p erhaps the most common mec hanism for allo cating costs of a shared resource .Shenk er p oin ts out problems with this sc heme with resp ect to b oth e ciency and strategicb eha vior in the con text of allo cating access to congested computer net w orks , a problem analogous toour transp ortation task . the case of a decreasing returns tec hnology , the pro ducer s carrier s optimizationproblem has a unique solution . The optimal lev el of activit y maximizes rev en ues min us costs ,whic h o ccurs at the p oin t where the output price equals marginal cost . Using this result ,carriers submit supply bids sp ecifying transp ortation services as a function of link prices with resource price xed , and demand bids sp ecifying required resources as a function ofinput prices for activit y lev el computed with output price xed .F or example , consider carrier C . A t output price p and input price p , the carrier spro t isp y BnZr p c y where y is the lev el of service it c ho oses to supply . Giv en the cost function ab o v e , thisexpression is maximized at y p BnZr p p . T aking p as xed , the carrier submits asupply bid with y a function of p . On the demand side , the carrier tak es p as xed andsubmits a demand bid for enough go o d G to pro duce y , where y is treated as a functionof p .With the revised con guration and agen t b eha viors describ ed , w alras deriv es the sys tem equilibrium SE , that is , the cargo allo cation minimizing o v erall transp ortation costs .The deriv ed cargo mo v emen ts are correct to within in bidding cycles , and to in , where in eac h cycle ev ery agen t submits an a v erage of one bid to one auction . Thetotal cost in units of G , its division b et w een shipp ers exp enditures and carriers pro ts ,and the equilibrium prices are presen ted in T able . Data for the UE solution of the ba sic shipp er mo del are included for comparison . That the decen tralized pro cess pro duces aglobal optim um is p erfectly consisten t with comp etitiv e b eha vior the carriers price theiroutputs at marginal cost , and the tec hnologies are con v ex .pricing TC exp ense pro t p p p p p p p SE . . . . . . . C UE . . . . . . . able Equilibria deriv ed b y w alras for the transp ortation example . TC , MC , and A Cstand for total , marginal , and a v erage cost , resp ectiv ely . TC shipp er exp ense BnZrcarrier pro t .As a simple c hec k on the prices of T able , w e can v erify that p p p andp p p . Both these relationships m ust hold in equilibrium assuming all links ha v enonzero mo v emen ts , else a shipp er could reduce its cost b y rerouting some cargo . Indeed ,for a simple small and symmetric example suc h as this , it is easy to deriv e the equilibriumanalytically using global equations suc h as these . But as argued ab o v e , it w ould b e improp erto exploit these relationships in the implemen tation of a truly distributed decision pro cess .The lesson from this exercise is that w e can ac hiev e qualitativ ely distinct results b y sim ple v ariations in the mark et con guration or agen t p olicies . F rom our designers p ersp ectiv e ,w e prefer the con guration that leads to the more transp ortation e cien t SE . Examinationof T able rev eals that w e can ac hiev e this result b y allo wing the carriers to earn nonzeropro ts economically sp eaking , these are really ren ts on the xed factor represen ted b y the Oriented Pr ogrammingcongested c hannel and redistributing these pro ts to the shipp ers to co v er their increasedexp enditures . In the mo del of general equilibrium with pro duction , consumers o wn sharesin the pro ducers pro ts . This closes the lo op so that all v alue is ultimately realized inconsumption . W e can sp ecify these shares as part of the initial con guration , just lik e theendo wmen t . In this example , w e distribute the pro ts ev enly b et w een the t w o shipp ers . . Arbitrageur Agen tsThe preceding results demonstrate that w alras can indeed implemen t a decen tralizedsolution to the m ulticommo dit y o w problem . But the mark et structure in Figure is notas distributed as it migh t b e , in that all agen ts are connected to G , and shipp ersneed to kno w ab out all links p oten tially serving their origin destination pair . The rst ofthese concerns is easily remedied , as the c hoice of a single transp ortation resource go o d w ascompletely arbitrary . F or example , it w ould b e straigh tforw ard to consider some collectionof resources e .g . , fuel , lab or , v ehicles , and endo w eac h shipp er with only subsets of these .The second concern can also b e addressed within w alras . T o do so , w e in tro duce y etanother sort of pro ducer agen t . These new agen ts , called arbitr ageurs , act as sp ecializedmiddlemen , monitoring isolated pieces of the net w ork for ine ciencies . An arbitrageurAi j k pro duces transp ortation from i to k b y buying capacit y from i to j and j to k . Itspro duction function simply sp eci es that the amoun t of its output go o d , Gi k , is equal tothe minim um of its t w o inputs , Gi j and Gj k . If pi j pj k pi k , then its pro ductionis pro table . Its bidding p olicy in w alras is to incremen t its lev el of activit y at eac hiteration b y an amoun t prop ortional to its curren t pro tabilit y or decremen t prop ortionalto the loss . Suc h incremen tal b eha vior is necessary for all constan t returns pro ducers inw alras , as the pro t maximization problem has no in terior solution in the linear case . o incorp orate arbitrageurs in to the transp ortation mark et structure , w e rst create newgo o ds corresp onding to the transitiv e closure of the transp ortation net w ork . In the examplenet w ork , this leads to go o ds for ev ery lo cation pair . Next , w e add an arbitrageur Ai j k forev ery triple of lo cations suc h that i ! j is in the original net w ork , and there exists apath from j to k that do es not tra v erse lo cation i . These t w o conditions ensure that thereis an arbitrageur Ai j k for ev ery pair i k connected b y a path with more than one link , andeliminate some com binations that are either redundan t or clearly unpro table .The revised mark et structure for the running example is depicted in Figure , with newgo o ds and agen ts shaded . Some go o ds and agen ts that are inactiv e in the mark et solutionha v e b een omitted from the diagram to a v oid clutter .Notice that in Figure the connectivit y of the shipp ers has b een signi can tly decreased ,as the shipp ers no w need b e a w are of only the go o d directly serving their origin destinationpair . This dramatically simpli es their bidding problem , as they can a v oid all analysis of theprice net w ork . The structure as a whole seems more distributed , as no agen t is concernedwith more than three go o ds . . Without suc h a restriction on its bidding b eha vior , the comp etitiv e constan t returns pro ducer w ouldc ho ose to op erate at a lev el of in nit y or zero , dep ending on whether its activit y w ere pro table orunpro table at the going prices at break ev en , the pro ducer is indi eren t among all lev els . Thisw ould lead to p erp etual oscillatio n , a problem noticed and solv ed b y P aul Sam uelson in when heconsidered the use of mark et mec hanisms to solv e linear programming problems Sam uelson , . ,, ,, ,, , ,, ,,,, ,,, C C C SG G GA , , , ,, , ,,, , The revised w alras mark et con guration with arbitrageurs .Despite the simpli ed shipp er b eha vior , w alras still con v erges to the SE , or optimalsolution , in this con guration . Although the resulting allo cation of resources is iden tical ,a qualitativ e c hange in mark et structure here corresp onds to a qualitativ e c hange in thedegree of decen tralization .In fact , the b eha vior of w alras on the mark et con guration with arbitrageurs is vir tually iden tical to a standard distributed algorithm Gallager , for m ulticommo dit y o w minim um dela y on comm unication net w orks . In Gallager s algorithm , distributedmo dules expressly di eren tiate the cost function to deriv e the marginal cost of increasing o w on a comm unication link . Flo ws are adjusted up or do wn so to equate the marginalcosts along comp eting subpaths . This pro cedure pro v ably con v erges to the optimal solutionas long as the iterativ e adjustmen t parameter is su cien tly small . Similarly , con v ergencein w alras for this mo del requires that the arbitrageurs do not adjust their activit y lev elsto o quic kly in resp onse to pro t opp ortunities or loss situations . . SummaryThe preceding sections ha v e dev elop ed three progressiv ely elab orate mark et con gurationsfor the m ulticommo dit y o w problem . T able summarizes the size and shap e of the con guration for a transp ortation net w ork with V lo cations and E links , and M mo v emen trequiremen ts . The basic shipp er mo del results in the user equilibrium , while b oth of theaugmen ted mo dels pro duce the globally optimal system equilibrium . The carrier mo del re quires E new pro ducer agen ts to pro duce the sup erior result . The arbitrageur mo del addsO V E more pro ducers and p oten tially some new go o ds as w ell , but reduces the n um b er ofgo o ds of in terest to an y individual agen t from O E to a small constan t .These mark et mo dels represen t three qualitativ ely distinct p oin ts on the sp ectrum ofp oten tial con gurations . Hybrid mo dels are also conceiv able , for example , where a partialset of arbitrageurs are included , p erhaps arranged in a hierarc h y or some other regular Oriented Pr ogrammingmo del go o ds shipp ers carriers arbitrageursBasic shipp er E M O E plus carriers E M O E E plus arbitrageurs O V M E O V E T able Num b ers of go o ds and agen ts for the three mark et con gurations . F or eac h t yp e ofagen t , the gure in brac k ets indicates the n um b er of go o ds on whic h eac h individualbids .structure . I w ould exp ect suc h con gurations to exhibit b eha viors in termediate to thesp eci c mo dels studied here , with resp ect to b oth equilibriu m pro duced and degree ofdecen tralization . . LimitationsOne serious limitation of w alras is the assumption that agen ts act comp etitiv ely . Asmen tioned ab o v e , this b eha vior is rational when there are man y agen ts , eac h small withresp ect to the o v erall econom y . Ho w ev er , when an individual agen t is large enough to a ectprices signi can tly i .e . , p ossesses mark et p o w er , it forfeits utilit y or pro ts b y failing totak e this in to accoun t . There are t w o approac hes to w ard alleviating the restriction of p erfectcomp etition in a computational econom y . First , w e could simply adopt mo dels of imp erfectcomp etition , p erhaps based on sp eci c forms of imp erfection e .g . , spatial monop olisticcomp etition or on general game theoretic mo dels . Second , as arc hitects w e can con gurethe mark ets to promote comp etitiv e b eha vior . F or example , decreasing the agen t s grain sizeand enabling free en try of agen ts should enhance the degree of comp etition . P erhaps mostin terestingly , b y con trolling the agen ts kno wledge of the mark et structure via standardinformation encapsulation tec hniques , w e can degrade their abilit y to exploit whatev ermark et p o w er they p ossess . Uncertain t y has b een sho wn to increase comp etitiv eness amongrisk a v erse agen ts in some formal bidding mo dels McAfee McMillan , , and in acomputational en vironmen t w e ha v e substan tial con trol o v er this uncertain t y .The existence of comp etitiv e equilibria and e cien t mark et allo cations also dep endscritically on the assumption of nonincreasing returns to scale . Although congestion is areal factor in transp ortation net w orks , for example , for man y mo des of transp ort thereare often other economies of scale and densit y that ma y lead to returns that are increasingo v erall Hark er , . Note that strategic in teractions , increasing returns , and other factorsdegrading the e ectiv eness of mark et mec hanisms also inhibit decen tralization in general ,and so w ould need to b e addressed directly in an y approac h .Ha ving cast w alras as a general en vironmen t for distributed planning , it is natural toask ho w univ ersal mark et orien ted programming is as a computational paradigm . W e canc haracterize the computational p o w er of this mo del easily enough , b y corresp ondence to theclass of con v ex programming problems represen ted b y economies satisfying the classical con ditions . Ho w ev er , the more in teresting issue is ho w w ell the conceptual framew ork of mark et corresp onds to the salien t features of distributed planning problems . Althoughit is to o early to mak e a de nitiv e assertion ab out this , it seems clear that man y planningtasks are fundamen tally problems in resource allo cation , and that the units of distributionoften corresp ond w ell with units of agency . Economics has b een the most prominen t andarguably the most successful approac h to mo deling resource allo cation with decen tralizeddecision making , and it is reasonable to supp ose that the concepts economists nd usefulin the so cial con text will pro v e similarly useful in our analogous computational con text .Of course , just as economics is not ideal for analyzing all asp ects of so cial in teraction , w eshould exp ect that man y issues in the organization of distributed planning will not b e w ellaccoun ted for in this framew ork .Finally , the transp ortation net w ork mo del presen ted here is a highly simpli ed v er sion of the actual planning problem for this domain . A more realistic treatmen t w ouldco v er m ultiple commo dit y t yp es , discrete mo v emen ts , temp oral exten t , hierarc hical net w ork structure , and other critical features of the problem . Some of these ma y b e capturedb y incremen tal extensions to the simple mo del , p erhaps applying elab orations dev elop edb y the transp ortation science comm unit y . F or example , man y transp ortation mo dels in cluding Hark er s more elab orate form ulation Hark er , allo w for v ariable supply anddemand of the commo dities and more complex shipp er carrier relationships . Concepts ofspatial price equilibrium , based on mark ets for commo dities in eac h lo cation , seem to o erthe most direct approac h to w ard extending the transp ortation mo del within w alras . . Related W ork . Distributed OptimizationThe tec hniques and mo dels describ ed here ob viously build on m uc h w ork in economics ,transp ortation science , and op erations researc h . The in tended researc h con tribution here isnot to these elds , but rather in their application to the construction of a computationalframew ork for decen tralized decision making in general . Nev ertheless , a few w ords are inorder regarding the relation of the approac h describ ed here to extan t metho ds for distributedoptimization .Although the most elab orate w alras mo del is essen tially equiv alen t to existing algo rithms for distributed m ulticommo dit y o w Bertsek as Tsitsiklis , Gallager , ,the mark et framew ork o ers an approac h to w ard extensions b ey ond the strict scop e of thisparticular optimization problem . F or example , w e could reduce the n um b er of arbitrageurs ,and while this w ould eliminate the guaran tees of optimalit y , w e migh t still ha v e a reasonableexp ectation for graceful degradation . Similarly , w e could realize conceptual extensions tothe structure of the problem , suc h as distributed pro duction of go o ds in addition to trans p ortation , b y adding new t yp es of agen ts . F or an y giv en extension , there ma y v ery w ell b ea customized distributed optimization algorithm that w ould outp erform the computationalmark et , but coming up with this algorithm w ould lik ely in v olv e a completely new analysis .Nev ertheless , it m ust b e stated that sp eculations regarding the metho dological adv an tagesof the mark et orien ted framew ork are indeed just sp eculations at this p oin t , and the relativ e exibilit y of applications programming in this paradigm m ust ultimately b e demonstratedempirically . Oriented Pr ogrammingFinally , there is a large literature on decomp osition metho ds for mathematical program ming problems , whic h is p erhaps the most common approac h to distributed optimization .Man y of these tec hniques can themselv es b e in terpreted in economic terms , using the closerelationship b et w een prices and Lagrange m ultipliers . Again , the main distinction of theapproac h adv o cated here is conceptual . Rather than taking a global optimization prob lem and decen tralizing it , our aim is to pro vide a framew ork for form ulating a task in adistributed manner in the rst place . . Mark et Based ComputationThe basic idea of applying economic mec hanisms to co ordinate distributed problem solvingis not new to the AI comm unit y . Starting with the con tract net Da vis Smith , ,man y ha v e found the metaphor of mark ets app ealing , and ha v e built systems organizedaround mark ets or mark et lik e mec hanisms Malone , Fik es , Gran t , Ho w ard , . Theoriginal con tract net actually did not include an y economic notions at all in its biddingmec hanism , ho w ev er , recen t w ork b y Sandholm has sho wn ho w cost and price canb e incorp orated in the con tract net proto col to mak e it more lik e a true mark et mec ha nism . Miller and Drexler Drexler Miller , Miller Drexler , ha v e examinedthe mark et based approac h in depth , presen ting some underlying rationale and addressingsp eci c issues salien t in a computational en vironmen t . W aldspurger , Hogg , Hub erman ,Kephart , and Stornetta in v estigated the concepts further b y actually implemen tingmark et mec hanisms to allo cate computational resources in a distributed op erating system .Researc hers in distributed computing Kurose Simha , ha v e also applied sp ecializedalgorithms based on economic analyses to sp eci c resource allo cation problems arising indistributed systems . F or further remarks on this line of w ork , see W ellman , .Recen tly , Ku w abara and Ishida ha v e exp erimen ted with demand adjustmen tmetho ds for a task v ery similar to the m ulticommo dit y o w problem considered here . Onesigni can t di erence is that their metho d w ould consider eac h path in the net w ork as aseparate resource , whereas the mark et structures here manipulate only links or lo cationpairs . Although they do not cast their system in a comp etitiv e equili briu m framew ork , theresults are congruen t with those obtained b y w alras .W alras is distinct from these prior e orts in t w o primary resp ects . First , it is con structed expressly in terms of concepts from general equilibrium theory , to promote math ematical analysis of the system and facilitate the application of economic principles toarc hitectural design . Second , w alras is designed to serv e as a general programming en vi ronmen t for implemen ting computational economies . Although not dev elop ed sp eci callyto allo cate computational resources , there is no reason these could not b e included in mar k et structures con gured for particular application domains . Indeed , the idea of groundingmeasures of the v alue of computation in real w orld v alues e .g . , cargo mo v emen ts follo wsnaturally from the general equilibri um view of in terconnected mark ets , and is one of themore exciting prosp ects for future applications of w alras to distributed problem solving .Organizational theorists ha v e studied mark ets as mec hanisms for co ordinating activitiesand allo cating resources within rms . F or example , Malone mo dels informationrequiremen ts , exibilit y and other p erformance c haracteristics of a v ariet y of mark et andnon mark et structures . In his terminology , w alras implemen ts a c entr alize d market , where allo cation of eac h go o d is mediated b y an auction . Using suc h mo dels , w e can determinewhether this gross form of organization is adv an tageous , giv en information ab out the costof comm unication , the exibilit y of individual mo dules , and other related features . In thispap er , w e examine in greater detail the co ordination pro cess in computational mark ets ,elab orating on the criteria for designing decen tralized allo cation mec hanisms . W e tak e thedistributivit y constrain t as exogenously imp osed when the constrain t is relaxable , b othorganizational and economic analysis illuminate the tradeo s underlying the mec hanismdesign problem .Finally , mark et orien ted programming shares with Shoham s agent oriente d pr o gr am ming Shoham , the view that distributed problem solving mo dules are b est designedand understo o d as rational agen ts . The t w o approac hes supp ort di eren t agen t op erations transactions v ersus sp eec h acts , adopt di eren t rationalit y criteria , and emphasize dif feren t agen t descriptors , but are ultimately aimed at ac hieving the same goal of sp ecifyingcomplex b eha vior in terms of agen t concepts e .g . , b elief , desire , capabilit y and so cial orga nizations . Com bining individual rationalit y with la ws of so cial in teraction pro vides p erhapsthe most natural approac h to generalizing New ell s kno wledge lev el analysis idea New ell , to distributed computation . . ConclusionIn summary , w alras represen ts a general approac h to the construction and analysis ofdistributed planning systems , based on general equilibriu m theory and comp etitiv e mec h anisms . The approac h w orks b y deriving the comp etitiv e equilibrium corresp onding to aparticular con guration of agen ts and commo dities , sp eci ed using w alras s basic con structs for de ning computational mark et structures . In a particular realization of thisapproac h for a simpli ed form of distributed transp ortation planning , w e see that qualita tiv e di erences in economic structure e .g . , cost sharing among shipp ers v ersus o wnershipof shared resources b y pro t maximizing carriers corresp ond to qualitativ ely distinct b e ha viors user v ersus system equilibrium . This exercise demonstrates that careful design ofthe distributed decision structure according to economic principles can sometimes lead toe ectiv e decen tralization , and that the b eha viors of alternativ e systems can b e meaningfullyanalyzed in economic terms .The con tribution of the w ork rep orted here lies in the idea of mark et orien ted program ming , an algorithm for distributed computation of comp etitiv e equilibria of computationaleconomies , and an initial illustration of the approac h on a simple problem in distributedresource allo cation . A great deal of additional w ork will b e required to understand the pre cise capabilities and limitations of the approac h , and to establish a broader metho dologyfor con guration of computational economies .Ac kno wledgemen tsThis pap er is a revised and extended v ersion of W ellman , . I ha v e b ene ted fromdiscussions of computational economies with man y colleagues , and w ould lik e to thank inparticular Jon Do yle , Ed Durfee , Eli Gafni , Daphne Koller , T racy Mullen , Anna Nagurney , Oriented Pr ogrammingScott Shenk er , Y oa v Shoham , Hal V arian , Carl W aldspurger , Martin W eitzman , and theanon ymous review ers for helpful commen ts and suggestions .ReferencesArro w , K . J . , Hurwicz , L . Eds . . . Studies in R esour c e A l lo c ation Pr o c esses .Cam bridge Univ ersit y Press , Cam bridge .Bertsek as , D . P . , Tsitsiklis , J . N . . Par al lel and Distribute d Computation . Pren tice Hall , Englew o o d Cli s , NJ .Dafermos , S . , Nagurney , A . . Supply and demand equilibration algorithms for aclass of mark et equilibrium problems . T r ansp ortation Scienc e , , .Da vis , R . , Smith , R . G . . Negotiation as a metaphor for distributed problemsolving . A rti cial Intel ligenc e , , .Drexler , K . E . , Miller , M . S . . Incen tiv e engineering for computational resourcemanagemen t . In Hub erman , pp . .Eydeland , A . , Nagurney , A . . Progressiv e equilibration algorithms The case oflinear transaction costs . Computer Scienc e in Ec onomics and Management , , .Gallager , R . G . . A minim um dela y routing algorithm using distributed computation .IEEE T r ansactions on Communic ations , , .Hark er , P . T . . Alternativ e mo dels of spatial comp etition . Op er ations R ese ar ch , , .Hark er , P . T . . Pr e dicting Inter city F r eight Flows . VNU Science Press , Utrec h t , TheNetherlands .Hark er , P . T . . Multiple equilibrium b eha viors on net w orks . T r ansp ortation Scienc e , , .Haurie , A . , Marcotte , P . . On the relationship b et w een Nash Cournot and W ardropequilibria . Networks , , .Hic ks , J . R . . V alue and Capital second edition . Oxford Univ ersit y Press , London .Hilden brand , W . , Kirman , A . P . . Intr o duction to Equilibrium A nalysis V ari ations on Themes by Edgeworth and Walr as . North Holland Publishing Compan y ,Amsterdam .Hub erman , B . A . Ed . . . The Ec olo gy of Computation . North Holland .Hurwicz , L . . The design of resource allo cation mec hanisms . In Arro w and Hurwicz , pp . . Reprin ted from A meric an Ec onomic R eview Pap ers and Pr o c e e dings , . , J . O . , Hogg , T . , Hub erman , B . A . . Dynamics of computational ecosys tems . Physic al R eview A , , .Ko opmans , T . C . . Uses of prices . In Scienti c Pap ers of Tjal ling C . Ko opmans , pp . . Springer V erlag . Originally published in the Pro ceedings of the Conferenceon Op erations Researc h in Pro duction and In v en tory Con trol , .Kurose , J . F . , Simha , R . . A micro economic approac h to optimal resource allo cationin distributed computer systems . IEEE T r ansactions on Computers , , .Ku w abara , K . , Ishida , T . . Sym biotic approac h to distributed resource allo cation T o w ard co ordinated balancing . In Pr e Pr o c e e dings of the Eur op e an Workshop onMo deling A utonomous A gents in a Multi A gent World .La v oie , D . , Baetjer , H . , T ulloh , W . . Coping with complexit y OOPS and theeconomists critique of cen tral planning . Hotline on Obje ct Oriente d T e chnolo gy , , .Malone , T . W . , Fik es , R . E . , Gran t , K . R . , Ho w ard , M . T . . En terprise A mark et lik e task sc heduler for distributed computing en vironmen ts . In Hub erman , pp . .Malone , T . W . . Mo deling co ordination in organizations and mark ets . ManagementScienc e , , .McAfee , R . P . , McMillan , J . . Auctions and bidding . Journal of Ec onomic Liter a tur e , , .Milgrom , P . , Rob erts , J . . Adaptiv e and sophisticated learning in normal formgames . Games and Ec onomic Behavior , , .Miller , M . S . , Drexler , K . E . . Mark ets and computation Agoric op en systems . InHub erman , pp . .Nagurney , A . . Network Ec onomics A V ariational Ine quality Appr o ach . Klu w erAcademic Publishers .New ell , A . . The kno wledge lev el . A rti cial Intel ligenc e , , .Reiter , S . . Information incen tiv e and p erformance in the new elfare economics . InReiter , S . Ed . , Studies in Mathematic al Ec onomics . MAA Studies in Mathematics .Sam uelson , P . A . . Mark et mec hanisms and maximization . In Stiglitz , J . E . Ed . ,The Col le cte d Scienti c Pap ers of Paul A . Samuelson , V ol . , pp . . MIT Press ,Cam bridge , MA . Originally app eared in RAND researc h memoranda , .Sam uelson , P . A . . Complemen tarit y An essa y on the anniv ersary of the Hic ks Allen rev olution in demand theory . Journal of Ec onomic Liter atur e , , . Oriented Pr ogrammingSandholm , T . . An implemen tation of the con tract net proto col based on marginalcost calculations . In Pr o c e e dings of the National Confer enc e on A rti cial Intel ligenc e ,pp . W ashington , DC . AAAI .Scarf , H . E . . The computation of equilibrium prices . In Scarf , H . E . , Sho v en , J . B . Eds . , Applie d Gener al Equilibrium A nalysis , pp . . Cam bridge Univ ersit y Press ,Cam bridge .Shenk er , S . . Congestion con trol in computer net w orks An exercise in cost sharing .Prepared for deliv ery at Ann ual Meeting of the American P olitical Science Asso ciation .Shoham , Y . . Agen t orien ted programming . A rti cial Intel ligenc e , , .Sho v en , J . B . , Whalley , J . . Applied general equilib rium mo dels of taxation andin ternational trade An in tro duction and surv ey . Journal of Ec onomic Liter atur e , , .Sho v en , J . B . , Whalley , J . . Applying Gener al Equilibrium . Cam bridge Univ ersit yPress .V arian , H . R . . Micr o e c onomic A nalysis second edition . W . W . Norton Compan y ,New Y ork .W aldspurger , C . A . , Hogg , T . , Hub erman , B . A . , Kephart , J . O . , Stornetta , S . .Spa wn A distributed computational econom y . IEEE T r ansactions on Softwar e En gine ering , , .W ang , Z . , Slagle , J . . An ob ject orien ted kno wledge based approac h for form ulatingapplied general equilibrium mo dels . In Thir d International Workshop on A rti cialIntel ligenc e in Ec onomics and Management P ortland , OR .W ellman , M . P . . Review of Hub erman . A rti cial Intel ligenc e , , .W ellman , M . P . . A general equilib rium approac h to distributed transp ortation plan ning . In Pr o c e e dings of the National Confer enc e on A rti cial Intel ligenc e , pp . Jose , CA . AAAI . "
"Journal of Arti cial In telligence Researc h Submitted published Empirical Analysis of Searc h in GSA TIan P . Gen t I .P .Gent gh .a c .ukDep artment of A rti cial Intel ligenc e , University of Edinbur gh South Bridge , Edinbur gh EH , Unite d KingdomT ob y W alsh w alsh orr aine , , rue du Jar din Botanique , Vil lers les Nancy , F r anc eAbstractW e describ e an extensiv e study of searc h in GSA T , an appro ximation pro cedure forprop ositional satis abilit y . GSA T p erforms greedy hill clim bing on the n um b er of satis edclauses in a truth assignmen t . Our exp erimen ts pro vide a more complete picture of GSA T ssearc h than previous accoun ts . W e describ e in detail the t w o phases of searc h rapid hill clim bing follo w ed b y a long plateau searc h . W e demonstrate that when applied to randomlygenerated SA T problems , there is a v ery simple scaling with problem size for b oth themean n um b er of satis ed clauses and the mean branc hing rate . Our results allo w us tomak e detailed n umerical conjectures ab out the length of the hill clim bing phase , the a v eragegradien t of this phase , and to conjecture that b oth the a v erage score and a v erage branc hingrate deca y exp onen tially during plateau searc h . W e end b y sho wing ho w these results canb e used to direct future theoretical analysis . This w ork pro vides a case study of ho wcomputer exp erimen ts can b e used to impro v e understanding of the theoretical prop ertiesof algorithms . . In tro ductionMathematicians are increasingly recognizing the usefulness of exp erimen ts with computersto help adv ance mathematical theory . It is surprising therefore that one area of mathematicswhic h has b ene tted little from empirical results is the theory of algorithms , esp ecially thoseused in AI . Since the ob jects of this theory are abstract descriptions of computer programs ,w e should in principle b e able to reason ab out programs en tirely deductiv ely . Ho w ev er ,suc h theoretical analysis is often to o complex for our curren t mathematical to ols . Wheretheoretical analysis is practical , it is often limited to unrealistically simple cases . F orexample , results presen ted in Koutsoupias P apadimitriou , for the greedy algorithmfor satis abilit y do not apply to in teresting and hard region of problems as describ ed in x .In addition , actual b eha viour on real problems is sometimes quite di eren t to w orst anda v erage case analyses . W e therefore supp ort the calls of McGeo c h McGeo c h , , Ho ok er Ho ok er , and others for the dev elopmen t of an empirical science of algorithms . Insuc h a science , exp erimen ts as w ell as theory are used to adv ance our understanding ofthe prop erties of algorithms . One of the aims of this pap er is to demonstrate the b ene tsof suc h an empirical approac h . W e will presen t some surprising exp erimen tal results anddemonstrate ho w suc h results can direct future e orts for a theoretical analysis .The algorithm studied in this pap er is GSA T , a randomized hill cli m bin g pro cedure forprop ositional satis abilit y or SA T Selman , Lev esque , Mitc hell , Selman Kautz , . Prop ositional satis abilit y is the problem of deciding if there is an assignmen t forc AI Access F oundation and Morgan Kaufmann Publishers . All righ ts reserv ed .Gent W alshthe v ariables in a prop ositional form ula that mak es the form ula true . Recen tly , there hasb een considerable in terest in GSA T as it app ears to b e able to solv e large and di cult satis abilit y problems b ey ond the range of con v en tional pro cedures lik e Da vis Putnam Selmanet al . , . W e b eliev e that the results w e giv e here will actually apply to a larger familyof pro cedures for satis abilit y called GenSA T Gen t W alsh , . Understanding suc hpro cedures more fully is of considerable practical in terest since SA T is , in man y w a ys , thearc het ypical and in tractable NP hard problem . In addition , man y AI problems can b eenco ded quite naturally in SA T e g . constrain t satisfaction , diagnosis and vision in terpret ation , refutational theorem pro ving , planning .This pap er is structured as follo ws . In x w e in tro duce GSA T , the algorithm studiedin the rest of the pap er . In x w e de ne and motiv ate the c hoice of problems used in ourexp erimen ts . The exp erimen ts themselv es are describ ed in x . These exp erimen ts pro videa more complete picture of GSA T s searc h than previous informal accoun ts . The resultsof these exp erimen ts are analysed more closely in x using some p o w erful statistical to ols .This analysis allo w us to mak e v arious exp erimen tally v eri able conjectures ab out GSA T ssearc h . F or example , w e are able to conjecture the length of GSA T s initial hill cli m bingphase the a v erage gradien t of this phase the simple scaling of v arious imp ortan t featureslik e the score on whic h hill cli m bin g is p erformed and the branc hing rate . In x w e suggestho w suc h results can b e used to direct future theoretical analysis . Finally , in x w e describ erelated w ork and end with some brief conclusions in x . . GSA TGSA T is a random greedy hill cli m bing pro cedure . GSA T deals with form ulae in conjunct iv e normal form CNF a form ula , is in CNF i it is a conjunction of clauses , where aclause is a disjunction of literals . GSA T starts with a randomly generated truth assignmen t ,then hill cli m bs b y ipping the v ariable assignmen t whic h giv es the largest increase inthe n um b er of clauses satis ed called the score from no w on . Giv en the c hoice b et w eensev eral equally go o d ips , GSA T pic ks one at random . If no ip can increase the score ,then a v ariable is ipp ed whic h do es not c hange the score or failing that whic h decreasesthe score the least . Th us GSA T starts in a random part of the searc h space and searc hesfor a global solution using only lo cal information . Despite its simplicit y , this pro cedure hasb een sho wn to giv e go o d p erformance on hard satis abilit y problems Selman et al . , .pro cedure GSA T for i to Max triesT random truth assignmen tfor j to Max ipsif T satis es then return Telse P oss ips set of v ars whic h increase satis abilit y mostV a random elemen t of P oss ipsT T with V s truth assignmen t ipp edendendreturn no satisfying assignmen t found Empirical Anal ysis of Sear ch in GSA TIn Gen t W alsh , w e describ e a large n um b er of exp erimen ts whic h suggestthat neither greediness not randomness is imp ortan t for the p erformance of this pro cedure .These exp erimen ts also suggest v arious other conjectures . F or instance , for random SA Tproblems see x the log of the run time app ears to scale with a less than linear dep endencyon the problem size . Conjectures suc h as these could , as w e noted in the in tro duction ,b e v ery pro tably used to direct future e orts to analyse GSA T theoretically . Indeed ,w e b eliev e that the exp erimen ts rep orted here suggest v arious conjectures whic h w ould b euseful in a pro of of the relationship b et w een run time and problem size see x for moredetails . Problem SpaceT o b e able to p erform exp erimen ts on an algorithm , y ou need a source of problems on whic hto run the algorithm . Ideally the problems should come from a probabilit y distributionwith some w ell de ned prop erties , con tain a few simple parameters and b e represen tativ e ofproblems whic h o ccur in real situations . Unfortunately , it is often di cult to meet all thesecriteria . In practice , one is usually forced to accept either problems from a w ell de neddistribution with a few simple parameters or a b enc hmark set of real problems , necessarilyfrom some unkno wn distribution . In these exp erimen ts w e adopt the former approac h anduse CNF form ulae randomly generated according to the random k SA T mo del .Problems in random k SA T with N v ariables and L clauses are generated as follo ws a random subset of size k of the N v ariables is selected for eac h clause , and eac h v ari able is made p ositiv e or negativ e with probabilit y . F or random SA T , there is a phasetransition from satis able to unsatis able when L is appro ximately . Mitc hell , Selman , Lev esque , Larrab ee Tsuji , Cra wford Auton , . A t lo w er L , mostproblems generated are under constrained and are th us satis able at higher L , most prob lems generated are o v er constrained and are th us unsatis able . As with man y NP completeproblems , problems in the phase transition are t ypically m uc h more di cult to solv e thanproblems a w a y from the transition Cheeseman , Kanefsky , T a ylor , . The regionL . is th us generally considered to b e a go o d source of hard SA T problems and hasb een the fo cus of m uc h recen t exp erimen tal e ort . . GSA T s searc hWhen GSA T w as rst in tro duced , it w as noted that searc h in eac h try is divided in to t w ophases . In the rst phase of a try , eac h ip increases the score . Ho w ev er , this phase isrelativ ely short and is follo w ed b y a second phase in whic h most ips do not increase thescore , but are instead sidew a ys mo v es whic h lea v e the same n um b er of clauses satis ed .This phase is a searc h of a plateau for the o ccasional ip that can increase the score . of the aims of this pap er is to impro v e up on suc h informal observ ations b y makingquantitative measuremen ts of GSA T s searc h , and b y using these measuremen ts to mak esev eral exp erimen tally testable predictions . . Informal observ ations to this e ect w ere made b y Bart Selman during the presen tation of Selman et al . , at AAAI . These observ ations w ere enlarged up on in Gen t W alsh , . W alshIn our exp erimen ts , w e follo w ed three metho dological principles from McGeo c h , .First , w e p erformed exp erimen ts with large problem sizes and man y rep etitions , to reducev ariance and allo w for emergen t prop erties . Second , w e sough t go o d views of the data . Thatis , w e lo ok ed for features of p erformance whic h are meaningful and whic h are as predictableas p ossible . Third , w e analysed our results closely . Suitable analysis of data ma y sho wfeatures whic h are not clear from a simple presen tation . In the rest of this pap er w e sho who w these principles enabled us to mak e v ery detailed conjectures ab out GSA T s searc h .Man y features of GSA T s searc h space can b e graphically illustrated b y plotting ho wthey v ary during a try . The most ob vious feature to plot is the score , the n um b er of satis edclauses . In our quest for a go o d view of GSA T s searc h space , w e also decided to plot p oss ips at eac h ip that is , the n um b er of equally go o d ips b et w een whic h GSA T randomlypic ks . This is an in teresting measure since it indicates the branc hing rate of GSA T s searc hspace .W e b egin with one try of GSA T on a v ariable random SA T problem in thedi cult region of L . Figure . Although there is considerable v ariation b et w eentries , this graph illustrates features common to all tries . Both score in Figure andp oss ips in Figure are plotted as p ercen tages of their maximal v alues , that is L and Nresp ectiv ely . The p ercen tage score starts just ab o v e . , whic h migh t seem surprisinglyhigh . Theoretically , ho w ev er , w e exp ect a random truth assignmen t in k SA T to satisfy k BnZr k of all clauses in this instance , . As exp ected from the earlier informal description ,the score clim bs rapidly at rst , and then attens o as w e moun t the plateau . The graphis discrete since p ositiv e mo v es increase the score b y a xed amoun t , but some of thisdiscreteness is lost due to the small scale . T o illustrate the discreteness , in Figure w eplot the c hange in the n um b er of satis ed clauses made b y eac h ip as its exact v alue ,unscaled . Note that the x axis for b oth plots in Figure is the same . . . . flipsPercentage score in score poss flips a Score b Change in score , and p oss ipsFigure GSA T s b eha viour during one try , N , L , rst ipsThe b eha viour of p oss ips is considerably more complicated than that of the score . Itis easiest rst to consider p oss ips once on the plateau . The start of plateau searc h , after ips , coincides with a v ery large increase in p oss ips , corresp onding to a c hange from Empirical Anal ysis of Sear ch in GSA Tthe region where a small n um b er of ips can increase the score b y to a region where alarge n um b er of ips can b e made whic h lea v e the score unc hanged . Once on the plateau ,there are sev eral sharp dips in p oss ips . These corresp ond to ips where an increase b y the score w as e ected , as can b e seen from Figure . It seems that if y ou can increasethe score on the plateau , y ou only ha v e a v ery small n um b er of w a ys to do it . Also , thedominance of ips whic h mak e no c hange in score graphically illustrates the need for suc h sidew a ys ips , a need that has b een noted b efore Selman et al . , Gen t W alsh , .P erhaps the most fascinating feature is the initial b eha viour of p oss ips . There arefour w ell de ned w edges starting at , , , and ips , with o ccasional sharp dips .These w edges demonstrate b eha viour analogous to the that of p oss ips on the plateau .The plateau spans the region where ips t ypically do not c hange the score w e call thisregion H since hill cl im bi ng t ypically mak es zero c hange to the score . The last w edgespans the region H where hill clim bi ng t ypically increases the score b y , as can b e seenv ery clearly from Figure . Again Figure sho ws that the next three w edges readingrigh t to left span regions H , H , and H . As with the transition on to the plateau , thetransition b et w een eac h region is mark ed b y a sharp increase in p oss ips . Dips in thew edges represen t un usual ips whic h increase the score b y more than the c haracteristicv alue for that region , just as the dips in p oss ips on the plateau represen t ips where anincrease in score w as p ossible . This exact correlation can b e seen clearly in Figure . Notethat in this exp erimen t , in no region Hj did a c hange in score of j o ccur , and that therew as no c hange in score of BnZr at all . In addition , eac h w edge in p oss ips app ears to deca yclose to linearly . This is explained b y the facts that once a v ariable is ipp ed it no longerapp ears in p oss ips ipping it bac k w ould decrease score , that most of the v ariables inp oss ips can b e ipp ed indep enden tly of eac h other , and that new v ariables are rarelyadded to p oss ips as a consequence of an earlier ip . On the plateau , ho w ev er , when av ariable is ipp ed whic h do es not c hange the score , it remains in p oss ips since ipping itbac k also do es not c hange the score .T o determine if this b eha viour is t ypical , w e generated random SA T problemswith N and L . , and ran tries of GSA T on eac h problem . Figure sho ws themean p ercen tage score Figure presen ts the mean p ercen tage p oss ips togetherwith the mean c hange in score at eac h ip . The small discreteness in this gure is due tothe discreteness of P ostscript s plotting . The a v erage p ercen tage score is v ery similar to the b eha viour on the individual run ofFigure , naturally b eing somewhat smo other . The graph of a v erage p oss ips seems quitedi eren t , but it is to b e exp ected that y ou will neither observ e the sharply de ned dipsin p oss ips from Figure , nor the v ery sharply de ned start to the w edges , since thesehapp en at v arying times . It is remark able that the w edges are consisten t enough to b evisible when a v eraged o v er , tries the smo othing in the w edges and the start of theplateau is caused b y the regions not starting at exactly the same time in eac h try .Figure do es not distinguish b et w een satis able and unsatis able problems . Thereis no curren t tec hnique for determining the satis abilit y of v ariable SA T problemsin feasible time . F rom instances w e ha v e b een able to test , w e do not b eliev e that large . In this pap er w e assign a score of to ips whic h w ere not p erformed b ecause a satisfying truthassignmen t had already b een found . W alsh . . . flipsMean percentage score percent poss flipsMean change in score a Mean score b Mean c hange in score , p oss ipsFigure Mean GSA T b eha viour , N , L . , rst ipsdi erences from Figure will b e seen when it is p ossible to plot satis able and unsatis ableproblems separately , but this remains an in teresting topic to in v estigate in the future .Exp erimen ts with other v alues of N with the same ratio of clauses to v ariables demon strated qualitativ ely similar b eha viour . More careful analysis sho ws the remark able fact thatnot only is the b eha viour qualitativ ely similar , but quan titativ ely similar , with a simple lin ear dep endency on N . If graphs similar to Figure are plotted for eac h N with the x axisscaled b y N , b eha viour is almost identic al . T o illustrate this , Figure sho ws the meanp ercen tage score , p ercen tage p oss ips , and c hange in score , for N , , and , forL . and for the rst . ips ips at N . Both Figure and Figure the closeness of the scaling , to the exten t that they ma y app ear to con tain justone thic k line . In Figure there is a sligh t tendency for the di eren t regions of hill cli m bingto b ecome b etter de ned with increasing N .The gures w e ha v e presen ted only reac h a v ery early stage of plateau searc h . T oin v estigate further along the plateau , w e p erformed exp erimen ts with , , , ,and v ariables from to . ips . Figure sho ws the mean p ercen tage score ineac h case , while Figure sho ws the mean p ercen tage p oss ips , magni ed on the y axisfor clarit y . Both these gures demonstrate the closeness of the scaling on the plateau . InFigure the graphs are not quite so close together as in Figure . The phases of hill clim bing b ecome m uc h b etter de ned with increasing N . During plateau searc h , althoughseparate lines are distinguishable , the di erence is alw a ys considerably less than of thetotal n um b er of v ariables .The problems used in these exp erimen ts random SA T with L . are b eliev ed tob e un usually hard and are satis able with probabilit y appro ximately . Neither of thesefacts app ears to b e relev an t to the scaling of GSA T s searc h . T o c hec k this w e p erformeda similar range of exp erimen ts with a ratio of clauses to v ariables of . Although almost allsuc h problems are unsatis able , w e observ ed exactly the same scaling b eha viour . The score . A t v ariables , . ips is close to the optimal v alue for Max ips . Ho w ev er , exp erimen ts ha v esuggested that Max ips ma y need to v ary quadratically for larger N Gen t W alsh , . Empirical Anal ysis of Sear ch in GSA T . . . .... . percentage score . . .... . percent poss flipsMean change in score a Mean score b Mean c hange in score , p oss ipsFigure Scaling of mean GSA T b eha viour , N , , , rst . ips . . . . . . percentage . . . flipsscore . . . . . . flipsMean percentage poss flips .. . a mean score , L . b mean p oss ips , L . Scaling of mean GSA T b eha viour , N , , , , es not reac h suc h a high v alue as in Figure , as is to b e exp ected , but nev ertheless sho wsthe same linear scaling . On the plateau , the mean v alue of p oss ips is lo w er than b efore .W e again observ ed this b eha viour for L , where almost all problems are satis able .The score approac hes faster than b efore , and a higher v alue of p oss ips is reac hedon the plateau , but the deca y in the v alue of p oss ips seen in Figure do es not seem tob e presen t .T o summarise , w e ha v e sho wn that GSA T s hill cli m bing go es through sev eral distinctphases , and that the a v erage b eha viour of certain imp ortan t features scale in linear fashionwith N . These results pro vide a considerable adv ance on previous informal descriptions ofGSA T s searc h . W alsh . Numerical ConjecturesIn this section , w e will sho w that detailed n umerical conjectures can b e made if the datapresen ted graphically in x is analysed n umerically . W e divide our analysis in to t w o parts rst w e deal with the plateau searc h , where b eha viour is relativ ely simple , then w e analysethe hill cli m bi ng searc h .On the plateau , b oth a v erage score and p oss ips seem to deca y exp onen tially with asimple linear dep endency on problem size . T o test this , w e p erformed regression analysison our exp erimen tal data , using the mo delsS x N B BnZr C e BnZr xA N P x N E F e BnZr xD N where x represen ts the n um b er of ips , S x the a v erage score at ip x and P x the a v eragen um b er of p ossible ips . T o determine GSA T s b eha viour just on the plateau , w e analyseddata on mean score , starting from . ips , a time when plateau searc h alw a ys app ears toha v e started see x . Our exp erimen tal data tted the mo del v ery w ell . Detailed results forN are giv en in T able to three signi can t gures . The v alues of A , B , and C c hangeonly sligh tly with N , pro viding further evidence for the scaling of GSA T s b eha viour . F or L the asymptotic mean p ercen tage score is v ery close to of clauses b eing satis ed ,while for L . it is appro ximately . of clauses and for L it is appro ximately . of clauses . A go o d t w as also found for mean p oss ips b eha viour see T able forN , except for L , where the mean v alue of p oss ips on the plateau ma y b econstan t . It seems that for L . the asymptotic v alue of p oss ips is ab out of Nand that for it is ab out of N .It is imp ortan t to note that the b eha viour w e analysed w as for mean b eha viour o v erb oth satis able and unsatis able problems . It is lik ely that individual problems will exhibitsimilar b eha viour with di eren t asymptotes , but w e do not exp ect ev en satis able problemsto yield a mean score of asymptotically . Note that as N increases a small error inp ercen tage terms ma y corresp ond to a large error in the actual score . As a result , ourpredictions of asymptotic score ma y b e inaccurate for large N , or for v ery large n um b ers of ips . F urther exp erimen tation is necessary to examine these issues in detail .L N N A B C R . . . . . . . . . . . . . able Regression results for a v erage score of GSA T . . The v alue of R a n um b er in the in terv al indicating ho w w ell the v ariance in data is explained b ythe regression form ula . BnZr R the ratio b et w een v ariance of the data from its predicted v alue , and thev ariance of the data from the mean of all the data . A v alue of R to indicates that the regressionform ula ts the data v ery w ell . Empirical Anal ysis of Sear ch in GSA TL N N D E F R . . . . . . . . . able Regression results on a v erage p oss ips of GSA T .W e ha v e also analysed GSA T s b eha viour during its hill cli m bing phase . Figure ws regions where most ips increase the score b y , then b y , then b y , then b y .Analysis of our data suggested that eac h phase lasts roughly t wice the length of the previousone . This motiv ates the follo wing conjectures GSA T mo v es through a sequence of regionsHj for j in whic h the ma jorit y of ips increase the score b y j , and where thelength of eac h region Hj is prop ortional to BnZr j except for the region H whic h represen tsplateau searc h .T o in v estigate this conjecture , w e analysed tries eac h on di eren t problems forrandom SA T problems at N and L . . W e v ery rarely observ e ips in Hj thatincrease the score b y less than j , and so de ne Hj as the region b et w een the rst ip whic hincreases the score b y exactly j and the rst ip whic h increases the score b y less thanj unless the latter actually app ears b efore the former , in whic h case Hj is empt y . Onesimple test of our conjecture is to compare the total time sp en t in Hj with the total time upto the end of Hj w e predict that this ratio will b e . F or j to the mean and standarddeviations of this ratio , and the length of eac h region are sho wn in T able . datasupp orts our conjecture although as j increases eac h region is sligh tly longer than predicted .The total length of hill clim bi ng at N is . ips , while at N it is . . Thisis consisten t with the scaling b eha viour observ ed in x .Region mean ratio s .d . mean length s .d .All clim bing . . . . . . . . . . . . . . . . . able Comparativ e and Absolute Lengths of hill cli m bing phasesOur conjecture has an app ealing corollary . Namely , that if there are i non empt y hill clim bing regions , the a v erage c hange in score p er ip during hill clim bi ng is i i It follo ws from this that mean gradien t of the en tire hill cli m bing phase is appro ximately .A t N , w e observ ed a mean ratio of c hange in score p er ip during hill cli m bi ng of . . The data for All clim bing is the length to the start of H . W alshwith a standard deviation of . . A t N , the ratio is . with a standard deviation of . .The mo del presen ted ab o v e ignores ips in Hj whic h increase the score b y more thanj . Suc h ips w ere seen in Figure in regions H to H . In our exp erimen t . of ipsin H w ere of size and . of ips in H w ere of size . Ho w ev er , ips of size j ere v ery rare , forming only ab out . of all ips in H and H . W e conjectured thatan exp onen tial deca y similar to that in H o ccurs in eac h Hj . That is , w e conjecture thatthe a v erage c hange in n um b er of satis ed clauses from ip x to ip x in Hj is giv en b y j Ej e BnZr xDj N This migh t corresp ond to a mo del of GSA T s searc h in whic h there are a certain n um b erof ips of size j in eac h region Hj , and the probabilit y of making a j ip is merelydep enden t on the n um b er of suc h ips left the rest of the time , GSA T is obliged to mak ea ip of size j . Our data from tries tted this mo del w ell , giving v alues of R . for H and . for H . The regression ga v e estimates for the parameters of D ,E , D , E . Not surprisingly , since the region H is v ery short ,data w as to o noisy to obtain a b etter t with the mo del than with one of linear deca y .These results supp ort our conjecture , but more exp erimen ts on larger problems are neededto lengthen the region Hj for j . . Theoretical ConjecturesEmpirical results lik e those giv en in x can b e used to direct e orts to analyse algorithmstheoretically . F or example , consider the plateau region of GSA T s searc h . If the mo del applies also to successful tries , the asymptotic score is L , givingS x L BnZr C N e BnZr xA NDi eren tiating with resp ect to x w e get ,d S x d x CA e BnZr xa N L BnZr S x A NThe gradien t is a go o d appro ximation for Dx , the a v erage size of a ip at x . Hence ,Dx L BnZr S x A NOur exp erimen ts suggest that do wn w ard ips and those of more than are v ery rare on theplateau . Th us , a go o d rst order appro ximation for Dx is as follo ws , where pr ob Dx j is the probabilit y that a ip at x is of size j .Dx LXj BnZr L j pr ob Dx j pr ob Dx Hence ,pr ob Dx L BnZr S x A N Empirical Anal ysis of Sear ch in GSA TThat is , on the plateau the probabilit y of making a ip of size ma y b e directly pro p ortional to L BnZr S x , the a v erage n um b er of clauses remaining unsatis ed and in v erselyprop ortional N , to the n um b er of v ariables . A similar analysis and result can b e giv en forpr ob Dx j in the hill cl im bi ng region Hj , whic h w ould explain the mo del prop osedin x .If our theoretical conjecture is correct , it can b e used to sho w that the mean n um b erof ips on successful tries will b e prop ortional to N ln N . F urther in v estigation , b oth ex p erimen tal and theoretical , will b e needed to determine the accuracy of this prediction .Our conjectures in this section should b e seen as conjectures as to what a formal theoryof GSA T s searc h migh t lo ok lik e , and should b e useful in determining results suc h as a v erage run time and the optimal setting for a parameter lik e Max ips . In addition , if w ecan dev elop a mo del of GSA T s searc h in whic h pr ob Dx j is related to the n um b erof unsatis ed clauses and N as in the ab o v e equation , then the exp erimen tally observ edexp onen tial b eha viour and linear scaling of the score will follo w immediately . . Related W orkPrior to the in tro duction of GSA T in Selman et al . , , a closely related set of pro ced ures w ere studied b y Gu Gu , . These pro cedures ha v e a di eren t con trol structureto GSA T whic h allo ws them , for instance , to mak e sidew a ys mo v es when up w ards mo v esare p ossible . This mak es it di cult to compare our results directly . Nev ertheless , w e arecon den t that the approac h tak en here w ould apply equally w ell to these pro cedures , andthat similar results could b e exp ected . Another greedy algorithm for satis abilit y hasb een analysed in Koutsoupias P apadimitriou , , but our results are not directlyapplicable to it b ecause , unlik e GSA T , it disallo ws sidew a ys ips .In Gen t W alsh , w e describ e an empirical study of GenSA T , a family of pro cedures related to GSA T . This study fo cuses on the imp ortance of randomness , greedinessand hill cli m bing for the e ectiv eness of these pro cedures . In addition , w e determine ho wp erformance dep ends on parameters lik e Max tries and Max ips . W e sho w ed also thatcertain v arian ts of GenSA T could outp erform GSA T on random problems . It w ould b ev ery in teresting to p erform a similar analysis to that giv en here of these closely relatedpro cedures .GSA T is closely related to sim ulated annealing v an Laarho v en Aarts , andthe Metrop olis algorithm , whic h b oth use greedy lo cal searc h with a randomised metho d ofallo wing non optimal ips . Theoretical w ork on these algorithms has not applied to SA Tproblems , for example Jerrum , Jerrum Sorkin , , while exp erimen tal studies ofthe relationship b et w een GSA T and sim ulated annealing ha v e as y et only reac hed ten tativ econclusions Selman Kautz , Sp ears , .Pro cedures lik e GSA T ha v e also b een successfully applied to constrain t satisfactionproblems other than satis abilit y . F or example , Min ton , Johnston , Philips , Laird , prop osed a greedy lo cal searc h pro cedure whic h p erformed w ell sc heduling observ ations onthe Hubble Space T elescop e , and other constrain t problems lik e the million queens , and colourabilit y . It w ould b e v ery in teresting to see ho w the results giv en here map acrossto these new problem domains . W alsh . ConclusionsW e ha v e describ ed an empirical study of searc h in GSA T , an appro ximation pro cedure forsatis abilit y . W e p erformed detailed analysis of the t w o basic phases of GSA T s searc h ,an initial p erio d of fast hill cli m bin g follo w ed b y a longer p erio d of plateau searc h . W eha v e sho wn that the hill cli m bing phases can b e brok en do wn further in to a n um b er ofdistinct phases eac h corresp onding to progressiv ely slo w er clim bing , and eac h phase lastingt wice as long as the last . W e ha v e also sho wn that , in certain w ell de ned problem classes ,the a v erage b eha viour of certain imp ortan t features of GSA T s searc h the a v erage scoreand the a v erage branc hing rate at a giv en p oin t scale in a remark ably simple w a y withthe problem size W e ha v e also demonstrated that the b eha viour of these features can b emo delled v ery w ell b y simple exp onen tial deca y , b oth in the plateau and in the hill cli m bingphase . Finally , w e used our exp erimen ts to conjecture v arious prop erties e g . the probabilit yof making a ip of a certain size that will b e useful in a theoretical analysis of GSA T . Theseresults illustrate ho w carefully p erformed exp erimen ts can b e used to guide theory , and ho wcomputers ha v e an increasingly imp ortan t r ole to pla y in the analysis of algorithms .Ac kno wledgemen tsThis researc h is supp orted b y a SER C P ostdo ctoral F ello wship to the rst author anda HCM P ostdo ctoral fello wship to the second . W e thank Alan Bundy , Ian Green , andthe mem b ers of the Mathematical Reasoning Group for their constructiv e commen ts andfor the quadrillion CPU cycles donated to these and other exp erimen ts from SER C gran tGR H . W e also thank Andrew Bremner , Judith Underw o o d , and the review ers ofthis journal for other help .ReferencesCheeseman , P . , Kanefsky , B . , T a ylor , W . . Where the really hard problems are .In Pr o c e e dings of the IJCAI , pp . . In ternational Join t Conference onArti cial In telligence .Cra wford , J . , Auton , L . . Exp erimen tal results on the crosso v er p oin t in satis abilit y problems . In Pr o c e e dings of the Eleventh National Confer enc e on A rti cialIntel ligenc e , pp . . AAAI Press The MIT Press .Gen t , I . P . , W alsh , T . . T o w ards an Understanding of Hill clim bi ng Pro cedures forSA T . In Pr o c e e dings of the Eleventh National Confer enc e on A rti cial Intel ligenc e ,pp . . AAAI Press The MIT Press .Gen t , I . P . , W alsh , T . . The enigma of SA T hill cli m bin g pro cedures . Researc hpap er , Dept . of Arti cial In telligence , Univ ersit y of Edin burgh .Gu , J . . E cien t lo cal searc h for v ery large scale satis abilit y problems . SIGAR TBul letin , . Empirical Anal ysis of Sear ch in GSA THo ok er , J . N . . Needed An empirical science of algorithms . T ec h . rep . , GraduateSc ho ol of Industrial Administration , Carnegie Mellon Univ ersit y , Pittsburgh P A .Jerrum , M . . Large cliques elude the Metrop olis pro cess . R andom Structur es andA lgorithms , , .Jerrum , M . , Sorkin , G . . Sim ulated annealing for graph bisection . T ec h . rep .ECS LF CS , Departmen t of Computer Science , Univ ersit y of Edin burgh .Koutsoupias , E . , P apadimitriou , C . H . . On the greedy algorithm for satis abilit y .Information Pr o c essing L etters , , .Larrab ee , T . , Tsuji , Y . . Evidence for a Satis abilit y Threshold for Random orm ulas . T ec h . rep . UCSC CRL , Baskin Cen ter for Computer Engineering andInformation Sciences , Univ ersit y of California , San ta Cruz .McGeo c h , C . . Exp erimental A nalysis of A lgorithms . Ph .D . thesis , Carnegie MellonUniv ersit y . Also a v ailable as CMU CS .Min ton , S . , Johnston , M . D . , Philips , A . B . , Laird , P . . Solving large scale con strain t satisfaction and sc heduling problems using a heuristic repair metho d . InAAAI , Pr o c e e dings Eighth National Confer enc e on A rti cial Intel ligenc e , pp . . AAAI Press MIT Press .Mitc hell , D . , Selman , B . , Lev esque , H . . Hard and easy distributions of SA Tproblems . In Pr o c e e dings , National Confer enc e on A rti cial Intel ligenc e . AAAIPress The MIT Press .Selman , B . , Kautz , H . . Domain indep enden t extensions to GSA T Solving largestructured satis abilit y problems . In Pr o c e e dings , IJCAI . In ternational Join t Con ference on Arti cial In telligence .Selman , B . , Kautz , H . . An empirical study of greedy lo cal searc h for satis abilit ytesting . In Pr o c e e dings of the Eleventh National Confer enc e on A rti cial Intel ligenc e ,pp . . AAAI Press The MIT Press .Selman , B . , Lev esque , H . , Mitc hell , D . . A new metho d for solving hard satis abilit yproblems . In Pr o c e e dings , National Confer enc e on A rti cial Intel ligenc e . AAAIPress The MIT Press .Sp ears , W . M . . Sim ulated annealing for hard satis abilit y problems . T ec h . rep .AIC , AI Cen ter , Na v al Researc h Lab oratory .v an Laarho v en , P . , Aarts , E . . Simulate d A nne aling The ory and Applic ations . D .Reidel Publishing Compan y , Dordrec h t , Holland . "
"Journal of Arti cial In telligence Researc h Submitted published Di cultie s of Learning Logic Programs with CutF rancesco Bergadano ber gad an a di Catania , Dip artimento di Matematic a ,via A ndr e a Doria , Catania , ItalyDaniele Gunetti gunetti b erto T rinc hero trincher a di T orino , Dip artimento di Informatic a ,c orso Svizzer a , T orino , ItalyAbstractAs real logic programmers normally use cut ! , an e ectiv e learning pro cedure for logicprograms should b e able to deal with it . Because the cut predicate has only a pro ceduralmeaning , clauses con taining cut cannot b e learned using an extensional ev aluation metho d ,as is done in most learning systems . On the other hand , searc hing a space of p ossibleprograms instead of a space of indep enden t clauses is unfeasible . An alternativ e solutionis to generate rst a candidate base program whic h co v ers the p ositiv e examples , and thenmak e it consisten t b y inserting cut where appropriate . The problem of learning programswith cut has not b een in v estigated b efore and this seems to b e a natural and reasonableapproac h . W e generalize this sc heme and in v estigate the di culties that arise . Some of thema jor shortcomings are actually caused , in general , b y the need for in tensional ev aluation .As a conclusion , the analysis of this pap er suggests , on precise and tec hnical grounds , thatlearning cut is di cult , and curren t induction tec hniques should probably b e restricted topurely declarativ e logic languages . . In tro ductionMuc h recen t researc h in AI and Mac hine Learning is addressing the problem of learningrelations from examples , esp ecially under the title of Inductiv e Logic Programming Mug gleton , . One goal of this line of researc h , although certainly not the only one , is theinductiv e syn thesis of logic programs . More generally , w e are in terested in the constructionof program dev elopmen t to ols based on Mac hine Learning tec hniques . Suc h tec hniques no winclude e cien t algorithms for the induction of logical descriptions of recursiv e relations .Ho w ev er , real logic programs con tain features that are not purely logical , most notably thecut ! predicate . The problem of learning programs with cut has not b een studied b eforein Inductiv e Logic Programming , and this pap er analyzes the di culties in v olv ed . . Wh y Learn Programs with Cut ?There are t w o main motiv ations for learning logic programs with cut . ILP should pro vide practical to ols for dev eloping logic programs , in the con text ofsome general program dev elopmen t metho dology e .g . , Bergadano , as realsize logic programs normally con tain cut , learning cut will b e imp ortan t for creatingan in tegrated Soft w are Engineering framew ork .c AI Access F oundation and Morgan Kaufmann Publishers . All righ ts reserv ed .Ber gad ano , Gunetti , Trincher o . Extensiv e use of cut can mak e programs sensibly shorter , and the di cult y of learninga giv en logic program is v ery m uc h related to its length .F or b oth of these ob jectiv es , w e need not only cuts that mak e the programs moree cien t without c hanging their input output b eha vior green cuts , but also cuts thateliminate some p ossible computed results red cuts . Red cuts are sometimes consideredbad programming st yle , but are often useful . Moreo v er , only the red cuts are e ectiv e inmaking programs shorter . Green cuts are also imp ortan t , and less con tro v ersial . Once acorrect program has b een inferred via inductiv e metho ds , it could b e made more e cien tthrough the insertion of green cuts , either man ually or b y means of automated programtransformation tec hniques Lau Clemen t , . . Wh y Standard Approac hes Cannot b e Used ?Most Mac hine Learning algorithms generate rules or clauses one at a time and indep enden tlyof eac h other if a rule is useful it co v ers some p ositiv e example and correct it do es notco v er an y negativ e example , then it is added to the description or program whic h is b einggenerated , un til all p ositiv e examples ha v e b een co v ered . This means that w e are searc hinga space of p ossible clauses , without bac ktrac king . This is ob viously a great adv an tage , asprograms are sets of clauses , and therefore the space of p ossible programs is exp onen tiallylarger .The one principle whic h allo ws this simpli cation of the problem is the extensionalev aluation of p ossible clauses , used to determine whether a clause C cov er s an examplee . The fact that a clause C co v ers an example e is then used as an appro ximation of thefact that a logic program con taining C deriv es e . Consider , for instance , the clause C p X ,Y , and supp ose the example e is p a ,b . In order to see whether C co v ers e , theextensionalit y principle mak es us ev aluate an y literal in as true if and only if it matc hessome giv en p ositiv e example . F or instance , if q X ,Z p Z ,Y , then the example p a ,b is extensional l y cov er ed i there is a ground term c suc h that q a ,c and p c ,b are giv enas p ositiv e examples . In particular , in order to obtain the truth v alue of p c ,b , w e willnot need to call other clauses that w ere learned previously . F or this reason , determiningwhether C co v ers e only dep ends on C and on the p ositiv e examples . Therefore , the learningsystem will decide whether to accept C as part of the nal program P indep enden tly of theother clauses P will con tain .The extensionalit y principle is found in F oil Quinlan , and its deriv ativ es , but isalso used in b ottom up metho ds suc h as Golem Muggleton F eng , . Shapiro s MISsystem Shapiro , uses it when re ning clauses , although it do es not when bac ktracinginconsistencies . W e ha v e also used an extensional ev aluation of clauses in the FILP system Bergadano Gunetti , .When learning programs with cut , clauses are no longer indep enden t and their stand alone extensional ev aluation is meaningless . When a cut predicate is ev aluated , other p os sible clauses for pro ving the same goal will b e ignored . This c hanges the meaning of theseother clauses . Ev en if a clause extensionally co v ers some example e , it ma y b e the case thatthe nal program do es not deriv e e , b ecause some deriv ation paths ha v e b een eliminatedb y the ev aluation of a cut predicate . Difficul ties of Learning Logic Pr ograms with CutHo w ev er , an exhaustiv e searc h in a space of programs is prohibitiv e . Learning metho ds ,ev en if based on extensionalit y , are often considered ine cien t if su cien t prior informationis not a v ailable searc hing for sets of clauses will b e exp onen tially w orse . This w ould amoun tto a brute force en umeration of all p ossible logic programs con taining cut , un til a programthat is consisten t with the giv en examples is found . . Is there an Alternativ e Metho d ?Cut will only eliminate some computed results , i .e . , after adding cut to some program , itma y b e the case that some example is no longer deriv ed . This observ ation suggests a generallearning strategy a base program P is induced with standard tec hniques , giv en the p ositiv eand ma yb e some of the negativ e examples , then the remaining negativ e examples are ruledout b y inserting cut in some clause of P . Ob viously , after inserting cut , w e m ust mak e surethat the p ositiv e examples ma y still b e deriv ed .Giv en the presen t tec hnology and the discussion ab o v e , this seems to b e the only viablepath to a p ossible solution . Using standard tec hniques , the base program P w ould b e gener ated one clause at a time , so that the p ositiv e examples are extensionally co v ered . Ho w ev er ,w e think this view is to o restrictiv e , as there are programs whic h deriv e all giv en p ositiv eexamples , although they do not co v er them extensionally Bergadano , DeRaedt ,La vrac , Dzeroski , . More generally , w e consider traces of the p ositiv e examples De nition Given a hyp othesis sp ac e S of p ossible clauses , and an example e such that S e , the set of clauses T S which is use d during the derivation of e is c al le d a trace for e .W e will use as a candidate base program P an y subset of S whic h is the union of sometraces for the p ositiv e examples . If P S extensionally co v ers the p ositiv e examples , then itwill also b e the union of suc h traces , but the con v erse is not alw a ys true . After a candidateprogram has b een generated , an attempt is made to insert cuts so that the negativ e examplesare not deriv ed . If this is successful , w e ha v e a solution , otherwise , w e bac ktrac k to anothercandidate base program . W e will analyze the man y problems inheren t in learning cut withthis class of trace based learning metho ds , but , as w e discuss later Section , the sameproblems need to b e faced in the more restrictiv e framew ork of extensional ev aluation . Inother w ords , ev en if w e c ho ose to learn the base program P extensionally , and then w etry to mak e it consisten t b y using cut , the same computational problems w ould still arise .The main di erence is that standard approac hes based on extensionalit y do not allo w forbac ktrac king and do not guaran tee that a correct solution is found Bergadano , .As far as computational complexit y is concerned , trace based metho ds ha v e a complexit ystanding b et w een the searc h in a space of indep enden t clauses for the extensional metho ds and the exhaustiv e searc h in a space of p ossible programs . W e need the follo wing De nition Given a hyp othesis sp ac e S , the depth of an example e is the maximumnumb er of clauses in S suc c essful ly use d in the derivation of e .F or example , if w e are in a list pro cessing domain , and S only con tains recursiv e calls ofthe t yp e P H j T . . . , P T , . . . then the depth of an example P L is the length of L .F or practical program induction tasks , it is often the case that the depth of an example is gad ano , Gunetti , Trincher orelated to its complexit y , and not to the h yp othesis space S . If d is the maxim um depth forthe giv en m p ositiv e examples , then the complexit y of trace based metho ds is of the orderof j S j md , while extensional metho ds will just en umerate p ossible clauses with a complexit ywhic h is linear in j S j , and en umerating all p ossible programs is exp onen tial in j S j . . A Simple Induction Pro cedureThe trace based induction pro cedure w e analyze here tak es as input a nite set of clausesS and a set of p ositiv e and negativ e examples E and E and tries to nd a subset T of Ssuc h that T deriv es all the p ositiv e examples and none of the negativ e examples . F or ev eryp ositiv e example e E , w e assume that S is large enough to deriv e it . Moreo v er , w eassume that all clauses in S are attened . If this is not the case , clauses are attened as aprepro cessing step .W e consider one p ossible pro of for S e , and w e build an in termediate program T Scon taining a trace of the deriv ation . The same is done for the other p ositiv e examples , andthe corresp onding traces T are merged . Ev ery time T is up dated , it is c hec k ed against thenegativ e examples . If some of them are deriv ed from T , cut ! is inserted in the an teceden tsof the clauses in T , so that a consisten t program is found , if it exists . If this is not the case ,the pro cedure bac ktrac ks to a di eren t pro of for S e . The algorithm can b e informallydescrib ed as follo ws input a set of clauses Sa set of p ositiv e examples E a set of negativ e examples E S atten S T F or eac h p ositiv e example e E nd T S suc h that T S LD e bac ktrac king p oin t T T T T derives some negative example e then trycut T ,e if trycut T ,e fails then bac ktrac koutput the clauses listed in Ttrycut T ,e insert ! somewhere in T bac ktrac king p oin t so that . all previously co v ered p ositiv e examples are still deriv ed from T , and . T S LD e The complexit y of adding cut somewhere in the trace T , so that the negativ e example e is no longer deriv ed , ob viously only dep ends on the size of T . But this size dep ends on thedepth of the p ositiv e examples , not on the size of the h yp othesis space S . Although more . A clause is f l attened if it do es not con tain an y functional sym b ol . Giv en an un attened clause , it is alw a yp ossible to atten it b y turning functions in to new predicates with an additional argumen t represen tingthe result of the function and vice v ersa Rouv eirol , in press . Difficul ties of Learning Logic Pr ograms with Cutclev er w a ys of doing this can b e devised , based on the particular example e , w e prop ose asimple en umerativ e tec hnique in the implemen tation describ ed in the App endix . . Example Simplifying a ListIn this section w e sho w an example of the use of the induction pro cedure to learn the logicprogram simpl if y . S impl if y tak es as input a list whose mem b ers ma y b e lists , andtransforms it in to a attened list of single mem b ers , con taining no rep etitions and nolists as mem b ers . This program app ears as exercise n um b er in Co elho Cotta , ,is comp osed of nine clauses plus the clauses for append and member six of them arerecursiv e , one is doubly recursiv e and cut is extensiv ely used . Ev en if simpl if y is a not av ery complex logic program , it is more complex than usual ILP test cases . F or instance ,the q uick sor t and par tition program , whic h is v ery often used , is comp osed of only v eclauses plus those for append , and three of them are recursiv e . Moreo v er , note that theconciseness of simpl if y is essen tially due to the extensiv e use of cut . Without cut , thisprogram w ould b e m uc h longer . In general , the longer a logic program , the more di cultto learn it .As a consequence , w e start with a relativ ely strong bias supp ose that the follo wingh yp othesis space of N p ossible clauses is de ned b y the user The clause simplify L ,NL atten L ,L , remo v e L ,NL . All clauses whose head is atten X ,L and whose b o dy is comp osed of a conjunctionof an y of the follo wing literals head X ,H , tail X ,L , equal X , L ,T , n ull T , n ull H , n ull L , equal X , L , atten H ,X , atten L ,X ,app end X ,X ,L , assign X ,L , assign X ,L , list X ,L . All clauses whose head is remo v e IL ,OL and whose b o dy is comp osed of a con junction of an y of the follo wing literals cons X ,N ,OL , n ull IL , assign ,OL ,head IL ,X , tail IL ,L , mem b er X ,L , remo v e L ,OL , remo v e L ,N . The correct clauses for nul l , head , tail , eq ual , assig n , member , append are giv en n ull .head H j ,H .tail j T ,T .equal X ,X .assign X ,X .mem b er X , X j .mem b er X , j T mem b er X ,T . gad ano , Gunetti , Trincher oapp end ,Z ,Z .app end H j X ,Y , H j Z app end X ,Y ,Z .By using v arious kinds of constrain ts , the initial n um b er of clauses can b e strongly reduced .P ossible constrain ts are the follo wing Once an output is pro duced it m ust not b e instan tiated again . This means that an yv ariable cannot o ccur as output in the an teceden t more than once . Inputs m ust b e used all input v ariables in the head of a clause m ust also o ccur in itsan teceden t . Some conjunctions of literals are ruled out b ecause they can nev er b e true , e .g .n ull IL head IL ,X .By applying v arious com bination of these constrain ts it is p ossible to strongly restrict theinitial h yp othesis space , whic h is then giv en in input to the learning pro cedure . The set ofp ositiv e and negativ e examples used in the learning task is simplify p os , b ,a ,a , , b ,a . remo v e p os a ,a , a . simplify neg , b ,a ,a , ,X , not equal X , b ,a .simplify neg a ,b ,a , , a , b , a . remo v e neg a ,a , a , a .Note that w e de ne some negativ e examples of simpl if y to b e all the examples withthe same input of a giv en p ositiv e example and a di eren t output , for instance sim plify neg , b ,a ,a , , a ,b . Ob viously , it is also p ossible to giv e negativ e examples asnormal ground literals . The learning pro cedure outputs the program for simpl if y rep ortedb elo w , whic h turns out to b e substan tially equiv alen t to the one describ ed in Co elho Cotta , w e ha v e k ept clauses un attened .simplify L ,NL atten L ,L , remo v e L ,NL . atten X ,L equal X , L ,T , n ull T , ! , atten L ,X , assign X ,L . atten X ,L head X ,H , tail X ,L , n ull H , ! , atten L ,X , assign X ,L . atten X ,L equal X , L , ! , atten L ,X , assign X ,L . atten X ,L head X ,H , tail X ,L , ! , atten H ,X , ! , atten L ,X , app end X ,X ,L . atten X ,L list X ,L .remo v e IL ,OL head IL ,X , tail IL ,L , mem b er X ,L , ! , remo v e L ,OL .remo v e IL ,OL head IL ,X , tail IL ,L , remo v e L ,N , cons X ,N ,OL .remo v e IL ,OL n ull IL , assign ,OL .The learning task tak es ab out seconds on our implemen tation . Ho w ev er , This is obtainedat some sp ecial conditions , whic h are thoroughly discussed in the next sections All the constrain ts listed ab o v e are applied , so that the nal h yp othesis space isreduced to less than one h undred clauses . Difficul ties of Learning Logic Pr ograms with Cut Clauses in the h yp othesis space are generated in the correct order , as they m ust app earin the nal program . Moreo v er , literals in eac h clause are in the correct p osition . Thisis imp ortan t , since in a logic program with cut the relativ e p osition of clauses andliterals is signi can t . As a consequence , w e can learn simpl if y without ha ving to testfor di eren t clause and literal orderings see subsections . and . . W e tell the learning pro cedure to use at most t w o cuts p er clause . This seems to b equite an in tuitiv e constrain t since , in fact , man y classical logic programs ha v e no morethan one cut p er clause see subsections . and . . . ProblemsExp erimen ts with the ab o v e induction pro cedure ha v e sho wn that man y problems arise whenlearning logic programs con taining cut . In the follo wing , w e analyze these problems , andthis is a ma jor con tribution of the presen t pap er . As cut cannot b e ev aluated extensionally ,this analysis is general , and do es not dep end on the sp eci c induction metho d adopted .Some p ossible partial solutions will b e discussed in Section . . Problem In tensional Ev aluation , Bac ktrac king and CutThe learning pro cedure of Section is v ery simple , but it can b e ine cien t . Ho w ev er ,w e b eliev e this is common to ev ery in tensional metho d , b ecause clauses cannot b e learnedindep enden tly of one another . As a consequence , bac ktrac king cannot b e a v oided and thiscan ha v e some impact on the complexit y of the learning pro cess . Moreo v er , cut m ust b eadded to ev ery trace co v ering negativ e examples . If no constrain ts are in force , w e canrange from only one cut in the whole trace to a cut b et w een eac h t w o literals of eac h clausein the trace . Clearly , the n um b er of p ossibilities is exp onen tial in the n um b er of literals inthe trace . F ortunately , this n um b er is usually m uc h smaller than the size of the h yp othesisspace , as it dep ends on the depth of the p ositiv e examples .Ho w ev er , bac ktrac king also has some adv an tages in particular , it can b e useful to searc hfor alternativ e solutions . These alternativ e programs can then b e confron ted on the basis ofan y required c haracteristic , suc h as simplicit y or e ciency . F or example , using bac ktrac kingw e disco v ered a v ersion of simpl if y equiv alen t to the one giv en but without the cut predicateb et w een the t w o recursiv e calls of the fourth clause of f l atten . . Problem Ordering of Clauses in the T raceIn a logic program con taining cut , the m utual p osition of clauses is signi can t , and a di er en t ordering can lead to a di eren t p erhaps wrong b eha vior of the program . F or example ,the follo wing program for inter section c in t X ,S ,Y n ull X , n ull Y .c in t X ,S ,Y head X ,H , tail X ,T ail , mem b er H ,S , ! , in t T ail ,S ,S , cons H ,S ,Y .c in t X ,S ,Y head X ,H , tail X ,T ail , in t T ail ,S ,Y .b eha v es correctly only if c comes b efore c . Supp ose the h yp othesis space giv en in inputto the induction pro cedure consists of the same three clauses as ab o v e , but with c b efore gad ano , Gunetti , Trincher oc . If int a , a , is giv en as a negativ e example , then the learning task fails , b ecauseclauses c and c deriv e that example .In other w ords , learning a program con taining cut means not only to learn a set ofclauses , but also a sp eci c ordering for those clauses . In terms of our induction pro cedurethis means that for ev ery trace T co v ering some negativ e example , w e m ust c hec k not onlyev ery p osition for inserting cuts , but also ev ery p ossible clause ordering in the trace . This generate and test b eha vior is not di cult to implemen t , but it can dramatically decreasethe p erformance of the learning task . In the w orst case all p ossible p erm utations m ust b egenerated and c hec k ed , and this requires a time prop ortional to md ! for a trace of mdclauses .The necessit y to test for di eren t p erm utations of clauses in a trace is a primary sourceof ine ciency when learning programs with cut , and probably the most di cult problemto solv e . . Problem Kinds of Giv en ExamplesOur induction pro cedure is only able to learn programs whic h are traces , i .e . where ev eryclause in the program is used to deriv e at least one p ositiv e example . When learning de niteclauses , this is not a problem , b ecause deriv ation is monotone , and for ev ery program P ,complete and consisten t w .r .t . the giv en examples , there is a program P P whic h is alsocomplete and consisten t and is a trace . On the other hand , when learning clauses con tain ing cut , it ma y happ en that the only complete and consisten t program s in the h yp othesisspace is neither a trace , nor con tains it as a subset . This is b ecause deriv ation is no longermonotone and it can b e the case that a negativ e example is deriv ed b y a set of clauses , butnot b y a sup erset of them , as in the follo wing simple example S f sum A ,B ,C A , ! , M is A , sum M ,B ,N , C is N .sum A ,B ,C C is B . gsum p os , , , sum neg , , .The t w o clauses in the h yp othesis space represen t a complete and consisten t program forthe giv en examples , but our pro cedure is unable to learn it . Observ e that the negativ eexample is deriv ed b y the second clause , whic h is a trace for the p ositiv e example , but notb y the rst and the second together .This problem can b e a v oided if w e require that , for ev ery negativ e example , a corre sp onding p ositiv e example with the same input b e giv en in the ab o v e case , the examplerequired is sum p os , , . In this w a y , if a complete program exists in the h yp othesisspace , then it is also a trace , and can b e learned . Then it can b e made consisten t usingcut , in order to rule out the deriv ation of negativ e examples . The constrain t on p ositiv eand negativ e examples seems to b e quite in tuitiv e . In fact , when writing a program , a . it m ust b e noted that if w e are learning programs for t w o di eren t predicates , of j and k clausesresp ectiv ely that is , md j k , then w e ha v e to consider not j k ! di eren t programs , but onlyj ! k ! . W e can do b etter if , inside a program , it is kno wn that non recursiv e clauses ha v e a xedp osition , and can b e put b efore or after of all the recursiv e clauses . . a learned program P is compl ete if it deriv es all the giv en p ositiv e examples , and it is consistent if itdo es not deriv e an y of the giv en negativ e examples Difficul ties of Learning Logic Pr ograms with Cutprogrammer usually thinks in terms of what a program should compute on giv en inputs ,and then tries to a v oid wrong computations for those inputs . . Problem Ordering of Giv en ExamplesWhen learning clauses with cut , ev en the order of the p ositiv e examples ma y b e signi can t .In the example ab o v e , if sum p os , , comes after sum p os , , then the learning taskfails to learn a correct program for sum , b ecause it cannot nd a program consisten t w .r .t .the rst p ositiv e example and the negativ e one s .In general , for a giv en set of m p ositiv e examples this problem can b e remedied b ytesting di eren t example orderings . Again , in the w orst case k ! di eren t orderings of a setof k p ositiv e examples m ust b e c hec k ed . Moreo v er , in some situations a fa v orable orderingdo es not exist . Consider the follo wing h yp othesis space c in t X ,Y ,W head X ,A , tail X ,B , notmem b er A ,Y , in t B ,Y ,W .c in t X ,Y ,W head X ,A , tail X ,B , notmem b er A ,Y , ! , in t B ,Y ,W .c in t X ,Y ,Z head X ,A , tail X ,B , in t B ,Y ,W , cons A ,W ,Z .c in t X ,Y ,Z head X ,A , tail X ,B , ! , in t B ,Y ,W , cons A ,W ,Z .c in t X ,Y ,Z n ull Z .together with the set of examples e in t p os a , b , .e in t p os a , a , a .e in t neg a , b , a .e in t neg a , a , .Our induction pro cedure will not b e able to nd a correct program for an y ordering of thet w o p ositiv e examples , ev en if suc h a program do es exist c , c , c . This program is theunion of t w o traces c , c , whic h co v ers e , and c , c , whic h co v ers e . Both of these tracesare inconsisten t , b ecause the rst co v ers e , and the second co v ers e . This problem canb e remedied only if all the p ositiv e examples are deriv ed b efore the c hec k against negativ eexamples is done .Ho w ev er , in that case w e ha v e a further loss of e ciency , b ecause some inconsisten ttraces are discarded only in the end . In other w ords , w e w ould need to learn a programco v ering al l the p ositiv e examples , and then mak e it consisten t b y using cut and b y reorder ing clauses . Moreo v er , there can b e no w a y to mak e a program consisten t b y using cut andreorderings . As a consequence , all the time used to build that program is w asted . As anexample , supp ose w e are giv en the follo wing h yp othesis space c in t X ,Y ,Z head X ,A , tail X ,B , in t B ,Y ,W , cons A ,W ,Z .c in t X ,Y ,Z n ull X , n ull Z .c in t X ,Y ,Z n ull Z . gad ano , Gunetti , Trincher owith the examples e in t p os a , a , a .e in t p os a ,b , c , .e in t neg a , b , a .Then w e can learn the trace c , c from e and the trace c from e . But c , c , c co v erse , and there is no w a y to mak e it consisten t using cut or b y reordering its clauses . In fact ,the rst partial trace is resp onsible for this inconsistency , and hence the time used to learn c is totally w asted .Here it is also p ossible to understand wh y w e need attened clauses . Consider the fol lo wing program for inter section , whic h is equiv alen t to c , c , c , but with the three clausesun attened u in t A j B ,Y ,W notmem b er A ,Y , ! , in t B ,Y ,W .u in t A j B ,Y , A j W ! , in t B ,Y ,W .u in t , , .No w , this program co v ers in t neg a , a , , i .e . u , u , u in t a , a , . In fact , clauseu fails on this example b ecause a is a mem b er of a . Clause u fails b ecause the empt ylist cannot b e matc hed with A j W . But clause u succeeds b ecause its argumen ts matc hthose of the negativ e example . As a consequence , this program w ould b e rejected b y theinduction pro cedure .The problem is that , if w e use un attened clauses , it ma y happ en that a clause b o dy isnot ev aluated b ecause an example do es not matc h the head of the clause . As a consequence ,p ossible cuts in that clause are not ev aluated and cannot in uence the b eha vior of the en tireprogram . In our example , the cut in clause u has no e ect b ecause the output argumen t ofin t a , a , do es not matc h A j W , and the b o dy of u is not ev aluated at all . Then u is red and the negativ e example is co v ered . In the attened v ersion , clause c fails only whencons a , , is reac hed , but at that p oin t a cut is in force and clause c cannot b e activ ated .Note that program u , u , u b eha v es correctly on the query in t a , a ,X , and giv es X a as the only output . . Problem Ordering of LiteralsEv en the relativ e p osition of literals and cut in a clause is signi can t . Consider again thecorrect program for inter section as ab o v e c , c , c , but with c mo di ed b y putting thecons literal in fron t of the an teceden t c in t X ,Y ,Z cons A ,W ,Z , head X ,A , tail X ,B , in t B ,Y ,W .Then , there is no w a y to get a correct program for in tersection using this clause . T o ruleout the negativ e example in t neg a , a , w e m ust put a cut b efore the cons predicate ,in order to prev en t the activ ation of c . But , then , some p ositiv e examples are no longerco v ered , suc h as in t p os a , , . In fact , w e ha v e a wrong b eha vior ev ery time clause c is Difficul ties of Learning Logic Pr ograms with Cutcalled and fails , since it prev en ts the activ ation on c . In general , this problem cannot b ea v oided ev en b y reordering clauses if w e put c after c and c , then in t neg a , a , willb e co v ered . As a consequence , w e should also test for ev ery p ossible p erm utation of literalsin ev ery clause of a candidate program . . Situations where Learning Cut is still PracticalF rom the ab o v e analysis , learning cut app ears to b e di cult since , in general , a learningpro cedure should b e able to bac ktrac k on the candidate base programs e .g . , traces , onthe p osition of cut s in the program , on the order of the clauses in the program , on theorder of literals in the clauses and on the order of giv en p ositiv e examples . Ho w ev er , w eha v e sp otted some general conditions at whic h learning cut could still b e practical . Clearly ,these conditions cannot b e a nal solution to learning cut , but , if applicable , can alleviatethe computational problems of the task . . Small Hyp othesis SpaceFirst of all , a restricted h yp othesis space is necessary . If clauses cannot b e learned inde p enden tly of one another , a small h yp othesis space w ould help to limit the bac ktrac kingrequired on candidate traces problem . Moreo v er , ev en the n um b er of clauses in a tracew ould b e probably smaller , and hence also the n um b er of di eren t p erm utations and then um b er of di eren t p ositions for inserted cuts problems and . A small trace w ould alsoha v e a sligh t p ositiv e impact on the need to test for di eren t literal orderings in clauses problem .In general , man y kinds of constrain ts can b e applied to k eep a h yp othesis space small ,suc h as ij determinism Muggleton F eng , , rule sets and sc hemata Kietz W rob el , Bergadano Gunetti , , determinations Russell , , lo calit y Cohen , ,etc in fact , some of these restrictions and others , suc h as those listed in Section , area v ailable in the actual implemen tation of our pro cedure see the App endix . Moreo v er ,candidate recursiv e clauses m ust b e designed so that no in nite c hains of recursiv e callscan tak e place Bergadano Gunetti , otherwise the learning task itself could b enon terminating . In general , the n um b er of p ossible recursiv e calls m ust b e k ept small , inorder to a v oid to o m uc h bac ktrac king when searc hing for p ossible traces . Ho w ev er , generalconstrain ts ma y not b e su cien t . The h yp othesis space m ust b e designed carefully fromthe v ery b eginning , and this can b e di cult . In the example of learning simpl if y an initialh yp othesis space of only clauses w as obtained sp ecifying not only the set of requiredpredicates , but ev en the v ariables o ccurring in ev ery literal .If clauses cannot b e learned indep enden tly , exp erimen ts ha v e sho wn to us that a dra matic impro v emen t of the learning task can b e obtained b y generating the clauses in theh yp othesis space so that recursiv e clauses , and in general more complex clauses , are tak enin to consideration after the simpler and non recursiv e ones . Since simpler and non recursiv eclauses require less time to b e ev aluated , they will ha v e a small impact on the learning time .Moreo v er , learning simpler clauses i .e . shorter also alleviates problem . . W e found these constrain ts particularl y useful . By using them w e w ere often able to restrict a h yp othesisspace of one order of magnitude without ruling out an y p ossible solution . gad ano , Gunetti , Trincher oFinally , it m ust b e noted that our induction pro cedure do es not necessarily require thatthe h yp othesis space S of p ossible clauses b e represen ted explicitly . The learning task couldstart with an empt y set S and an implicit description of the h yp othesis space , for examplethe one giv en in Section . When a p ositiv e example cannot b e deriv ed from S , a new clauseis ask ed for to a clause generator and added to S . This step is rep eated un til the exampleis deriv able from the up dated S , and then the learning task can pro ceed normally . . Simple ExamplesAnother impro v emen t can b e ac hiev ed b y using examples that are as simple as p ossible .In fact , eac h example whic h ma y in v olv e a recursiv e call is p oten tially resp onsible for theactiv ation of all the corresp onding clauses in the h yp othesis space . The more complex theexample , the larger the n um b er of consecutiv e recursiv e activ ations of clauses and the largerthe n um b er of traces to b e considered for bac ktrac king problem . F or instance , to learnthe append relation , it ma y b e su cien t to use an example lik e app end a , b , a ,b insteadof one lik e app end a ,b ,c ,d , b , a ,b ,c ,d ,b . Since simple examples w ould probably requirea smaller n um b er of di eren t clauses to b e deriv ed , this w ould result in smaller traces ,alleviating the problem of p erm utation of clauses and literals in a trace problems and and decreasing the n um b er of p ositions for cuts problem . . Small Num b er of ExamplesSince a candidate program is formed b y taking the union of partial traces learned for singleexamples , if w e w an t a small trace problems and w e m ust use as few examples asp ossible , while still completely describing the required concept . In other w ords , w e shoulda v oid redundan t information . F or example , if w e w an t to learn the program for append , itwill b e normally su cien t to use only one of the t w o p ositiv e examples app end a , b , a ,b and app end c , d , c ,d . Ob viously it ma y happ en that di eren t examples are deriv ed b ythe same set of clauses , and in this case the nal program do es not c hange .Ha ving to c hec k for all p ossible orderings of a set of p ositiv e examples , a small n um b er ofexamples is also a solution to problem . F ortunately , exp erimen ts ha v e sho wn that normallyv ery few p ositiv e examples are needed to learn a program , and hence the corresp ondingn um b er of di eren t orderings is , in an y case , a small n um b er . Moreo v er , since in ourmetho d a p ositiv e example is su cien t to learn all the clauses necessary to deriv e it , mostof the time a complete program can b e learned using only one w ell c hosen example . If suc han example can b e found as in the case of the learning task of section , where only oneexample of simpl if y and one of r emov e are giv en , the computational problem of testingdi eren t example orderings is automatically solv ed .Ho w ev er , it m ust b e noted that , in general , a small n um b er of examples ma y not b esu cien t , except for v ery simple programs . In fact , if w e w an t to learn logic programssuc h as member , append , r ev er se and so on , then an y example in v olving recursion will b esu cien t . But for more complex programs the c hoice ma y not b e trivial . F or example , ourpro cedure is able to learn the q uick sor t plus par tition program with only one go o d example . But if one do es not kno w ho w q uick sor t and par tition w ork , it is lik ely thatshe or he will pro vide an example allo wing to learn only a partial description of par tition .This is particularly clear in the example of simpl if y . Had w e used the p ositiv e example Difficul ties of Learning Logic Pr ograms with Cutsimplify p os , b ,a ,a , b ,a whic h is v ery close to the one e ectiv ely used , the rst clauseof f l atten w ould not ha v e b een learned . In other w ords , to giv e few examples w e m ust giv ego o d examples , and often this is p ossible only b y ha ving in mind at least partially and inan informal w a y the target program . Moreo v er , for complex programs , go o d examples canmean complex examples , and this is in con trast with the previous requiremen t . F or furtherstudies of learning from go o d examples w e refer the reader to the w ork of Ling andAha , Ling , Mat win and Lap oin te . . Constrained P ositions for Cut and LiteralsExp erimen ts ha v e sho wn that it is not practical to allo w the learning pro cedure to test allp ossible p ositions of cut in a trace , ev en if w e are able to k eep the n um b er of clauses ina trace small . The user m ust b e able to indicate the p ositions where a cut is allo w ed too ccur , e .g . , at the b eginning of a clause b o dy , or b efore a recursiv e call . In this case , man yalternativ e programs with cut are automatically ruled out and th us do not ha v e to b e testedagainst the negativ e examples . It ma y also b e useful to limit the maxim um n um b er of cutsp er clause or p er trace . F or example , most of the time one cut p er clause can b e su cien tto learn a correct program . In the actual implemen tation of our pro cedure , it is in factp ossible to sp ecify the exact p osition of cut w .r .t . a literal or a group of literals within eac hclause of the h yp othesis space , when this information is kno wn .T o eliminate the need to test for di eren t ordering of literals problem , w e ma y alsoimp ose a particular global order , whic h m ust b e main tained in ev ery clause of the h yp othesisspace . Ho w ev er this requires a deep kno wledge of the program w e w an t , otherwise some or ev en all solutions will b e lost . Moreo v er , this solution can b e in con trast with a use ofconstrained p ositions for cut , since a solution program for a particular literal ordering andfor particular p ositions for cuts ma y not exist . . ConclusionOur induction pro cedure is based on an in tensional ev aluation of clauses . Since the cutpredicate has no declarativ e meaning , w e b eliev e that in tensional ev aluation of clausescannot b e abandoned , indep enden tly of the kind of learning metho d adopted . This candecrease the p erformance of the learning task , compared with extensional metho ds , whic hexamine clauses one at a time without bac ktrac king . Ho w ev er , the computational problemsoutlined in Section remain ev en if w e c ho ose to learn a complete program extensionally ,and then w e try to mak e it consisten t b y inserting cut . The only di erence is that w e donot ha v e bac ktrac king problem , but the situation is probably w orse , since extensionalmetho ds can fail to learn a complete program ev en if it exists in the h yp othesis space . Bergadano , .Ev en if the abilit y to learn clauses con taining pro cedural predicates lik e cut seems to b efundamen tal to learning real logic programs , in particular short and e cien t programs ,man y problems in uencing the complexit y of the learning task m ust b e faced . These includethe n um b er and the relativ e ordering of clauses and literals in the h yp othesis space , the kindand the relativ e ordering of giv en examples . Suc h problems seem to b e related to the needfor an in tensional ev aluation of clauses in general , and not to the particular learning metho dadopted . Ev en just to alleviate these problems , it seems necessary to kno w a lot ab out the gad ano , Gunetti , Trincher otarget program . An alternativ e solution is simply to ignore some of the problems . That is ,a v oid testing for di eren t clause and or literal and or example orderings . Clearly , in thisw a y the learning pro cess can b ecome feasible , but it can fail to nd a solution ev en whenit exists . Ho w ev er , man y ILP systems suc h as F oil adopt suc h an incomplete but fast approac h , whic h is guided b y heuristic information .As a consequence , w e view results presen ted in this pap er as , at least partially , nega tiv e . The problems w e raised app ear computationally di cult , and suggest that atten tionshould b e restricted to purely declarativ e logic languages , whic h are , in an y case , su cien tlyexpressiv e .Ac kno wledgemen tsThis w ork w as in part supp orted b y BRA ESPRIT pro ject on Inductiv e Logic Pro gramming .App endix AThe induction pro cedure of Section is written in C prolog in terpreted and runs on aSUNsparcstation . W e are planning to translate it in QUINTUS prolog . This App endixcon tains a simpli ed description of its implemen tation . As a preliminary step , in order torecord a trace of the clauses deriving a p ositiv e example e , ev ery clause in the h yp othesisspace m ust b e n um b ered and mo di ed b y adding to its b o dy t w o literals . The rstone , al l ow ed n , m is used to activ ate only the clauses whic h m ust b e c hec k ed against thenegativ e examples . The second one , mar k er n , is used to remem b er that clause n um b er nhas b een successfully used while deriving e . Hence , in general , a clause in the h yp othesisspace S tak es the follo wing form P X , , Xm al l ow ed n , m , , mar k er n .where is the actual b o dy of the clause , n is the n um b er of the clause in the set and m is an um b er used to deal with cuts . F or ev ery clause n , the one without cut is augmen ted withal l ow ed n , , while those con taining a cut somewhere in their b o dy are augmen ted withal l ow ed n , , al l ow ed n , , . . . , and so on . Moreo v er , for ev ery augmen ted clause as ab o v e ,a fact al t n , m . is inserted in S , in order to implemen t an en umeration mec hanism .A simpli ed but running v ersion of the learning algorithm is rep orted b elo w . In thealgorithm , the output , if an y , is the v ariable T race con taining the list of the n um b ers of the clauses represen ting the learned program P . By using the bac ktrac king mec hanism of Prolog ,more than one solution trace can b e found . W e assume the t w o predicates l istpositiv eand l istneg ativ e build a list of the giv en p ositiv e and negativ e examples , resp ectiv ely .consult le con taining the set of clauses S . . W e assume clauses in the h yp othesis space to b e attened Difficul ties of Learning Logic Pr ograms with Cutallo w ed X , .mark er X assert trace X .mark er X retract trace X , ! , fail .main listp ositiv e P osexamplelist , tracer ,P osexamplelist ,T race .tracer Co v ered , Example j Cdr ,T race Example , ? bac ktrac king p oin t ? setof L ,trace L ,T race ,notneg T race , Example j Co v ered ,Cdr ,tracer Example j Co v ered ,Cdr ,T race .tracer , ,T race setof I ,J ,allo w ed I ,J ,T race , asserta mark er X true , ! .assertem .assertem I j Cdr alt I ,J , bac k assert allo w ed I ,J , assertem Cdr .prep T retract allo w ed X , , assertem T .bac k assert X assert X .bac k assert X retract X , ! , fail .resetallo w ed ! .resetallo w ed ab olish allo w ed , , assert allo w ed X , , ! .notneg T ,Co v ered ,Remaining listnegativ e .notneg T ,Co v ered ,Remaining listnegativ e Negexamplelist ,asserta mark er X true , ! ,prep T , ? bac ktrac king p oin t ? tryp os Co v ered , trynegs Negexamplelist ,resetallo w ed Remaining ,retract mark er X true , ! .notneg T ,Co v ered ,Remaining resetallo w ed Remaining ,retract mark er X true , ! , ! , fail .tryp os Example j Cdr Example , ! , tryp os Cdr .tryp os ! .trynegs Example j Cdr Example , ! ,fail .trynegs Example j Cdr trynegs Cdr .trynegs ! .Actually , our complete implemen tation is more complex , also in order to ac hiev e greatere ciency . The b eha vior of the learning task is quite simple . Initially , the set S of clauses isread in to the Prolog in terpreter , together with the learning algorithm . Then the learningtask can b e started b y calling the predicate main . A list of the p ositiv e examples is formed gad ano , Gunetti , Trincher oand the tr acer pro cedure is called on that list . F or ev ery p ositiv e example , tr acer callsthe example itself , ring all the clauses in S that ma y b e resolv ed against that example .Observ e that , initially , an al l ow ed X , predicate is asserted in the database in this w a yonly clauses not con taining a cut are al l ow ed to b e used this is b ecause clauses with cut areemplo y ed only if some negativ e example is deriv ed . Then , a trace , if an y , of the n um b ersasso ciated to the clauses successfully used in the deriv ation of that example is built , usingthe setof predicate .The trace is added to the traces found for the previous examples , and the result isc hec k ed against the set of the negativ e examples calling the notneg pro cedure . If notnegdo es not fail i .e . no negativ e examples are co v ered b y this trace then a new p ositiv eexample is tak en in to consideration . Otherwise notneg mo di es the trace with cut andtests it again . If also this fails , bac ktrac king o ccurs and a new trace for the curren t example and p ossibly for the previous ones is searc hed for .The notneg pro cedure w orks as follo ws . First , only the clauses in the trace are al l ow edto b e c hec k ed against the negativ e examples , b y retracting the al l ow ed X , clause andasserting an al l ow ed n , if the n th clause without cut is in the trace . This is done withthe pr ep and asser tem predicates . Then a list of the negativ e examples is formed and w ec hec k if they can b e deriv ed from the clauses in the trace . If at least one negativ e example isco v ered , i .e . , if tr y neg s fails then w e bac ktrac k to the pr ep pro cedure bac ktrac king p oin t where a clause of the trace is substituted with an equiv alen t one but with cut insertedsomewhere or in a di eren t p osition . If no correct program can b e found in suc h a w a yb y trying all p ossible alternativ es i .e . b y using cut in all p ossible w a ys , notneg fails , andbac ktrac king to bac ktrac king p oin t o ccurs , where another trace is searc hed for . Otherwise ,all clauses in S without cut are reactiv ated b y asserting again al l ow ed X , , and the nextp ositiv e example is considered . Note that tr y pos is used in notneg to v erify if a mo di edtrace still deriv es the set of p ositiv e examples deriv ed initially . The p ossibilit y to substituteclauses in the curren t trace with others ha ving cut inserted somewhere is ac hiev ed throughthe al t predicate in the asser tem pro cedure . Finally , note that this simpli ed v ersion ofthe learning pro cedure is not able to generate and test for di eren t orderings of clauses ina trace or for di eren t ordering of literals in eac h clause , nor to use di eren t orderings forthe set of p ositiv e examples .In order to deriv e all the p ositiv e examples b efore the c hec k against the negativ e ones see subsection . , w e m ust c hange the rst clause of the tr acer pro cedure in to tracer P os , . . . ,P osn P os , . . . ,P osn , setof L ,trace L ,T , notneg T .The actual implemen tation of the ab o v e induction pro cedure is a v ailable through ftp . F orfurther information con tact gunetti D . , Ling , C . , Mat win , S . , Lap oin te , S . . Learning Singly Recursiv e Relationsfrom Small Datasets . In Pr o c e e dings of the IJCAI workshop on ILP .Bergadano , F . . Inductiv e database relations . IEEE T r ansactions on Data andKnow le dge Engine ering , . Difficul ties of Learning Logic Pr ograms with CutBergadano , F . . T est Case Generation b y Means of Learning T ec hniques . In Pr o c e e dings of A CM SIGSOFT .Bergadano , F . , Gunetti , D . . An in teractiv e system to learn functional logic pro grams . In Pr o c e e dings of IJCAI .Co elho , H . , Cotta , J . C . . Pr olo g by Example how to le arn te ach and use it . Berlin Springer V erlag .Cohen , W . . Rapid Protot yping of ILP Systems Using Explicit Bias . In Pr o c e e dingsof the IJCAI workshop on ILP .DeRaedt , L . , La vrac , N . , Dzeroski , S . . Multiple predicate learning . In Pr o c e e dingsof IJCAI .Kietz , J . U . , W rob el , S . . Con trolling the Complexit y of Learning in Logic throughSyn tactic and T ask Orien ted Mo dels . In Muggleton , S . Ed . , Inductive L o gic Pr o gr amming . London Academic Press .Lau , K . K . , Clemen t , T . Eds . . . L o gic Pr o gr am Synthesis and T r ansformation .Berlin Springer V erlag .Ling , X . C . . Learning from Go o d Examples . In Pr o c e e dings of IJCAI .Muggleton , S . Ed . . . Inductive L o gic Pr o gr amming . London Academic Press .Muggleton , S . , F eng , C . . E cien t Induction of Logic Programs . In Pr o c e e dings ofthe rst c onfer enc e on A lgorithmic L e arning The ory .Quinlan , R . . Learning Logical De nitions from Relations . Machine L e arning , , .Rouv eirol , C . in press . Flattening a represen tation c hange for generalization . MachineL e arning .Russell , S . . T ree structured bias . In Pr o c e e dings of AAAI .Shapiro , E . Y . . A lgorithmic Pr o gr am Debugging . Cam bridge , CA MIT Press . "
" Journal of Artificial Intelligence Research Submitted published AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. Software Agents Completing Patterns and Constructing User Interfaces Jeffrey C. Schlimmer SCHLIMMER Leonard A. Hermens LHERMENS School of Electrical Engineering Computer Science, Washington State University, Pullman, WA , U.S.A. Abstract To support the goal of allowing users to record and retrieve information, this paper describes an interactive note taking system for pen based computers with two distinctive features. First, it actively predicts what the user is going to write. Second, it automatically constructs a custom, button box user interface on request. The system is an example of a learning apprentice software agent. A machine learning component characterizes the syntax and semantics of the users information. A performance system uses this learned information to generate completion strings and construct a user interface. .Introduction and Motivation People like to record information for later consultation. For many , the media of choice is paper. It is easy to use, inexpensive, and durable. To its disadvantage, paper records do not scale well. As the amount of information grows, retrieval becomes inef cient, physical stor age becomes excessive, and duplication and distribution become expensive. Digital media offers better scaling capabilities. With indexing and sub linear algorithms, retrieval is ef cient using high density devices, storage space is minimal and with electronic storage and high speed networks, duplication and distribution is fast and inexpensive. It is clear that our computing environments are evolving as several vendors are beginning to market inexpen sive, hand held, highly portable computers that can convert handwriting into text. We view this as the start of a new paradigm shift in how traditional digital information will be gath ered and used. One obvious change is that these computers embrace the paper metaphor , eliminating the need for typing. It is in this paradigm that our research is inspired, and one of our primary goals is to combine the best of both worlds by making digital media as conve nient as paper . This document describes an interactive note taking software system for computers with pen based input devices. Our software has two distinctive features rst, it actively predicts what the user is going to write and provides a default that the user may select second, the software automatically constructs a graphical interface at the user s request. The purpose of these features is to speed up information entry and reduce user errors. Viewed in a lar ger context, the interactive note taking system is a type of self customizing software. To clarify this notion, consider a pair of dimensions for characterizing software. As Figure depicts, one dimension is task speci city. Software that addresses a generic task e.g., a spreadsheet lies between task independent software e.g., a compiler and task specic software e.g., a particular company s accounting software . Another dimension is the amount of user customization required to make the software useful. Task generic soft ware lies between the two extremes, requiring modest programming in a specialized S CHLIMMER H ERMENS language. Self customizing software uses machine learning techniques to automatically cus tomize task generic software to a speci c user. Because the software learns to assist the user by watching them complete tasks, the software is also a learning apprentice. Similarly , because the user does not explicitly program the defaults or the user interface for the note taking system, it is a type of software agent. Agents are a new user interface paradigm that free the user from having to explicitly command the computer . The user can record informa tion directly and in a free form manner . Behind the interface, the software is acting on behalf of the user , helping to capture and or ganize the information. Next we will introduce the performance component of the note taking software in more detail, then describe the representations and algorithms used by the learning methods. We also present empirical results, comparing the performance of seven alternate methods on nine realistic note taking domains, and nally, we describe related research and identify some of the system s limitations.Figure Continuum of software development depicting the traditional trade off between the development cost per user and the amount of user customization required. Self customizing software eliminates the need for user customization by starting with partially specified software and applying machine learning methods to complete any remaining customization.Generic Task Specificity of Product Specific Low Development Cost User HighHigh LowUser Customization RequiredVisual BASIC Custom SoftwareSpreadsheets Self Customizing S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES .Performance Task The primary function of the note taking software is to improve the user s speed and accuracy as they enter notes about various domains of interest. A note is a short sequence of descrip tive terms that describe a single object of interest. Example shows a note describing a par ticular personal computer recorded by the rst author from a Usenet newsgroup during PowerBook , . and Int. Drives, Baud FAX Modem Example Example is a note describing a fabric pattern recorded by the rst author s wife Butterick Size dress, top Example Tables through later in the paper list sample notes drawn from seven other domains. The user may enter notes from dif ferent domains at their convenience and may use whatever syntactic style comes naturally . From the user s point of view , the software operates in one of two modes a contextual prompting mode, and an interactive graphical interface mode. In the rst mode, the software continuously predicts a likely completion as the user writes out a note. It of fers this as a default for the user . The location and presentation of this default must balance con icting requirements to be convenient yet unobtrusive. For example, the hand should not hide the indicated default while the user is writing. Our solution is to have a small, colored comple tion button follow to the left and below where the user is writing. In this location, it is visible to either right or left handed people as they write out notes. The user can reposition the but ton to another location if they prefer . The default text is displayed to the immediate right of this button in a smaller font. The completion button is green the text is black. The comple tion button saturation ranges from appearing green , when the software is highly con dent of the predicted value, to appearing white , when the software lacks con dence. The but ton has a light gray frame , so it is visible even when the software has no prediction. Figure Figure Screen snapshot of the note taking software in contextual prompting mode for a PowerBook note. The two triangles in the lower left are scroller buttons. S CHLIMMER H ERMENS portrays a screen snapshot of the software operating in the contextual prompting mode for a PowerBook note. The software s second mode presents an interactive graphical interface. Instead of requiring the user to write out the text of a note, the software presents a radio button and check box interface what we call a button box interface . With this, the user may select from text fragments, portions of notes called descriptive terms , by tapping on radio buttons or check boxes with the pen interface device. Each selection from the button box interface is added to the current note. Intuitively , check boxes are generated to depict optional descrip tive terms, whereas radio button panels are generated to depict alternate, exclusive descrip tive terms. For user convenience, the radio buttons are clustered into panels and are sorted alphabetically in ascending order from top to bottom. To allow the user to add new descrip tive terms to a button box panel, an additional blank button is included at the bottom of each. When the user selects a radio button item, the graphical interface is expanded to depict addi tional choices corresponding to descriptive terms that follow syntactically . The software indicates its predictions by preselecting the corresponding buttons and highlighting them in green. The user may easily override the default selection by tapping the desired button. Figure portrays a screen snapshot of the software operating in the interactive graphical interface mode for a PowerBook note. The software is in prompting mode when a user begins to write a note. If the learned syn tax for the domain of the note is suf ciently mature see Section , Constructing a Button Box Interface , then the software can switch into the button box mode. To indicate this to the user, a mode switch depicted as a radio button is presented for the user s notice. A conve nient and unobtrusive location for this switch is just below the completion button. In keeping with the color theme, the mode switch also has a green hue. If the user taps this switch, the written text is removed , and the appropriate radio buttons and check boxes are inserted. The system automatically selects buttons that match the user written text. As the user makes additional selections, the interface expands to include additional buttons. When the user nishes a note, in either mode, the software returns to prompting mode in anticipation of another note. Because the interface is constructed from a learned syntax, as the softwareFigure Screen snapshot of the note taking software in button box mode for a PowerBook note. S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES renes its representation of the domains of the notes , the button box interface also improves. On line Appendix is a demonstration of the system s operation in each of its two modes. .Learning a Syntax To implement the two modes of the note taking software, the system internally learns two structures. To characterize the syntax of user s notes, it learns nite state machines FSMs . To generate predictions, it learns decision tree classi ers situated at states within the FSMs. In order to construct a graphical user interface, the system converts a FSM into a set of buttons. This section describes the representation and method for learning FSMs. The next section discusses learning of the embedded classi ers. . Prior to learning a nite state machine, the user s note must rst be converted into a sequence of tokens. Useful tokenizers can be domain independent. However , handcrafted domain speci c tokenizers lead to more useful representations. The generic tokenizer used for the results reported here uses normal punctuation, whitespace, and alpha numeric charac ter boundaries as token delimiters. For example, our generic tokenizer splits the sample PowerBook note in Example into the following tokens NULL K PowerBook , . MB and MB Int. Drives , Baud FAX Modem . The token NULL is prepended by the tokenizer . This convention simpli es the code for constructing a FSM. . a Finite State Machine Deterministic nite state machines FSMs are one candidate approach for describing the syntax of a user s notes because they are well understood and relatively expressive. More over, Angluin and Berwick and Pilato present a straightforward algorithm for learning a speci c subclass of FSMs called k reversible FSMs. The algorithm is incremental . Of the functionality described here, our prototype implements all but the transition from button box to contex tual prompting. The mechanism for such a transition is machine dependent and is not germane to this research. S CHLIMMER H ERMENS and does not suf fer from presentation order ef fects. Berwick and Pilato de ne a k reversible FSM as A regular language is k reversible , where k is a non negative integer , if whenever two prexes whose last k wor ds tokens match have a tail in common, then the two pre xes have all tails in common. In other words, a deterministic nite state automaton DF A FSM is k reversible if it is deterministic with lookahead k when its sets of initial and nal states are swapped and all of its arcs transitions are reversed. Given a list of tokens, the k reversible FSM algorithm rst constructs a pre x tree, where all token sequences with common k leaders share a k length path through the FSM. For example, Figure depicts a simple FSM constructed for a single fabric pattern note. The text of the user s note was converted into a sequence of tokens. Then a transition was created for each token and a sequence of states was created to link them together . One state serves as the initial state, and another indicates the completion of the sequence. For convenience, this latter, terminal state is depicted with a double circle. If the FSM is able to nd a transition for each token in the sequence, and it arrives at the terminal state, then the FSM accepts the token sequence as an instance of the language it de nes. Figure depicts the same FSM after another path has been added corresponding to a second fabric pattern note Example . Now the FSM will accept either note if expressed as a sequence of tokens. This FSM is a trivial pre x tree because only the rst state is shared between the two paths.Figure a Degenerate finite state machine after processing a single fabric pattern note, and b prefix tree finite state machine after adding a second fabric pattern note cf. Example . NULL Butterickstart terminal a Size dress NULL NULL Butterick Butterickstart terminalterminalSize Size top b S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES A prex tree is minimal for observed token sequences, but it may not be general enough for use in prediction. The pre x tree is, in essence, an expensive method for memorizing token sequenceswhich is not the desired result. For the sake of prediction, it is desirable to have a FSM that can accept new , previously unseen combinations of tokens. The pre x tree automaton can be converted into a more general FSM by mer ging some of its states. A particular method for doing this converts a pre x tree into a k reversible FSM via Angluin s algorithm. The algorithm mer ges states that have similar transitions, and it creates a FSM that accepts all token sequences in the pre x tree, as well as other candidate sequences. Table lists the three rules for deciding when to mer ge a pair of states in a pre x tree to form a k reversible FSM. In the special case where k equals zero, all states have a common k leader, and Rule ensures that there will be only one accepting state. Because the rules in Table must be applied to each pair of states in the FSM, and because each time a pair of states is mer ged the process must be repeated, the asymptotic complexity of the process is O , where is the number of states in the FSM. Applying these rules to the pre x tree in Figure with k equal to zero results in a FSM depicted in Figure . Notice that the rst two states have been mer ged to make the FSM deterministic Rule . The accepting states have also been mer ged in compliance with Rule . The resulting FSM has fewer states but is not more general. It only accepts the two token sequences originally seen. Extending this example, Figure illustrates the addition of a third fabric pattern note as a pre x tree path to the FSM. Reapplying the rules results in the FSM shown in Figure . The rst two states have been mer ged as before through the action of the determinism Rule . Note that a pair of latter states have also been mer ged because they share a common zero leader true of all pairs of states and because they transition to the common terminal state on the token dress . Figure depicts a more sophisticated result it shows a learned zero reversible FSM for notes about PowerBook computers. This example shows that the model number is never followed by a speci cation for an internal oppy drive, but that other model numbers are. Any model may have an external oppy drive. Note that there is a single terminal state. Whitespace and punctuation have been eliminated for clarity in the gure. The rules listed in Table are generalization operators that allow the FSM to accept previously unobserved sequences. Whenever two or more states are mer ged into one, the FSM will accept more sequences than before if the new state is at the tail end of more transi tions than one of the previous states and if the new state is at the head end of at least one transition. For example, the state just after State in Figure was mer ged from several previous states and generalizes memory sizes for PowerBook models. These rules comprise a heuristic bias and may be too conservative. For example, Figure depicts a FSM for notesA k leader is de ned as a path of length k that accepts in the given state. Merge any two states if either of the following is true .Another state transitions to both states on the same token or This enforces determinism. .Both states have a common k leader and a.Both states are accepting states, or b.Both states transition to a common state via the same token. Table FSM state merging rules from Angluin, . S CHLIMMER H ERMENS about fabric patterns. Many of the states prior to the accepting state could be usefully merged, but using only the rules listed in Table , many more notes will have to be processed before this happens. If the FSM in Figure were rendered as a button box interface, it would reect little of the true structure of the domain of fabric patterns. Table lists specializations of Rules and and an additional pair of rules we developed to make the FSM generalize more readily . Note that the parameter k has been set to zero in Rule and to one in Rule . Effectively, two states are mer ged by Rules or if they share an incoming or outgoing transition. Rule is a Kleene rule that encourages the FSM to generalize the number of times a token may appear in a sequence. If one state has a transition to another , then mer ging them will result in a transition that loops from and to the newly mer ged state. Figure depicts a FSM for notes about fabric patterns learned using all three generalization rules in Table . The resulting FSM accurately captures the syntax of the user s fabric pattern notes and correctly indicates the syntactically optional tokens that may appear at the end of note. When rendered as a button box interface, it clearly depicts the user s syntax as illustrated later by Figure . The added generalization rules may have only mar ginal effects on the systems ability to accurately predict a completion as the user writes out a note as Table below indicates . Their purpose is to improve the quality of the custom interface. Cohen uses an interesting alternative representation for learning a syntactic form. The goal in his work is to guide the generation of proof structures. Intuitively , the represen tation is a nite state machine that accepts a tree rather than a sequence, and for this reason it is termed a tree automaton. Like the rules in Tables and , tree automatons are generalizedFigure a Finite state machine after processing two fabric pattern notes and applying state merging rules in Table , and b prefix tree finite state machine after adding a third fabric pattern note. dress NULL Butterickstart terminalSize Size top a dress dress NULL NULL Butterick Butterickstart terminal terminalSize Size Size top b S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES by merging states that share similar transitions. Oddly enough, one motivation for using tree automatons is that they are less likely to introduce extraneous loops, the opposite of the problem with the original FSM mer ging rules in Table . It is not clear how to map the sequence of tokens in the user s notes into a tree structure, but the less sequential nature of the tree automaton may help alleviate sequencing problems in rendering the custom user interface see Section , Observations Limitations . . To use the nite state machine for prediction, the software needs a strategy for dealing with novel tokens. For example, when the user takes a note about a PowerBook computer with aFigure Sample finite state machine after processing three fabric pattern notes. dress NULL Butterickstart terminalSize Size Size top Merge any two states if any of the following are true .Another state transitions to both states on the same token or This enforces determinism. .Both states have a common leader and a.Both states are accepting states, or b.Both states transition to a common state via the same token or .Both states have a common leader and a.Both states transition to a common state via any token, or b.One transitions to the other via any token. Table Extended FSM state merging rules. S CHLIMMER H ERMENS FAXbis . Kv . ExtDrives . and Drive Drivesand . MBIntMBandMB . NULLstart terminal , Battery, Case, Charger, FPU, Video Figure Zero reversible FSM characterizing PowerBook notes cf. Example . S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES new memory con guration, the FSM will not have a transition for the rst token. If the soft ware is to prompt the user , then it must have a means for deciding where novel tokens lie in a notes syntaxwhich state to predict from. Without such a mechanism, no meaningful prediction can be generated after novel tokens. A state may not have a transition for the next token. In general, this is a single symptom with three possible causes a novel token has been inserted, a suitable token has been omitted and the next token would be accepted by a subsequent state, or a token has been simply replaced by another in the syntax. For example, in the sequence of tokens NULL , , K , PB , is a novel token, a familiar memory size has been omitted, and PowerBook has been replaced by PB . An optimal solution would identify the state requiring a minimum number of insertions, omissions, and replacements necessary to parse the new sequence. An efcient, heuristic approximation does a greedy search using a special marker . Each time the marked state in the FSM has a transition for the next token written by the user , the marker is moved forward, and a prediction is generated from that state. When there is no transition for the next token, a greedy search is conducted for some state including the marked one and those reachable from it that has a transition for some token including the next one and those following . If such a state is found, the marker is moved forward to that state, tokens for the transitions of skipped states are assumed omitted, and novel tokens are assumed inserted. If no state past the marker has a transition for any of the remaining tokens, the remaining tokens are assumed to be replacements for the same number of the most likely transitions the marker is not moved. If the user writes a subsequent token for which some state has a transition, theTop SkirtTop Skirt JumperDress Jumper Dress Dress Dress Dress Suze Size Size Size Size Size Size Size Size McCall s Butterick NULLstart terminal Figure Zero reversible finite state machine characterizing fabric pattern notes learned using merging rules listed in Table . S CHLIMMER H ERMENS marker is moved as described above, and the syntax of the user s note is realigned with the learned syntax. Continuing with the simple PowerBook example, the marker is moved to State of the FSM in Figure because the initial state had a transition for the rst token NULL . Because State doesnt have a transition for the next token , a greedy search is conducted to nd a nearby state that accepts either , K , or PB . The state just before State accepts K , so the marker is moved to that state. Another greedy search is started to nd a state that accepts PB . Because one cannot be found, the heuristic parsing assumes that it should skip to the next transition. In this case the one labeled PowerBook . Consequently , the system generates a prediction from State to prompt the user . . Finite State Machines If the user decides to take notes about multiple domains, it may be necessary to learn a sepa rate syntax for each domain. For example, a single syntax generalized over both the Power Book and fabric pattern notes is likely to yield confusing predictions and an unnatural user interface. Maintenance of multiple nite state machines is an instance of the clustering prob lemdeciding which notes should be clustered together to share a FSM. As Fisher discusses, this involves a trade of f between maximizing similarity within a cluster and mini mizing similarity between clusters. Without the rst criteria, all notes would be put into a single cluster . Without the second criteria, each note would be put into its own cluster . One obvious approach would be to require the user to prepend each note with a unique token to identify each note s domain. This simpli es the clustering computation. All notes sharing the rst token would share a FSM. However , with this scheme, the user would haveTop Skirt JumperJumper McCall s Butterick NULLstart terminalSize Sizes Figure Finite state machine characterizing fabric pattern notes learned using extended rules in Table . Compare to zero reversible finite state machine for the same domain in Figure . S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES to remember the identifying token or name for each domain. An interface could provide a pop up list of all previously used domain identi ers. This is not satisfactory because it requires overhead not needed when taking notes on paper . An alternative approach doesn t require any extra ef fort on the part of the user . A new note is grouped with the FSM that skips the fewest of its tokens. This heuristic encourages within cluster similarity because a FSM will accept new token sequences similar to those it summarizes. To inhibit the formation of single note FSMs, a new FSM is constructed only if all other FSMs skip more than half of the new note s tokens. This is a parametrized solution to encourage between cluster dissimilarity . .Learning Embedded Classi ers Finite state machines are useful representations for capturing the syntax of a user s notes, and they are easy to learn. When predicting a note s completion, it is essential that a predic tion be made from the correct state in the FSM as discussed above . It is also necessary to decide whether to terminate indicating acceptance of the note or continue prediction, and, in the later case, which transition to predict. To facilitate these decisions, the FSM can main tain a count of how many times parsing terminated and how many times each transition was taken. Prediction can then return the option with the maximum frequency . Figure depicts a FSM for which this method will prove insuf cient. There is only one state, an accepting state, and the transition corresponding to the token X is optional. This corresponds to a check box interface item. There are two problems with a frequency based prediction. First, the FSM does not indicate that the transition is to be taken at most once, yet this is quite clear from the user interface. Second, simple frequency based prediction would always recommend termination and never the transition. The FSM accepts whether the box is checked or not, thus the frequency of termination is greater than or equal to the frequency of the transition. This problem arises whenever there is a loop. Embedding general classi ers in a FSM can alleviate some of the FSM s representational shortcomings. For example, in the FSM depicted in Figure , a decision tree embedded in this state easily tests whether the transition has already been taken and can advise against repeating it. Moreover , a classi er can predict based on previous transitions rather than just the frequency of the current state s transitions. Therefore, a decision tree embedded in the state of Figure can predict when the transition should be taken as a function of other , earlier tokens in the sequence. Table lists sample decision trees embedded in states of the FSM depicted in Figure . The rst tree tests which token was parsed by a distant state, in effect augmenting the FSM representation. It relates memory size to hard disk capacity small amounts of memory correlate with a small hard disk . The second tree prevents an optional loop from being taken a second time by testing to see if the state has yet been visited during a parse of the note. After processing additional notes, this second decision treeXstart terminal Figure Simple finite state machine with one state. S CHLIMMER H ERMENS becomes more complex as the system tries to predict which PowerBook s have FAX modems and which do not. A classier is trained for each state in the FSM which a has more than one transition, or b is marked as a terminal state but also has a transition. The classi ers are updated incre mentally after the user nishes each note. The classi ers training data are token sequences parsed at this state. The class value of the data is the transition taken from, or termination at, this state by the token sequences. Only those classi ers whose states are used in a parse are updated. The attributes of the data are the names of states prior to this one, and the values of the attributes are the transitions taken from those states. A distinct attribute is de ned each time a state is visited during a given parse, so when a loop transition is taken a speci c attribute re ects this fact. For any of the attributes, if the corresponding state was not visited while parsing the token sequence, the attribute has a special, empty value. Consider the PowerBook FSM shown in Figure . A classier would be embedded at States , , , , , , . A training example corresponding to the note in Example for the classier at State would be Attributes Values NIL Drives , FAX Modem Class TERMINATE . Note that there is no value for State , denoting that it wasn t visited during the parse of Example . Also there are two attributes for State denoting that it has been visited twice. The classi er gives informed advice about which transition to take or whether to termi nate. The FSM in turn gives the classi er a speci c context for operation. If only a single classier were used to predict the next token, it would be hard pressed to represent the dif fer ent predictions required. The domain is naturally narrowed by the FSM and therefore reduces the representational demands on the classi er. Later, we present empirical resultsDecision tr ee embedded in State If State exited with Then predict Else if with Then predict Else if with Then predict Else if with Then predict .Decision tr ee embedded in State If State has not been visited Then predict FAX Else if State exited with FAX Then predict Modem . Table Sample decision trees embedded in the finite state machine depicted in Figure . S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES comparing a single classi er to a set of classi ers embedded in a FSM. The ndings there show that the latter outperforms the former , conrming the intuition that learning is more effective if situated within a narrow context. From the classi ers point of view , the learning task is non stationary . The concept to be learned is changing over time because the structure of the FSM is changing. When two states are merged, one of the two classi ers is discarded. The other is now embedded in a dif ferent position in the FSM, and it sees dif ferent training data. Similarly , when other states are merged, the attributes of the training data also change. To help mitigate this ef fect, the new state takes the oldest identi er assigned to the two mer ged states. Empirical results in Table illustrate that the FSM does not have to be xed before the classi er can learn useful information. .Contextual Pr ompting In the prompting mode, the software continuously predicts a likely completion as the user writes out a note. It presents this as a default next to the completion button. The button s saturation ranges from white to green in proportion to the con dence of the prediction. If the user taps the completion button, the prompt text is inserted at the end of the current note. A completion is generated by parsing the tokens already written by the user , nding the last state visited in the FSM, and predicting the next most likely transition or termination . This process is repeated until a stopping criterion is satis ed, which is discussed below . If the last token written by the user is incomplete, matching only a pre x of a state s transition, then the remainder of that transition is predicted. If the last token matches more than one transition, a generalized string is predicted using special characters to indicate the type and number of characters expected. If a digit is expected, a is included if a letter , an a is included if either are possible, a ? is included and if some transition s tokens are longer than others, a is appended to the end . For example, if the user has written PowerBook , the possible values for PowerBook models of , , , and are generalized, and the prompt is . A simple calculation is used to compute the con dence of the prediction and set the buttons color saturation. It is the simple ratio where is the frequency of the predicted arc or terminate i.e., the number of times this choice was taken while parsing previously observed notes , is the total frequency of all arcs and terminate , and is the number of tokens skipped during heuristic parsing cf. Section ., Parsing . Condence is directly proportional to the simple likelihood of the prediction and is degraded in proportion to the number of tokens the FSM had to skip to get to this point. This information is used in a simple way , so it is unclear if more sophisticated measures are needed. The stopping criterion is used to determine how much of a prompt to of fer the user . At one extreme, only a single token can be predicted. This gives the user little context and may not provide much assistance. At the other extreme, a sequence of tokens that completes the note can be predicted. This may be too lengthy , and the user would have to edit the prompt if selected. The stopping criterion in Table balances these two extremes and attempts to limit prompts to a consistent set of tokens. In particular , Condition stops expanding the promptfprediction f total fprediction f total skipped S CHLIMMER H ERMENS upon reaching a syntactic boundary leading punctuation or upon reaching a semantic boundary falling con dence . .Constructing a Button Box Interface In the button box mode, the software presents an interactive graphical interface. Instead of writing out the note, the user may select note fragments by tapping buttons. To switch from contextual mode to button box mode, a green radio button indicator is displayed below the completion button when the software is con dent about the user s syntax. If the user taps this indicator, the existing text is removed, and the corresponding buttons in the button box inter face are selected. As the user selects additional buttons, the interface dynamically expands to reveal additional choices. Because the interface re ects an improving syntactic representa tion, it also improves with successive notes. The button box interface is a direct presentation of a nite state machine. After the user has written out a token or so of the note, the software nds the FSM that best parses these tokens. The mode switch is presented if the syntax is suf ciently matureif the average number of times each state has been used to parse earlier notes is greater than . If the user selects this indicator , the FSM is incrementally rendered as a set of radio buttons and check boxes. The two user interface item types correspond to optional choices check boxes and exclusive choices radio buttons . Mapping a FSM into these two item types proceeds one state at a time. Given a particular state to be rendered, any transition that starts a path that does not branch and eventually returns back to the state is rendered as a check box a loop . The loop corresponds to syntactically optional information. The label for the check box con sists of each of the transition labels along the looping path. Other non looping transitions are rendered as buttons in a single radio button panel along with an extra, unlabeled button. They correspond to syntactically exclusive information. The label for each radio button consists of each transition label up to the point of a subsequent branch or termination. For example, compare the FSM depicted in Figure and the corresponding button box interface in Figure . Because the transitions for dif ferent radio buttons lead to dif ferent parts of the FSM, it may confuse the user to render the entire FSM at once. So, each branching state is rendered as it is visited. Initially , the rst state in the FSM is rendered. Then, when a radio button is selected, the branching state at the end of its transition path is rendered. Note that check boxes do not trigger additional rendering because the branching state at the end of their loopStop expanding the prompt if any of the following are true .The next prediction is to terminate or .The next prediction is a generalized string or .At least one token has already been predicted and a.The prediction starts with punctuation, or b.The con dence of the prediction is lower or .The next prediction is the same as the last prediction or .More than tokens have already been predicted. Table Stopping criterion for contextual prompting. S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES has already been rendered. This interactive process is repeated as long as the user selects radio buttons that lead to branching states. .Empirical Results We tested the interactive note taking software on notes drawn from a variety of domains. Tables through list sample notes from seven domains in addition to the PowerBook and fabric pattern sample notes listed above . CVA to Mediterranean A AG CVA to Vietnam RA NG Table Sample notes from the airwing domain. Listed above are of the notes about airwing assignments aboard aircraft carriers collected from Grove Miller, . B, , , . , Cyl. , bbl., Pontiac C, , X, . , Cyl. , bbl., Chevrolet Table Sample notes from the engine code domain. Listed above are of the notes about the meaning of engine codes stamped on automobile identification plates collected from Chiltons Repair Tune Up Guide . , Mazda MPV, MI, Pass, , Auto ABS, PL PW, Cruise, Dual Air , Grand Caravan, MI, Pass, , Auto Cruise, Air, Tilt, Tinting Table Sample notes from the minivan domain. Listed above are of the notes about minivan automobiles collected by the first author. Lorus Disney Oversize Mickey Mouse Watch. Genuine leather strap. Seiko Disney Ladies Minnie Mouse Watch. Leather strap. Table Sample notes from the watch domain. Listed above are of the notes about personal watches collected from the Best catalog a department store . S CHLIMMER H ERMENS azatadine maleate Blood thrombocytopenia. CNS disturbed coordination, dizziness, drowsiness, sedation, vertigo. CV palpitations, hypotension. GI anorexia, dry mouth and throat, nausea, vomiting. GU Urinary retention. Skin rash, urticaria. Other chills, thickening of bronchial secretions. brompheniramine maleate Blood aganulocytosis, thrombocytopenia. CNS dizziness, insomnia, irritability, tremors. CV hypotension, palpitations. GI anorexia, dry mouth and throat, nausea, vomiting. GU urinary retention. Skin rash, urticaria. After parenteral administration local reaction, sweating, syncope may occur. Table Sample notes from the antihistamine domain. Listed above are of the notes on the side effects of antihistamines collected from the Nurses Guide to Drugs . Canon FD f ., ., f , ., good sharpness, poor freedom from flare, better freedom from distortion, focal length marked on sides as well as on front of lens Chinon f ., ., f , ., poor sharpness, good freedom from flare, good freedom from distortion, cannot be locked in program mode, which is only a problem, of course, when lens is used on program mode cameras Table Sample notes from the lens domain. Listed above are of the notes about SLR camera normal lenses collected from the Consumer Reports . S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES Summary characteristics of the nine domains are listed in Table together with some simple measures to indicate prediction dif culty. For instance, Column shows the number of notes in the domain. With a larger number of notes, the easier it should be to accurately train a predictive method. Column shows the standard deviation STD of the length of all notes in each domain. It is more likely that a well behaved FSM can be discovered when STD is low . In this and successive tables, the domains are ranked by STD. Column presents the percentage of unique tokens in the notes. The fewer novel tokens a note has, the more likely that successive tokens can be predicted. This measure places an upper bound on predictive accuracy . Column shows the percentage of constant tokens, ones that always appear in a xed position. It is easier to predict these constant tokens. Finally , Column indicates the percentage of repeated tokens. When fewer tokens are repeated verbatim within a note, the more likely that the predictive method will not become confused about its locale within a note during prediction. The rst six domains are natural for the interactive note taking task because they exhibit a regular syntax. The last three domains are included to test the software s ability on less suitable domains. Notes from the Antihistamine, Lens, and Raptor domains contain highly variable lists of terms or natural language sentences. Learned FSMs for notes in these domains are unlikely to conver ge, and, in the experiments reported here, only the FSM for the Lens data exceeded the maturity threshold average state usage greater than . . Pr ediction Accuracy Column of Table lists the accuracy of next token predictions made by the software in prompting mode. The rst nine rows list predictive accuracy over all tokens as notes from each of the nine domains are independently processed in the order they were collected. The last row lists predictive accuracy over all tokens as notes from all nine domains are collec tively processed. This simulates a user taking notes about several domains simultaneously . To put these results in context, the table also lists predictive accuracies for several other methods. Column lists the accuracy for a lower bound method. It assumes that each note shares a xed sequence of tokens. Termed common , this method initializes its structure to the . W. . A very large falcon. Three color phases occur blackish, white, and gray brown. All are more uniformly colored than the Peregrine Falcon, which has dark mustaches and hood. . W. . Long winged, long tailed hawk with a white rump, usually seen soaring unsteadily over marshes with its wings held in a shallow V . Male has a pale gray back, head, and breast. Female and young are brown above, streaked below, young birds with a rusty tone. Table Sample notes from the raptor domain. Listed above are of the notes about North American birds of prey collected from Bull Farrand, . S CHLIMMER H ERMENS rst note. It then removes each token in this sequential structure that cannot be found in order in other notes. At best, this method can only pr edict the constant, delimit er like tokens that may appear regularly in notes. Its performance is limited by the percentage of constant tokens reported in Column of Table . It performs best for the PowerBook notes where it learns the following note syntax NULL K PowerBook MB MB Int. . Example The asterisks indicate Kleene star notation. This reads as some sequence of zero or more tokens then the token NULL , followed by zero or more tokens then K , followed by zero or more tokens then PowerBook , and so on. It is less successful for the minivan notes where it learns a simpler syntax NULL K MI Pass . Example Columns and of Table list the accuracy of using a classi er to directly predict the next token without explicitly learning a syntax. In this paradigm, examples are pre xes of token sequences. Attributes are the last token in the sequence, the second to last token, the third to last token, and so on. Class values are the next token in the sequencethe one to be predicted. Column lists the performance of a simple Bayes classi er, and Column lists the performance of an incremental variant of Schlimmer Fisher , . Perhaps surprisingly , these methods perform considerably worse than the simple conjunctive method. Without the bene t of a narrow context provided by the FSM, these methods must implicitly construct representations to detect dif ferences between similar situations that arise within a single note. For example, in the PowerBook notes, a classi er only approach must learn to discriminate between the rst and second occurrence of the MB token. Column of Table lists the accuracy of a more viable prediction mechanism. Based on simple ideas of memorization and termed digram , the method maintains a list of tokens that have immediately followed each observed token. For example, in the fabric pattern domain, this method retains the list of tokens , , , as those that follow the token Size . Each list of follow tokens are kept in order from most to least frequent. To predict the next token, the system looks for the last token written and Domain N Notes N TokensTokens Note STD Unique Constant Repeated Airwing . . Pattern . . Engine Code . . Minivan . . PowerBook . . Watch . . Antihistamine . . Lens . . Raptor . . Table Quantitative properties of the nine domains used to test alternative methods. S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES the most frequent follow token. This method is nearly as ef fective as any other in Table , especially on the combined task when notes from each domain are entered in random order . Laird describes an ef cient algorithm for maintaining higher dimensional n grams, in effect increasing the context of each prediction and ef fectively memorizing longer sequences of tokens. Laird s algorithm builds a Markov tree and incorporates heuristics that keep the size of the tree from growing excessively lar ge. Regrettably , these methods are unsuitable for the interactive note taking software because of the dif culty of using them to construct a custom user interface. It is plausible to construct a panel of exclusive choices based directly on the set of follow tokens, but it is unclear how to identify optional choices corresponding to loops in nite state machines. Moreover , if notes are drawn from dif ferent domains, and those domains share even a single token, then some follow set will include tokens from different domains. Using these follow sets to construct a user interface will unnecessarily confuse the user by introducing options from more than one domain at a time. Column of Table lists the accuracy of prediction based solely on the learned FSMs. Without an embedded classi er, this method must rely on prediction of the most common transition or termination from each state. Because the prediction is based on simple counts as noted in Section , Learning Embedded Classi ers , this method never predicts optional transitions. Columns and of Table list the accuracy of predicting using FSMs and embedded classiers. The classi ers used are simple Bayes and the incremental , respectively . The latter outperforms either the FSM alone or the FSM with embedded Bayes classi ers. If the system only makes predictions when its con dence measure is greater than ., the accu racy is signi cantly dif ferent for the Engine Code, Minivan, Lens, and Raptor domains, ranging between and percentage points of improvement. Column of Table lists an estimate of the upper bound on predictive accuracy . This was calculated by assuming that prediction errors were only made the rst time each distinct token was written. Domain Common Bayes FSM Upper Airwing Pattern Engine Code Minivan PowerBook Watch Antihistamine Lens Raptor Combined Table Percentage of tokens correctly predicted as a function of the learning method. S CHLIMMER H ERMENS . Decisions The note taking software embodies a number of design decisions. Table lists the ef fects of these decisions on predictive accuracy by comparing versions of the software with and with out each design feature. The rst column lists the predictive accuracy for the software s nominal con guration. Column lists the accuracy data for a slightly dif ferent generic tokenizer . Accuracy is higher for some domains, lower for others. A custom built tokenizer is one way to incorporate knowledge about the domain. Columns and show the accuracy for the system using only the original two FSM mer ging rules cf. Table and all but the last merging rule cf. Table , respectively . The decreased structural generality tends to lower predictive accuracy , but the embedded classi ers help compensate for the reduced accuracy. Column lists the accuracy for when the FSM does not heuristically continue parsing upon encountering a token for which there is no immediate transition. As expected, accuracy suffers considerably in some domains because a novel token in a sequence completely foils any subsequent prediction. Columns and list accuracy for dif ferent values of the free parameter controlling the clustering of notes together into a FSM. There is little effect on predictive accuracy in this case. Column shows the accuracy for when embedded classi ers do not use information about repeated states in the FSM. Without this information, the classi ers cannot predict that a loop transition should be taken exactly once. Surprisingly , elimination of this feature has little ef fect on accuracy . Column lists the accu racy for when the embedded classi ers associated with a pair of FSM states are discarded when the states are mer ged. Finally , Column lists the accuracy for when a new FSM state is assigned a unique ID rather than the ID of the oldest of the two mer ged states. . Button Box Interfaces In addition to Figure , Figures through depict button box interfaces for the ve other well behaved note taking domains listed at the top of Table . These interfaces are visual and offer the user an or ganized view of their notes, presenting options in a natural way . However , whenever unique tokens are involved, the current software makes no attempt to explicitly generalize tokens. This effect is re ected in the tour dates for the Airwing notes in Figure . Note that the radio button panel consist s of a long series of dates, none of which is likely to be selected for a new note. Domain NormDiff TokensRules ,bRules , RestartAccept AttsDrop ClassrNew IDs Airwing Pattern Engine Code Minivan PowerBook Watch Antihistamine Lens Raptor Table Percentage of tokens correctly predicted as a function of design variations. S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES .Related Work Self customizing so ftware agents have several subjective dimensions on which they can be evaluated an d compared Anticipation Does the system present alternatives without the user having to request them? User interface Is the system graphical, or is it command line oriented? User contr ol Can the user override or choose to ignore predictive actions? Modality If the system has a number of working modes, can the user work in any mode without explicitly selecting one of them? Learning update Is learning incremental, continuous and or real time?Figure Screen snapshot of the note taking software in button box mode for an airwing note. Figure Screen snapshot of the note taking software in button box mode for a fabric pattern note. S CHLIMMER H ERMENS User adjustable Can the user tune the system parameters manually? Here we describe related system s that exhibit propertie s in each of t hese agent dimensions . Our note taking softwar e utilizes the anticipation user interface technique pioneered by Eager Cypher , . Eager is a non intrusive system that learns to perform iterative proce dures by watching the user . As such, it is a learning apprentice, a software agent , and an example of programming by example or demonstration. Situated within the HyperCard envi ronment, it continuously watches a user s actions. When it detects the second cycle of an iteration, it presents an execute icon for the user s notice. It also visually indicates the antic ipated next action by highlighting the appropriate button, menu item, or text selection in green. As the user performs their task, they can verify that Eager has learned the correctFigure Screen snapshot of the note taking software in button box mode for an engine code note. Figure Screen snapshot of the note taking software in button box mode for a minivan note. S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES procedure by comparing its anticipations to their actions. When the user is con dent enough, they can click on the execution icon, and Eager will run the iterative procedure to comple tion. Eager is highly anticipatory , uses a graphical interface, is non obtrusive, non modal, and learns in real time, but is not user adjustable. CAP is an apprenticeship system that learns to predict default values Dent, et al., . Its domain of operation is calendar management, and it learns preferences as a knowledgable secretary might. For example, a professor may prefer to hold a regular group meeting in a particular room at a particular time of day for a particular durationinformation that a secretary would know from experience. CAP collects information as the user manages their calendar, learns from previous meetings, and uses the regularities it learns to of fer default values for meeting location, time, and duration. The learning system is re run each night on the most recent meeting data, and the learned rules are applied for prediction the following day. CAP is also designed to utilize an extensible knowledge base that contains calendar information and a database of personnel information. The system continues to be used to manage individual faculty calendars. Though of fering some intelligence, CAP s user inter face is line oriented and is based on the Emacs editor . Questions asked of the user about meetings are presented using a command line dialog, and the default predictions are displayed one at a time. CAP can be characterized as anticipatory , command line oriented and modal with user control but not user adjustable , where learning is done in batch. Another related system addresses the task of learning to ll out a form Hermens Schlimmer , . The system r ecreates a paper form as an on screen facsimile, allowing the user to view all of the pertinent information at a glanc e. Input typed by the user into the elec tronic form is processed by a central form lling module. When the user completes a form copy, it is printed, and each eld value on the form is forwarded to a learning module a deci sion tree learning method . The learned representations predict default values for each eld on the form by referring to values observed on other elds and on the previous form copy . From the user s point of view , it is as if spreadsheet functions have been learned for each eld of the form. Empirical studies indicate that this system reduced the number of key strokes required of the user by on forms processed over the month period inFigure Screen snapshot of the note taking software in button box mode for a watch note. S CHLIMMER H ERMENS which it was actually used by of ce personnel . This system is unobtrusive, non modal and anticipatory , uses a graphical interface, and updates learning in real time. Maes and Kozierok are addressing the problem of self customizing software at a much more task independent level. They identify three learning opportunities for a software agent observing the user s actions and imitating them, receiving user feedback upon error , and incorporating explicit training by the user . To illustrate the generality of their frame work, they demonstrate simple learning apprentices that help sort the user s electronic mail and schedule meetings. Their initial systems use an instance based case or memory based approach primarily because it allows ef cient update and because it naturally generates a condence in each of its predictions. User s may set thresholds on these predictions, corre sponding to a minimum con dence for when the agent should prompt the user a tell me threshold and a higher minimum con dence for the agent to act immediately on behalf of the user a do it threshold . The framework for learning in this case is anticipatory , utilizes a graphical user interface, is devoted to user control, is non modal, learns in real time, and is user adjustable. A system developed for Macintosh Common Lisp MCL provides a word completion mechanism for word pre xes typed by the user in any window . J. Salem and A. Ruttenber g unpublished have devised MCL methods to display a word completion in the status bar of the each window . If the user desires to add the completion to the window , they simply press the CLEAR key. This word completion mechanism is similar to le name completion in EMACS and the C shell in UNIX systems, except that the word is displayed for the user before it is added. This system is anticipatory unlike the UNIX le completion , is command line oriented but displays the default completion in a graphical window , can be fully controlled by the user , is non modal, learns in real time, is not intended to be user adjustable though knowledgeable MCL programmers could easily make changes to the code . The interactive note taking software we have devised does not require any user program ming. It only receives implicit user feedback when the user chooses to complete a note in a different way than prompted. It does not have any mechanisms for direct user instruction or threshold tuning. In a system designed to be as easy to use as paper , such explicit adjustmen t may be inappropriate. We characterize our system as anticipatory , graphically oriented, and modal due to the switching that takes place when a user wishes to display the button box interface . It allows the user to override default prompts and predictions, and it learns in real time. We have not included features that allow the user to con gure the performance of the agent. .Observations Limitations The interactive note taking software is designed to help users capture information digitally , both to speed entry and improve accuracy , and to support the longer term goal of ef cient retrieval. The software incorporates two distinctive features. First, it actively predicts what the user is going to write. Second, it automatically constructs a custom radio button, check box user interface. This research explores the extremes of FSM learning and prediction, where the system has no explicit a priori knowledge of the note domains. We have tried to design the system so that it can learn quickly , yet adapt well to semantic and syntactic changes , all without a knowledge store from which to draw . It is clear that knowledge in the form of a domain spe cic tokenizer would aid FSM learning by chunking signi cant phrases and relating similar notations and abbreviations. Some preliminary work has shown that, after a few notes have S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES been written, users may create abbreviations instead of writing out whole words. A domain specic tokenizer would be able to relate an abbreviation and a whole word as being in the same class, and therefore allow for more exibility during note taking. For example, a domain speci c tokenizer may recognize that Megabytes , Meg , MB , and M all repre sent the same token for memory sizes. One could imagine a framework that would allow for domain speci c tokenizers to be simply plugged in. The prototype built to demonstrate these ideas was implemented on a conventional, micro computer with keyboard input. As a consequence, it was impossible to evaluate user acceptance of the new interface or the adaptive agent. With newly available computing devices incorporating pen input and handwriting recognition, it should be possible to re engineer the user interface and eld test these ideas with actual users. One aspect of note learning, related to tokenization and the button box user interface display, is the dif culty of generalizing numeric strings or unique tokens. The cardinality of the range of model numbers, telephone numbers, quantities, sizes, other numeric values, and even proper names is very lar ge in some note domains. The nite state machine learning method presented here is incapable of generalizing over transitions from a particular state, and, as a consequence, the current system has the problem of displaying a very lengthy button box interface list. A button is displayed for each value encountered in the syntax of notes, and there may be many choices. For example, a lar ge variety of pattern numbers may be available in the fabric pattern note domain. An appropriate mechanism is desired to deter mine when the list of numeric choices is too lar ge to be useful as a button box interface. The system can then generalize the expected number , indicating the number of digits to prompt the user , for example. This may be helpful to remind the user that a number is expected without presenting an overbearing list of possibilities. Another limitation of the current ef fort lies in the choice of nite state machines to represent the syntax of the user s notes. Notes may not be regular expressions with the consequence that the FSMs may become too lar ge as the learning method attempts to acquire a syntax. This may place an unreasonable demand on memory and lead to reduced prompting effectiveness. The choice of nite state machines also apparently constraints the custom user interface. Because FSM s branch in unpredicabl e ways, button box interface s must be rendered incre mentally. After the user indicates a particular transition by selecting a button , the system can render states reachable from that transition for the user . Ideally, the user should be able to select buttons corresponding to note fragments in any order , allowing them to write down the size before the pattern number , for example. To construct a non modal user interface, a more exible syntactic representation is needed. Several of the low level design decisions employed in this system are crude responses to technical issues . For instance, the decision to render a syntax as a button box interface only if the average number of times each state has been used to parse notes is greater than . This ignores the fact that some parts of the state machine have been used frequently for parsing notes while other parts have rarely been used. Similarly , the particular measure for estimat ing prompting con dence and setting the saturation of the completion button is simplistic and would bene t from a more sound statistical basis. Acknowledgments Anonymous reviewers suggested an additional example in Section , offered some re ne ments to the user interface, graciously identi ed some limitations of the work listed in S CHLIMMER H ERMENS Section , and pointed out some additional related work. Mike Kibler , Karl Hakimian, and the EECS staf f provided a consistent and reliable computing environment. Apple Cambridge developed and supports the Macintosh Common Lisp programming environment. Allen Cypher provided the tokenizer code. This work was supported in part by the National Science Foundation under grant number and by a grant from Digital Equipment Corporation. References Angluin, D. . Inference of reversible languages. Journal of the Association for Computing Machiner y , , . Berwick, R. C., Pilato, S. . Learning syntax by automata induction. Machine Learn ing , , . Bull, J., Farrand, J., Jr . . The Audubon Society Field Guide to North American Birds Eastern Edition . NY Alfred A. Knopf pp. . Chiltons Repair T une Up Guide GM X Body . Randor , PA Chilton Book p. . Cohen, W. W. . Generalizing number and learning from multiple examples in explana tion based learning. Proceedings of the Fifth International Confer ence on Machine Learning pp. . Ann Arbor, MI Mor gan Kaufmann. Consumer Reports , , . Mount Vernon, NY Consumers Union. Cypher, A. . Eager Programming repetitive tasks by example. Proceedings of CHI pp. . New Orleans, LA ACM. Dent, L., Boticario, J., McDermott, J., Mitchell, T., Zabowski, D. . A personal learning apprentice. Proceedings of the T enth National Confer ence on Articial Intelli gence pp. . San Jose, CA AAAI Press. Fisher, D. H. . Knowledge acquisition via incremental conceptual clustering. Machine Learning , , . Grove, M., Miller , J. . North American Rockwell A Vigilante. Arlington, TX Aerofax pp. . Hermens, L. A., Schlimmer , J. C. . A machine learning apprentice for the comple tion of repetitive forms. Proceedings of the Ninth IEEE Confer ence on Articial Intelli gence for Applications . Orlando, FL. Laird, P. . Discrete sequence prediction and its applications. Proceedings of the T enth National Confer ence on Articial Intelligence pp. . San Jose, CA AAAI Press. S OFTWARE A GENTS C OMPLETING P ATTERNS C ONSTRUCTING U SER I NTERFACES Maes, P., Kozierok, R. . Learning interface agents. Proceedings of the Eleventh National Confer ence on Articial Intelligence pp. . Washington, D. C. AAAI Press. Nurses Guide to Drugs . Horsham, P A Intermed Communications pp. . Schlimmer , J. C., Fisher , D. H. . A case study of incremental concept induction. Proceedings of the Fifth National Confer ence on Articial Intelligence pp. . Philadelphia, P A AAAI Press."
"Journal of Arti cial In telligence Researc h Submitted published Reasoning in T erminological Kno wledgeRepresen tation SystemsMartin Buc hheit buchheit R ese ar ch Center for A rti cial Intel ligenc e DFKI Stuhlsatzenhauswe g , D Saarbr ucken , GermanyF rancesco M . Donini donini oma .itAndrea Sc haerf aschaerf oma .itDip artimento di Informatic a e Sistemistic aUniversit a di R oma L a Sapienza , Via Salaria , I R oma , ItalyAbstractT erminologi cal kno wledge represen tation systems TKRSs are to ols for designing andusing kno wledge bases that mak e use of terminological languages or concept languages .W e analyze from a theoretical p oin t of view a TKRS whose capabilities go b ey ond theones of presen tly a v ailable TKRSs . The new features studied , often required in practicalapplications , can b e summarized in three main p oin ts . First , w e consider a highly expres siv e terminological language , called ALC N R , including general complemen ts of concepts ,n um b er restrictions and role conjunction . Second , w e allo w to express inclusion state men ts b et w een general concepts , and terminological cycles as a particular case . Third , w epro v e the decidabilit y of a n um b er of desirable TKRS deduction services lik e satis abilit y ,subsumption and instance c hec king through a sound , complete and terminating calculusfor reasoning in ALC N R kno wledge bases . Our calculus extends the general tec hniqueof constrain t systems . As a b ypro duct of the pro of , w e get also the result that inclusionstatemen ts in ALC N R can b e sim ulated b y terminological cycles , if descriptiv e seman ticsis adopted . . In tro ductionA general c haracteristic of man y prop osed terminological kno wledge represen tation systems TKRSs suc h as kr ypton Brac hman , Pigman Gilb ert , Lev esque , , nikl Kacz marek , Bates , Robins , , ba ck Quan tz Kindermann , , loom MacGregor Bates , , classic Borgida , Brac hman , McGuinness , Alp erin Resnic k , , kris Baader Hollunder , , k rep Ma ys , Dionne , W eida , , and others see Ric h ,editor , W o o ds Sc hmolze , , is that they are made up of t w o di eren t comp o nen ts . Informally sp eaking , the rst is a general sc hema concerning the classes of individualsto b e represen ted , their general prop erties and m utual relationships , while the second is a partial instan tiation of this sc hema , con taining assertions relating either individuals toclasses , or individual s to eac h other . This c haracteristic , whic h the men tioned prop osalsinherit from the seminal TKRS kl one Brac hman Sc hmolze , , is shared also b ysev eral prop osals of database mo dels suc h as Abrial s , candide Bec k , Gala , Na v athe , , and t axis Mylop oulos , Bernstein , W ong , .Retrieving information in actual kno wledge bases KBs built up using one of these sys tems is a deductiv e pro cess in v olving b oth the sc hema TBo x and its instan tiation ABo x .c AI Access F oundation and Morgan Kaufmann Publishers . All righ ts reserv ed .Buchheit , Donini , SchaerfIn fact , the TBo x is not just a set of constrain ts on p ossible ABo xes , but con tains in tensionalinformation ab out classes . This information is tak en in to accoun t when answ ering queriesto the KB .During the realization and use of a KB , a TKRS should pro vide a mec hanical solutionfor at least the follo wing problems from this p oin t on , w e use the w ord c onc ept to refer toa class . KB satis ability are an ABo x and a TBo x consisten t with eac h other ? That is , do esthe KB admit a mo del ? A p ositiv e answ er is useful in the v alidation phase , while thenegativ e answ er can b e used to mak e inferences in refutation st yle . The latter will b eprecisely the approac h tak en in this pap er . . Conc ept Satis ability giv en a KB and a concept C , do es there exist at least onemo del of the KB assigning a non empt y extension to C ? This is imp ortan t not onlyto rule out meaningless concepts in the KB design phase , but also in pro cessing theuser s queries , to eliminate parts of a query whic h cannot con tribute to the answ er . . Subsumption giv en a KB and t w o concepts C and D , is C more general than D inan y mo del of the KB ? Subsumption detects implicit dep endencies among the conceptsin the KB . . Instanc e Che cking giv en a KB , an individual a and a concept C , is a an instanceof C in an y mo del of the KB ? Note that retrieving all individuals describ ed b y agiv en concept a query in the database lexicon can b e form ulated as a set of parallelinstance c hec kings .The ab o v e questions can b e precisely c haracterized once the TKRS is giv en a seman tics see next section , whic h de nes mo dels of the KB and giv es a meaning to expressionsin the KB . Once the problems are formalized , one can start b oth a theoretical analysisof them , and ma yb e indep enden tly a searc h for reasoning pro cedures accomplishing thetasks . Completeness and correctness of pro cedures can b e judged with resp ect to the formalstatemen ts of the problems .Up to no w , all the prop osed systems giv e incomplete pro cedures for solving the ab o v eproblems , except for kris . That is , some inferences are missed , in some cases withouta precise seman tical c haracterization of whic h ones are . If the designer or the user needs more complete reasoning , she he m ust either write programs in a suitable programminglanguage as in the database prop osal of Abrial , and in t axis , or de ne appropriate in ference rules completing the inference capabilities of the system as in ba ck , loom , andclassic . F rom the theoretical p oin t of view , for sev eral systems e .g . , loom it is not ev enkno wn if complete pro cedures can ev er exist i .e . , the decidabilit y of the corresp ondingproblems is not kno wn .Recen t researc h on the computational complexit y of subsumption had an in uence inman y TKRSs on the c hoice for incomplete pro cedures . Brac hman and Lev esque . Also the system classic is complete , but only w .r .t . a non standard seman tics for the treatmen t ofindivid ual s . Complete reasoning w .r .t . standard seman tics for individu als is not pro vided , and is coNP hard Lenzerini Sc haerf , . able Reasoning in Terminological KR Systemsstarted this researc h analyzing the complexit y of subsumption b et w een pure concept ex pressions , abstracting from KBs w e call this problem later in the pap er as pur e subsump tion . The motiv ation for fo cusing on suc h a small problem w as that pure subsumption isa fundamen tal inference in an y TKRS . It turned out that pure subsumption is tractable i .e . , w orst case p olynomial time solv able for simple languages , and in tractable for sligh textensions of suc h languages , as subsequen t researc h de nitely con rmed Neb el , Donini , Lenzerini , Nardi , Nutt , , Sc hmidt Sc hau Smolk a , Donini ,Hollunder , Lenzerini , Marc hetti Spaccamela , Nardi , Nutt , . Also , b ey ond compu tational complexit y , pure subsumption w as pro v ed undecidable in the TKRSs U Sc hild , , kl one Sc hmidt Sc hau , and nikl P atel Sc hneider , .Note that extending the language results in enhancing its expressiv eness , therefore theresult of that researc h could b e summarized as The more a TKRS language is expressiv e ,the higher is the computational complexit y of reasoning in that language as Lev esque rst noted . This result has b een in terpreted in t w o di eren t w a ys , leading to t w odi eren t TKRSs design philosophies . General purp ose languages for TKRSs are in tractable , or ev en undecidable , andtractable languages are not expressiv e enough to b e of practical in terest . F ollo w ing this in terpretation , in sev eral TKRSs suc h as nikl , loom and ba ck incompletepro cedures for pure subsumption are considered satisfactory e .g . , see MacGregor Brill , for loom . Once completeness is abandoned for this basic subproblem ,completeness of o v erall reasoning pro cedures is not an issue an ymore but other issuesarise , suc h as ho w to compare incomplete pro cedures Heinsohn , Kudenk o , Neb el , Pro tlic h , , and ho w to judge a pro cedure complete enough MacGregor , . As a practical to ol , inference rules can b e used in suc h systems to ac hiev e theexp ected b eha vior of the KB w .r .t . the information con tained in it . . A TKRS is b y de nition general purp ose , hence it m ust pro vide tractable andcomplete reasoning to a user . F ollo wing this line , other TKRSs suc h as kr yptonand classic pro vide limited tractable languages for expressing concepts , follo wingthe small can b e b eautiful approac h see P atel Sc hneider , . The gap b et w eenwhat is expressible in the TKRS language and what is needed to b e expressed for theapplication is then lled b y the user , b y a sort of programming with inference rules .Of course , the usual problems presen t in program dev elopmen t and debugging arise McGuinness , .What is common to b oth approac hes is that a user m ust cop e with incomplete reasoning .The di erence is that in the former approac h , the burden of regaining useful y et missedinferences is mostly left to the dev elop ers of the TKRS and the user is supp osed to sp ecifywhat is complete enough , while in the latter this is mainly left to the user . Theseare p erfectly reasonable approac hes in a practical con text , where incomplete pro ceduresand sp ecialized programs are often used to deal with in tractable problems . In our opinionincomplete pro cedures are just a pro visional answ er to the problem the b est p ossible up tono w . In order to impro v e on suc h an answ er , a theoretical analysis of the general problems is to b e done .Previous theoretical results do not deal with the problems in their full generalit y .F or example , the problems are studied in Neb el , , Chapter , but only incomplete , Donini , Schaerfpro cedures are giv en , and cycles are not considered . In Donini , Lenzerini , Nardi , Sc haerf , Sc haerf , the complexit y of instance c hec king has b een analyzed , but only KBswithout a TBo x are treated . Instance c hec king has also b een analyzed in Vilain , ,but addressing only that part of the problem whic h can b e p erformed as parsing .In addition , w e think that the expressiv eness of actual systems should b e enhancedmaking terminological cycles see Neb el , , Chapter a v ailable in TKRSs . Suc h afeature is of undoubtable practical in terest MacGregor , , y et most presen t TKRSscan only appro ximate cycles , b y using forw ard inference rules as in ba ck , classic , loom .In our opinion , in order to mak e terminological cycles fully a v ailable in complete TKRSs , atheoretical in v estigation is still needed .Previous theoretical w ork on cycles w as done in Baader , , Baader , B urk ert ,Hollunder , Nutt , Siekmann , Dionne , Ma ys , Oles , , Neb el , , Sc hild , , but considering KBs formed b y the TBo x alone . Moreo v er , these approac hesdo not deal with n um b er restrictions except for Neb el , , Section . . a basic featurealready pro vided b y TKRSs and the tec hniques used do not seem easily extensible toreasoning with ABo xes . W e compare in detail sev eral of these w orks with ours in Section .In this pap er , w e prop ose a TKRS equipp ed with a highly expressiv e language , includ ing constructors often required in practical applications , and pro v e decidabili t y of problems . In particular , our system uses the language ALC N R , whic h supp orts general comple men ts of concepts , n um b er restrictions and role conjunction . Moreo v er , the system allo wsone to express inclusion statemen ts b et w een general concepts and , as a particular case ,terminological cycles . W e pro v e decidabilit y b y means of a suitable calculus , whic h is de v elop ed extending the w ell established framew ork of constrain t systems see Donini et al . , Sc hmidt Sc hau Smolk a , , th us exploiting a uniform approac h to reasoningin TKRSs . Moreo v er , our calculus can easily b e turned in to a decision pro cedure .The pap er is organized as follo ws . In Section w e in tro duce the language , and w egiv e it a T arski st yle extensional seman tics , whic h is the most commonly used . Using thisseman tics , w e establish relationships b et w een problems whic h allo w us to concen trateon KB satis abilit y only . In Section w e pro vide a calculus for KB satis abilit y , and sho wcorrectness and termination of the calculus . Hence , w e conclude that KB satis abilit y isdecidable in ALC N R , whic h is the main result of this pap er . In Section w e compare ourapproac h with previous results on decidable TKRSs , and w e establish the equiv alence ofgeneral cyclic inclusion statemen ts and general concept de nitions using the descriptiv eseman tics . Finally , w e discuss in detail sev eral practical issues related to our results inSection . . Preliminarie sIn this section w e rst presen t the basic notions regarding concept languages . Then w edescrib e kno wledge bases built up using concept languages , and reasoning services thatm ust b e pro vided for extracting information from suc h kno wledge bases . . Concept LanguagesIn concept languages , concepts represen t the classes of ob jects in the domain of in terest ,while roles represen t binary relations b et w een ob jects . Complex concepts and roles can b e able Reasoning in Terminological KR Systemsde ned b y means of suitable constructors applied to concept names and role names . Inparticular , concepts and roles in ALC N R can b e formed b y means of the follo wing syn tax where Pi for i k denotes a role name , C and D denote arbitrary concepts , andR an arbitrary role C D BnZr ! A j concept name j top concept ? j b ottom concept C u D j conjunction C t D j disjunction C j complemen t R . C j univ ersal quan ti cation R . C j existen tial quan ti cation n R j n R n um b er restrictions R BnZr ! P u u Pk role conjunction When no confusion arises w e drop the brac k ets around conjunctions and disjunctions .W e in terpret concepts as subsets of a domain and roles as binary relations o v er a domain .More precisely , an interpr etation I I I consists of a nonempt y set I the domainof I and a function I the extension function of I , whic h maps ev ery concept to a subsetof Iand ev ery role to a subset of I I . The in terpretation of concept names androle names is th us restricted b y A I I , and P I I I , resp ectiv ely . Moreo v er ,the in terpretation of complex concepts and roles m ust satisfy the follo wing equations fgdenotes the cardinalit y of a set I I ? I C u D I C I D I C t D I C I D I C I In C I R . C I f d Ij d d d R I ! d C Ig R . C I f d Ij d d d R I d C Ig n R I f d Ij f d j d d R Ig n g n R I f d Ij f d j d d R Ig n g P u u Pk I P I P Ik . Kno wledge BasesA kno wledge base built b y means of concept languages is generally formed b y t w o comp o nen ts The intensional one , called TBo x , and the extensional one , called ABo x .W e rst turn our atten tion to the TBo x . As w e said b efore , the in tensional lev el sp ec i es the prop erties of the concepts of in terest in a particular application . Syn tactically ,suc h prop erties are expressed in terms of what w e call inclusion statements . An inclusion , Donini , Schaerfstatemen t or simply inclusion has the formC v Dwhere C and D are t w o arbitrary ALC N R concepts . In tuitiv ely , the statemen t sp eci esthat ev ery instance of C is also an instance of D . More precisely , an in terpretation I satis esthe inclusion C v D if C I D I .A TBo x is a nite set of inclusions . An in terpretation I is a mo del for a TBo x T if Isatis es all inclusions in T .In general , TKRSs pro vide the user with mec hanisms for stating c onc ept intr o ductions e .g . , Neb el , , Section . of the form A D concept de nition , in terpreted as setequalit y , or A D concept sp eci cation , in terpreted as set inclusion , with the restrictionsthat the left hand side concept A m ust b e a concept name , that for eac h concept nameat most one in tro duction is allo w ed , and that no terminolo gic al cycles are allo w ed , i .e . ,no concept name ma y o ccur neither directly nor indirectly withi n its o wn in tro duction .These restrictions mak e it p ossible to substitute an o ccurrence of a de ned concept b y itsde nition .W e do not imp ose an y of these restrictions to the form of inclusions , obtaining statemen tsthat are syn tactically more expressiv e than concept in tro ductions . In particular , a de nitionof the form A D can b e expressed in our system using the pair of inclusions A v Dand D v A and a sp eci cation of the form A D can b e simply expressed b y A v D .Con v ersely , an inclusion of the form C v D , where C and D are arbitrary concepts , cannotb e expressed with concept in tro ductions . Moreo v er , cyclic inclusions are allo w ed in ourstatemen ts , realizing terminological cycles .As sho wn in Neb el , , there are at least three t yp es of seman tics for terminolog ical cycles , namely the least xp oin t , the greatest xp oin t , and the descriptiv e seman tics .Fixp oin t seman tics c ho ose particular mo dels among the set of in terpretations that satisfy astatemen t of the form A D . Suc h mo dels are c hosen as the least and the greatest xp oin tof the ab o v e equation . The descriptiv e seman tics instead considers all in terpretations thatsatisfy the statemen t i .e . , all xp oin ts as its mo dels .Ho w ev er , xp oin t seman tics naturally apply only to xp oin t statemen ts lik e A D ,where D is a function of A , i .e . , A ma y app ear in D , and there is no ob vious w a y toextend them to general inclusions . In addition , since our language includes the constructorfor complemen t of general concepts , the function D ma y b e not monotone , and thereforethe least and the greatest xp oin ts ma y b e not unique . Whether there exists or not ade nitional seman tics that is suitable for cyclic de nitions in expressiv e languages is stillunclear .Con v ersely , the descriptiv e seman tics in terprets statemen ts as just restricting the set ofp ossible mo dels , with no de nitional imp ort . Although it is not completely satisfactory in allpractical cases Baader , Neb el , , the descriptiv e seman tics has b een consideredto b e the most appropriate one for general cyclic statemen ts in p o w erful concept languages .Hence , it seems to b e the most suitable to b e extended to our case and it is exactly the onew e ha v e adopted ab o v e .Observ e that our decision to put general inclusions in the TBo x is not a standard one . Infact , in TKRS lik e kr ypton suc h statemen ts w ere put in the ABo x . Ho w ev er , w e conceiv e able Reasoning in Terminological KR Systemsinclusions as a generalization of traditional TBo x statemen ts acyclic concept in tro ductions ,with their de nitional imp ort , can b e p erfectly expressed with inclusions and cyclic conceptin tro ductions can b e expressed as w ell , if descriptiv e seman tics is adopted . Therefore , w eb eliev e that inclusions should b e part of the TBo x .Notice that role conjunction allo ws one to express the practical feature of subr oles . F orexample , the role ADOPTEDCHILD can b e written as CHILD u ADOPTEDCHILD , where ADOPTED CHILD is a role name , making it a subrole of CHILD . F ollo wing suc h idea , ev ery hierarc h yof role names can b e rephrased with a set of role conjunctions , and vice v ersa .Actual systems usually pro vide for the construction of hierarc hies of roles b y means ofrole in tro ductions i .e . , statemen ts of the form P R and P R in the TBo x . Ho w ev er ,in our simple language for roles , cyclic de nitions of roles can b e alw a ys reduced to acyclicde nitions , as explained in Neb el , , Sec . . . . When role de nitions are acyclic , onecan alw a ys substitute in ev ery concept eac h role name with its de nition , obtaining anequiv alen t concept . Therefore , w e do not consider role de nitions in this pap er , and w econceiv e the TBo x just as a set of concept inclusions .Ev en so , it is w orth to notice that concept inclusions can express kno wledge ab out roles .In particular , domain and range restrictions of roles can b e expressed , in a w a y similar tothe one in Catarci Lenzerini , . Restricting the domain of a role R to a concept Cand its range to a concept D can b e done b y the t w o inclusions R . v C v R . DIt is straigh tforw ard to sho w that if an in terpretation I satis es the t w o inclusions , thenR I C I D I .Com bining subroles with domain and range restrictions it is also p ossible to partiallyexpress the constructor for r ole r estriction , whic h is presen t in v arious prop osals e .g . ,the language F L in Brac hman Lev esque , . Role restriction , written as R C , isde ned b y R C I f d d I Ij d d R I d C Ig . F or example therole DAUGHTER , whic h can b e form ulated as CHILD Female , can b e partially sim ulated b yCHILD u DAUGHTER , with the inclusion v DAUGHTER . Female . Ho w ev er , this sim ulationw ould not b e complete in n um b er restrictions E .g . , if a mother has at least three daugh ters ,then w e kno w she has at least three female c hildren if instead w e kno w that she has threefemale c hildren w e cannot infer that she has three daugh ters .W e can no w turn our atten tion to the extensional level , i .e . , the ABo x . The ABo xessen tially allo ws one to sp ecify instance of relations b et w een individual s and concepts , andb et w een pairs of individuals and roles .Let O b e an alphab et of sym b ols , called individuals . Instance of relationships are ex pressed in terms of memb ership assertions of the form C a R a b where a and b are individuals , C is an ALC N R concept , and R is an ALC N R role . In tu itiv ely , the rst form states that a is an instance of C , whereas the second form states thata is related to b b y means of the role R . , Donini , SchaerfIn order to assign a meaning to mem b ership assertions , the extension function Iof anin terpretation I is extended to individuals b y mapping them to elemen ts of Iin suc h aw a y that a I b Iif a b . This prop ert y is called Unique Name Assumption it ensuresthat di eren t individuals are in terpreted as di eren t ob jects .An in terpretation I satis es the assertion C a if a I C I , and satis es R a b if a I b I R I . An ABo x is a nite set of mem b ership assertions . I is a mo del for an ABo xA if I satis es all the assertions in A .An ALC N R know le dge b ase is a pair hT Ai where T is a TBo x and A is anABo x . An in terpretation I is a mo del for if it is b oth a mo del for T and a mo del for A .W e can no w formally de ne the problems men tioned in the in tro duction . Let b ean ALC N R kno wledge base . . KB satis ability is satis able , if it has a mo del . Conc ept Satis ability C is satis able w .r .t , if there exists a mo del I of suc h thatC I . Subsumption C is subsume d b y D w .r .t . , if C I D Ifor ev ery mo del I of . Instanc e Che cking a is an instance of C , written j C a , if the assertion C a issatis ed in ev ery mo del of .In Neb el , , Sec . . . it is sho wn that the ABo x pla ys no activ e role when c hec kingconcept satis abilit y and subsumption . In particular , Neb el sho ws that the ABo x sub jectto its satis abilit y can b e replaced b y an empt y one without a ecting the result of thoseservices . Actually , in Neb el , , the ab o v e prop ert y is stated for a language less expres siv e than ALC N R . Ho w ev er , it is easy to sho w that it extends to ALC N R . It is imp ortan tto remark that suc h a prop ert y is not v alid for all concept languages . In fact , there arelanguages that include some constructors that refer to the individuals in the concept lan guage , e .g . , the constructor one of Borgida et al . , that forms a concept from a set ofen umerated individuals . If a concept language includes suc h a constructor the individualsin the TBo x can in teract with the individual s in the ABo x , as sho wn in Sc haerf , .As a consequence , b oth concept satis abilit y and subsumption dep end also on the ABo x .Example . Consider the follo wing kno wledge base hT Ai T f TEACHES . Course v Student u DEGREE . BS t Prof Prof v DEGREE . MS DEGREE . MS v DEGREE . BS MS u BS v ?gA f TEACHES john cs DEGREE john Course cs g is a fragmen t of a h yp othetical kno wledge base describing the organization of a univ ersit y .The rst inclusion , for instance , states that the p ersons teac hing a course are either graduatestuden ts studen ts with a BS degree or professors . It is easy to see that is satis able . F orexample , the follo wing in terpretation I satis es all the inclusions in T and all the assertions able Reasoning in Terminological KR Systemsin A , and therefore it is a mo del for I f john cs csb g john I john cs I cs I f john g Prof I Course I f cs g BS I f csb gMS I TEACHES I f john cs g DEGREE I f john csb gW e ha v e describ ed the in terpretation I b y giving only I , and the v alues of I onconcept names and role names . It is straigh tforw ard to see that all v alues of I on complexconcepts and roles are uniquely determined b y imp osing that I m ust satisfy the Equations page .Notice that it is p ossible to dra w sev eral non trivial conclusions from . F or example , w ecan infer that j Student john . In tuitiv ely this can b e sho wn as follo ws John teac hesa course , th us he is either a studen t with a BS or a professor . But he can t b e a professorsince professors ha v e at least t w o degrees BS and MS and he has at most one , thereforehe is a studen t .Giv en the previous seman tics , the problems can all b e reduced to KB satis abilit y or to its complemen t in linear time . In fact , giv en a kno wledge base hT Ai , t w oconcepts C and D , an individual a , and an individual b not app earing in , the follo wingequiv alences hold C is satis able w r t i hT A f C b gi is satis able C is subsumed b y D w r t i hT A f C u D b gi is not satis able j C a i hT A f C a gi is not satis able A sligh tly di eren t form of these equiv alences has b een giv en in Hollunder , . Theequiv alences giv en here are a straigh tforw ard consequence of the ones giv en b y Hollunder .Ho w ev er , the ab o v e equiv alences are not v alid for languages includin g constructors that referto the individuals in the concept language . The equiv alences b et w een reasoning services insuc h languages are studied in Sc haerf , .Based on the ab o v e equiv alences , in the next section w e concen trate just on KB satis abilit y . . Decidabilit y ResultIn this section w e pro vide a calculus for deciding KB satis abilit y . In particular , in Subsec tion . w e presen t the calculus and w e state its correctness . Then , in Subsection . , w epro v e the termination of the calculus . This will b e su cien t to assess the decidabilit y of allproblems , thanks to the relationships b et w een the four problems . . The calculus and its correctnessOur metho d mak es use of the notion of c onstr aint system Donini et al . , Sc hmidt Sc hau Smolk a , Donini , Lenzerini , Nardi , Sc haerf , , and is based on atableaux lik e calculus Fitting , that tries to build a mo del for the logical form ulacorresp onding to a KB . , Donini , SchaerfW e in tro duce an alphab et of v ariable sym b ols V together with a w ell founded totalordering on V . The alphab et V is disjoin t from the other ones de ned so far . Thepurp ose of the ordering will b ecome clear later . The elemen ts of V are denoted b y theletters x y z w . F rom this p oin t on , w e use the term obje ct as an abstraction for individualand v ariable i .e . , an ob ject is an elemen t of O V . Ob jects are denoted b y the sym b olss t and , as in Section , individuals are denoted b y a b .A c onstr aint is a syn tactic en tit y of one of the forms s C sP t x . x C s t where C is a concept and P is a role name . Concepts are assumed to b e simple , i .e . , theonly complemen ts they con tain are of the form A , where A is a concept name . ArbitraryALC N R concepts can b e rewritten in to equiv alen t simple concepts in linear time Doniniet al . , . A constrain t system is a nite nonempt y set of constrain ts .Giv en an in terpretation I , w e de ne an I assignment as a function that maps ev eryv ariable of V to an elemen t of I , and ev ery individual a to a I i .e . , a a Ifor alla O .A pair I satis es the constrain t s C if s C I , the constrain t sP t if s t P I , the constrain t s t if s t , and nally , the constrain t x . x C if C I I notice that do es not pla y an y role in this case . A constrain t system S is satis able ifthere is a pair I that satis es ev ery constrain t in S .An ALC N R kno wledge base hT Ai can b e translated in to a constrain t systemS b y replacing ev ery inclusion C v D T with the constrain t x . x C t D , ev erymem b ership assertion C a with the constrain t a C , ev ery R a b with the constrain tsaP b aPk b if R P u u Pk , and including the constrain t a b for ev ery pair a b of individuals app earing in A . It is easy to see that is satis able if and only if S issatis able .In order to c hec k a constrain t system S for satis abilit y , our tec hnique adds constrain tsto S un til either an eviden t con tradiction is generated or an in terpretation satisfying it canb e obtained from the resulting system . Constrain ts are added on the basis of a suitable setof so called pr op agation rules .Before pro viding the rules , w e need some additional de nitions . Let S b e a constrain tsystem and R P u u Pk k b e a role . W e sa y that t is an R suc c essor of s in Sif sP t sPk t are in S . W e sa y that t is a dir e ct suc c essor of s in S if for some role R ,t is an R successor of s . W e call direct predecessor the in v erse relation of direct successor .If S is clear from the con text w e omit it . Moreo v er , w e denote b y suc c essor the transitiv eclosure of the relation direct successor , and w e denote b y pr e de c essor its in v erse .W e assume that v ariables are in tro duced in a constrain t system according to the ordering . This means , if y is in tro duced in a constrain t system S then x y for all v ariables xthat are already in S .W e denote b y S x s the constrain t system obtained from S b y replacing eac h o ccurrenceof the v ariable x b y the ob ject s .W e sa y that s and t are sep ar ate d in S if the constrain t s t is in S .Giv en a constrain t system S and an ob ject s , w e de ne the function as follo ws S s f C j s C S g . Moreo v er , w e sa y that t w o v ariables x and y are S e quivalent , able Reasoning in Terminological KR Systemswritten x s y , if S x S y . In tuitiv ely , t w o S equiv alen t v ariables can represen t thesame elemen t in the p oten tial in terpretation built b y the rules , unless they are separated .The pr op agation rules are . S !u f s C s C g Sif . s C u C is in S , . s C and s C are not b oth in S . S !t f s D g Sif . s C t C is in S , . neither s C nor s C is in S , . D C or D C . S ! f t C g Sif . s R . C is in S , . t is an R successor of s , . t C is not in S . S ! f sP y sPk y y C g Sif . s R . C is in S , . R P u u Pk , . y is a new v ariable , . there is no t suc h that t is an R successor of s in S and t C is in S , . if s is a v ariable there is no v ariable w suc h that w s and s s w . S ! f sP yi sPk yi j i n g f yi yj j i j n i j g Sif . s n R is in S , . R P u u Pk , . y yn are new v ariables , . there do not exist n pairwise separated R successors of s in S , . if s is a v ariable there is no v ariable w suc h that w s and s s w . S ! S y t if . s n R is in S , . s has more than n R successors in S , . y t are t w o R successors of s whic h are not separated . S ! x f s C g Sif . x . x C is in S , . s app ears in S , . s C is not in S .W e call the rules !t and ! nondeterministic rules , since they can b e applied indi eren t w a ys to the same constrain t system in tuitiv ely , they corresp ond to branc hingrules of tableaux . All the other rules are called deterministic rules . Moreo v er , w e call therules ! and ! gener ating rules , since they in tro duce new v ariables in the constrain tsystem . All other rules are called nongener ating ones . , Donini , SchaerfThe use of the condition based on the S equiv alence relation in the generating rules condition is related to the goal of k eeping the constrain t system nite ev en in presenceof p oten tially in nite c hains of applications of generating rules . Its role will b ecome clearerlater in the pap er .One can v erify that rules are alw a ys applied to a system S either b ecause of the presencein S of a giv en constrain t s C condition , or , in the case of the ! x rule , b ecause of thepresence of an ob ject s in S . When no confusion arises , w e will sa y that a rule is applie dto the constrain t s C or the ob ject s instead of sa ying that it is applied to the constrain tsystem S .Prop osition . In v ariance L et S and S e c onstr aint systems . Then . If S obtaine d fr om S by applic ation of a deterministic rule , then S is satis able ifand only if S satis able . . If S obtaine d fr om S by applic ation of a nondeterministic rule , then S is satis able if S satis able . Conversely , if S is satis able and a nondeterministic rule isapplic able to an obje ct s in S , then it c an b e applie d to s in such a way that it yieldsa satis able c onstr aint system .Pro of . The pro of is mainly a rephrasing of t ypical soundness pro ofs for tableaux meth o ds e .g . , Fitting , , Lemma . . . The only non standard constructors are n um b errestrictions . . Considering the deterministic rules one can directly c hec k that S is a subset of S .So it is ob vious that S is satis able if S satis able . In order to sho w that S satis able if this is the case for S w e consider in turneac h p ossible deterministic rule application leading from S to S . W e assume that I satis es S .If the !u rule is applied to s C u C in S , then S S f s C s C g . Since I satis es s C u C , I satis es s C and s C and therefore S .If the ! rule is applied to s R . C , there m ust b e an R successor t of s in S suc h thatS S f t C g . Since I satis es S , it holds that s t R I . Since I satis ess R . C , it holds that t C I . So I satis es t C and therefore S .If the ! x rule is applied to an s b ecause of the presence of x . x C in S , then S S f s C g . Since I satis es S it holds that C I I . Therefore s C Iand so I satis es S .If the ! rule is applied to s R . C , then S S f sP y sPk y y C g . Since I satis es S , there exists a d suc h that s d R Iand d C I . W e de ne the I assignmen t y d and t t for t y . It is easy to sho w that I satis es S .If the ! rule is applied to s n R , then S S f sP yi sPk yi j i n g f yi yj j i j n i j g . Since I satis es S , there exist n distinct elemen tsd dn Isuc h that s di R I . W e de ne the I assignmen t yi difor i n and t t for t f y yn g . It is easy to sho w that I satis es S . . Assume that S satis ed b y I . W e sho w that S is also satis able . If S obtained from S b y application of the !t rule , then S is a subset of S thereforesatis ed b y I . able Reasoning in Terminological KR SystemsIf S obtained from S b y application of the ! rule to s n R in S , then thereare y t in S suc h that S S y t . W e de ne the I assignmen t as y t and v v for ev ery ob ject v with v y . Ob viously I satis es S . No w supp ose that S is satis ed b y I and a nondeterministic rule is applicableto an ob ject s .If the !t rule is applicable to s C t C then , since S is satis able , s C t C I .It follo ws that either s C I or s C I or b oth . Hence , the !t rule can ob viouslyb e applied in a w a y suc h that I satis es the resulting constrain t system S .If the ! rule is applicable to s n R , then since I satis es S it holds that s n R Iand therefore the set f d Ij s d R Ig has at most n elemen ts .On the other hand , there are more than n R successors of s in S and for eac h R successor tof s w e ha v e s t R I . Th us , w e can conclude b y the Pigeonhole Principle see e .g . ,Lewis P apadimitriou , , page that there exist at least t w o R successors t t ssuc h that t t . Since I satis es S , the constrain t t t not in S . Thereforeone of the t w o m ust b e a v ariable , let s sa y t y . No w ob viously I satis es S y t .Giv en a constrain t system S , more than one rule migh t b e applicable to it . W e de nethe follo wing str ate gy for the application of rules . apply a rule to a v ariable only if no rule is applicable to individuals . apply a rule to a v ariable x only if no rule is applicable to a v ariable y suc h that y x . apply generating rules only if no nongenerating rule is applicable .The ab o v e strategy ensures that the v ariables are pro cessed one at a time according tothe ordering .F rom this p oin t on , w e assume that rules are alw a ys applied according to this strategyand that w e alw a ys start with a constrain t system S coming from an ALC N R kno wledgebase . The follo wing lemma is a direct consequence of these assumptions .Lemma . Stabilit y L et S b e a c onstr aint system and x b e a variable in S . L et agener ating rule b e applic able to x ac c or ding to the str ate gy . L et S e any c onstr aint systemderivable fr om S by any se quenc e p ossibly empty of applic ations of rules . Then . No rule is applic able in S a variable y with y x . S x S x . If y is a variable in S with y x then y is a variable in S , i .e . , the variable y is notsubstitute d by another variable or by a c onstant .Pro of . . By con tradiction Supp ose S S ! S ! ! Sn S , where u x g and a rule is applicable to a v ariable y suc h that y x in S . Thenthere exists a minimal i , where i n , suc h that this is the case in Si . Note that i infact , b ecause of the strategy , if a rule is applicable to x in S no rule is applicable to y in S .So no rule is applicable to an y v ariable z suc h that z x in S Si BnZr . It follo ws thatfrom Si BnZr to Si a rule is applied to x or to a v ariable w suc h that x w . By an exhaustiv e , Donini , Schaerfanalysis of all rules w e see that whic hev er is the rule applied from Si BnZr to Si no newconstrain t of the form y C or y Rz can b e added to Si BnZr , and therefore no rule is applicableto y in Si , con tradicting the assumption . . By con tradiction Supp ose S x S x . Call y the direct predecessor of x , then arule m ust ha v e b een applied either to y or to x itself . Ob viously w e ha v e y x , thereforethe former case cannot b e b ecause of p oin t . A case analysis sho ws that the only ruleswhic h can ha v e b een applied to x are generating ones and the ! and the ! rules . Butthese rules add new constrain ts only to the direct successors of x and not to x itself andtherefore do not c hange x . . This follo ws from p oin t . and the strategy .Lemma . pro v es that for a v ariable x whic h has a direct successor , x is stable ,i .e . , it will not c hange b ecause of subsequen t applications of rules . In fact , if a v ariablehas a direct successor it means that a generating rule has b een applied to it , therefore Lemma . . from that p oin t on x do es not c hange .A constrain t system is c omplete if no propagation rule applies to it . A complete systemderiv ed from a system S is also called a c ompletion of S . A clash is a constrain t systemha ving one of the follo wing forms f s ?g f s A s A g , where A is a concept name . f s n R g f sP ti sPk ti j i n g f ti tj j i j n i j g ,where R P u u Pk .A clash is eviden tly an unsatis able constrain t system . F or example , the last caserepresen ts the situation in whic h an ob ject has an at most restriction and a set of R successors that cannot b e iden ti ed either b ecause they are individuals or b ecause theyha v e b een created b y some at least restrictions .An y constrain t system con taining a clash is ob viously unsatis able . The purp ose of thecalculus is to generate completions , and lo ok for the presence of clashes inside . If S is acompletion of S and S con tains no clash , w e pro v e that it is alw a ys p ossible to constructa mo del for on the basis of S . Before lo oking at the tec hnical details of the pro of , let usconsider an example of application of the calculus for c hec king satis abilit y .Example . Consider the follo wing kno wledge base hT Ai T f Italian v FRIEND . Italian gA f FRIEND peter susan FRIEND . Italian peter FRIEND . Italian susan gThe corresp onding constrain t system S is S f x . x Italian t FRIEND . Italian peterFRIENDsusan able Reasoning in Terminological KR Systemspeter FRIEND . Italian susan FRIEND . Italianpeter susan gA sequence of applications of the propagation rules to S is as follo ws S S f susan Italian g ! rule S S f peter Italian t FRIEND . Italian g ! x rule S S f susan Italian t FRIEND . Italian g ! x rule S S f peter Italian g !t rule S S f susanFRIENDx x Italia n g ! rule S S f x Italian t FRIEND . Italian g ! x rule S S f x FRIEND . Italian g !t rule S S f xFRIENDy y It alian g ! rule S S f y Italian t FRIEND . Italian g ! x rule S S f y FRIEND . Italian g !t rule One can v erify that S is a complete clash free constrain t system . In particular , the ! rule is not applicable to y . In fact , since x S y condition is not satis ed . F rom S onecan build an in terpretation I , as follo ws again , w e giv e only the in terpretation of conceptand role names I f peter susan x y gpeter I peter , susan I susan , x x , y y ,Italian I f x y gFRIEND I f peter susan susan x x y y y gIt is easy to see that I is indeed a mo del for .In order to pro v e that it is alw a ys p ossible to obtain an in terpretation from a completeclash free constrain t system w e need some additional notions . Let S b e a constrain t systemand x , w v ariables in S . W e call w a witness of x in S if the three follo wing conditions hold . x s w . w x . there is no v ariable z suc h that z w and z satis es conditions . and . , i .e . , w isthe least v ariable w .r .t . satisfying conditions . and .W e sa y x is blo cke d by w in S if x has a witness w in S . The follo wing lemma states aprop ert y of witnesses .Lemma . L et S b e a c onstr aint system , x a variable in S . If x is blo cke d then . x has no dir e ct suc c essor and . x has exactly one witness . , Donini , SchaerfPro of . . By con tradiction Supp ose that x is blo c k ed in S and xP y is in S . During thecompletion pro cess leading to S a generating rule m ust ha v e b een applied to x in a systemS . It follo ws from the de nition of the rules that in S ev ery v ariable w x w e hadx s w . No w from Lemma . w e kno w , that for the constrain t system S deriv able fromS for ev ery w x in S w e also ha v e x s w . Hence there is no witness for x in S ,con tradicting the h yp othesis that x is blo c k ed . . This follo ws directly from condition . for a witness .As a consequence of Lemma . , in a constrain t system S , if w is a witness of x then w ha v e a witness itself , since b oth the relations and S equiv alence are transitiv e .The uniqueness of the witness for a blo c k ed v ariable is imp ortan t for de ning the follo wingparticular in terpretation out of S .Let S b e a constrain t system . W e de ne the c anonic al interpr etation IS and the c anon ic al IS assignment S as follo ws . IS f s j s is an ob ject in S g . S s s . s A ISif and only if s A is in S . s t P ISif and only if a sP t is in S or b s is a blo c k ed v ariable , w is the witness of s in S and w P t is in S .W e call s t a P r ole p air of s in IS if s t P IS , w e call s t a r ole p air of s in ISif s t is a P r ole p air for some role P . W e call a role pair explicit if it comes up from case . a of the de nition of the canonical in terpretation and w e call it implicit if it comes upfrom case . b .F rom Lemma . it is ob vious that a role pair cannot b e b oth explicit and implicit .Moreo v er , if a v ariable has an implicit role pair then all its role pairs are implicit and theyall come from exactly one witness , as stated b y the follo wing lemma .Lemma . L et S b e a c ompletion and x a variable in S . L et IS b e the c anonic al inter pr etation for S . If x has an implicit r ole p air x y , then . al l r ole p airs of x in IS ar e implicit . ther e is exactly one witness w of x in S such that for al l r oles P in S and al l P r ole p airs x ,y of x , the c onstr aint w P y is in S .Pro of . The rst statemen t follo ws from Lemma . p oin t . The second statemen t follo wsfrom Lemma . p oin t together with the de nition of IS .W e ha v e no w all the mac hinery needed to pro v e the main theorem of this subsection .Theorem . L et S b e a c omplete c onstr aint system . If S c ontains no clash then it issatis able . able Reasoning in Terminological KR SystemsPro of . Let IS and S b e the canonical in terpretation and canonical I assignmen t for S .W e pro v e that the pair IS S satis es ev ery constrain t c in S . If c has the form sP t ors t , then IS S satis es them b y de nition of IS and S . Considering the ! rule andthe ! rule w e see that a constrain t of the form s s can not b e in S . If c has the forms C , w e sho w b y induction on the structure of C that s C IS .W e rst consider the base cases . If C is a concept name , then s C ISb y de nitionof IS . If C , then ob viously s IS . The case that C ? cannot o ccur since S isclash free .Next w e analyze in turn eac h p ossible complex concept C . If C is of the form C thenC is a concept name since all concepts are simple . Then the constrain t s C is not in Ssince S is clash free . Then s C IS , that is , s ISn C IS . Hence s C IS .If C is of the form C u C then since S is complete s C is in S and s C is in S . Byinduction h yp othesis , s C IS and s C IS . Hence s C u C IS .If C is of the form C t C then since S is complete either s C is in S or s C is inS . By induction h yp othesis , either s C IS or s C IS . Hence s C t C IS .If C is of the form R . D , w e ha v e to sho w that for all t with s t R ISit holds thatt D IS . If s t R IS , then according to Lemma . t w o cases can o ccur . Either t is anR successor of s in S or s is blo c k ed b y a witness w in S and t is an R successor of w in S .In the rst case t D m ust also b e in S since S is complete . Then b y induction h yp othesisw e ha v e t D IS . In the second case b y de nition of witness , w R . D is in S and thenb ecause of completeness of S , t D m ust b e in S . By induction h yp othesis w e ha v e againt D IS .If C is of the form R . D w e ha v e to sho w that there exists a t ISwith s t R ISand t D IS . Since S is complete , either there is a t that is an R successor of s in S andt D is in S , or s is a v ariable blo c k ed b y a witness w in S . In the rst case , b y inductionh yp othesis and the de nition of IS , w e ha v e t D ISand s t R IS . In the second casew R . D is in S . Since w cannot b e blo c k ed and S is complete , w e ha v e that there is at that is an R successor of w in S and t D is in S . So b y induction h yp othesis w e ha v et D ISand b y the de nition of IS w e ha v e s t R IS .If C is of the form n R w e sho w the goal b y con tradiction . Assume that s n R IS . Then there exist atleast n distinct ob jects t tn with s ti R IS i n . This means that , since R P u u Pk , there are pairs s ti P ISj , wherei n and j k . Then according to Lemma . one of the t w o follo wing cases m usto ccur . Either all sPj ti for j k i n are in S or there exists a witness w of s inS with all w Pi ti for j k and i n are in S . In the rst case the ! rule can notb e applicable b ecause of completeness . This means that all the ti s are pairwise separated ,i .e . , that S con tains the constrain ts ti tj i j n i j . This con tradicts the factthat S is clash free . And the second case leads to an analogous con tradiction .If C is of the form n R w e sho w the goal b y con tradiction . Assume that s n R IS . Then there exist atmost m n m p ossibly distinct ob jects t tm with s ti R IS i m . W e ha v e to consider t w o cases . First case s is not blo c k ed inS . Since there are only m R successors of s in S , the ! rule is applicable to s . Thiscon tradicts the fact that S is complete . Second case s is blo c k ed b y a witness w in S .Since there are m R successors of w in S , the ! rule is applicable to w . But this leads tothe same con tradiction . , Donini , SchaerfIf c has the form x . x D then , since S is complete , for eac h ob ject t in S , t D is inS and , b y the previous cases , t D IS . Therefore , the pair IS S satis es x . x D .Finally , since IS S satis es all constrain ts in S , IS S satis es S .Theorem . Correctness A c onstr aint system S is satis able if and only if ther e existsat le ast one clash fr e e c ompletion of S .Pro of . F ollo ws immediately from Theorem . . Clearly , a system con taininga clash is unsatis able . If ev ery completion of S is unsatis able , then from Prop osition . , is unsatis able . . T ermination and complexit y of the calculusGiv en a constrain t system S , w e call nS the n um b er of concepts app earing in S , includingalso all the concepts app earing as a substring of another concept . Notice that nS is b oundedb y the length of the string expressing S .Lemma . L et S b e a c onstr aint system and let S e derive d fr om S by me ans of thepr op agation rules . In any set of variables in S mor e than nSvariables ther e ar eat le ast two variables x , y such that x s .Pro of . Eac h constrain t x C S y con tain only concepts of the constrain t system S .Since there are nS suc h concepts , giv en a v ariable x there cannot b e more than nSdi eren tsets of constrain ts x C in S .Lemma . L et S b e a c onstr aint system and let S e any c onstr aint system derive d fr omS by applying the pr op agation rules with the given str ate gy . Then , in S e ar e at most nSnon blo cke d variables .Pro of . Supp ose there are nS non blo c k ed v ariables . F rom Lemma . , w e kno w thatin S are at least t w o v ariables y , y suc h that y s y . Ob viously either y y ory y holds supp ose that y y . F rom the de nitions of witness and blo c k ed either y a witness of y or there exists a v ariable y suc h that y y and y is a witness of y .In b oth cases y is blo c k ed , con tradicting the h yp othesis .Theorem . T ermination and space complexit y L et b e an ALC N R know le dgeb ase and let n b e its size . Every c ompletion of S is nite and its size is O n .Pro of . Let S b e a completion of S . F rom Lemma . it follo ws that there are at most nnon blo c k ed v ariables in S . Therefore there are at most m ntotal v ariables in S , wherem is the maxim um n um b er of direct successors for a v ariable in S .Observ e that m is b ounded b y the n um b er of R . C concepts at most n plus the sum ofall n um b ers app earing in n um b er restrictions . Since these n um b ers are expressed in binary ,their sum is b ounded b y n . Hence , m n n . Since the n um b er of individuals is alsob ounded b y n , the total n um b er of ob jects in S is at most m n n n n n n ,that is , O n . able Reasoning in Terminological KR SystemsThe n um b er of di eren t constrain ts of the form s C , x . x C in whic h eac h ob ject s canb e in v olv ed is b ounded b y n , and eac h constrain t has size linear in n . Hence , the total sizeof these constrain ts is b ounded b y n n n , that is O n .The n um b er of constrain ts of the form sP t , s t is b ounded b y n n , and eac hconstrain t has constan t size .In conclusion , w e ha v e that the size of S is O n .Notice that the ab o v e one is just a coarse upp er b ound , obtained for theoretical purp oses .In practical cases w e exp ect the actual size to b e m uc h smaller than that . F or example ,if the n um b ers in v olv ed in n um b er restrictions w ere either expressed in unary notation , orlimited b y a constan t the latter b eing a reasonable restriction in practical systems thenan argumen tation analogous to the ab o v e one w ould lead to a b ound of n .Theorem . Decidability Given an ALC N R know le dge b ase , che cking whether is satis able is a de cidable pr oblem .Pro of . This follo ws from Theorems . and . and the fact that is satis able if andonly if S is satis able .W e can re ne the ab o v e theorem , b y giving tigh ter b ounds on the time required todecide satis abilit y .Theorem . Time complexit y Given an ALC N R know le dge b ase , che ckingwhether is satis able c an b e done in nondeterministic exp onential time .Pro of . In order to pro v e the claim it is su cien t to sho w that eac h completion is obtainedwith an exp onen tial n um b er of applications of rules . Since the n um b er of constrain ts ofeac h completion is exp onen tial Theorem . and eac h rule , but the ! rule , adds newconstrain ts to the constrain t system , it follo ws that all suc h rules are applied at most anexp onen tial n um b er of times . Regarding the ! rule , it is applied for eac h ob ject at most asman y times as the n um b er of its direct successors . Since suc h n um b er is at most exp onen tial if n um b ers are co ded in binary w .r .t . the size of the kno wledge base , the claim follo ws .A lo w er b ound of the complexit y of KB satis abilit y is obtained exploiting previousresults ab out the language ALC , whic h is a sublanguage of ALC N R that do es not includen um b er restrictions and role conjunction . W e kno w from McAllester , and indep en den tly from an observ ation b y Nutt that KB satis abilit y in ALC kno wledge basesis EXPTIME hard see Garey Johnson , , page for a de nition and hence itis hard for ALC N R kno wledge bases , to o . Hence , w e do not exp ect to nd an y algorithmsolving the problem in p olynomial space , unless PSP A CE EXPTIME . Therefore , w e donot exp ect to substan tially impro v e space complexit y of our calculus , whic h already w orksin exp onen tial space . W e no w discuss p ossible impro v emen ts on time complexit y .The prop osed calculus w orks in nondeterministic exp onen tial time , and hence impro v esthe one w e prop osed in Buc hheit , Donini , Sc haerf , , Sec . , whic h w orks in deter ministic double exp onen tial time . The k ey impro v emen t is that w e sho w ed that a KB hasa mo del if and only if it has a mo del of exp onen tial size . Ho w ev er , it ma y b e argued thatas it is , the calculus cannot y et b e turned in to a practical pro cedure , since suc h a pro ce dure w ould simply sim ulate nondeterminism b y a second lev el of exp onen tialit y , resulting , Donini , Schaerfin a double exp onen tial time pro cedure . Ho w ev er , the di eren t com binations of conceptsare only exp onen tially man y this is just the cardinalit y of the p o w erset of the set of con cepts . Hence , a double exp onen tial time pro cedure w astes most of the time re analyzingo v er and o v er ob jects with di eren t names y et with the same , in di eren t constrain tsystems . This could b e a v oided if w e allo w a v ariable to b e blo c k ed b y a witness that isin a pr eviously analyze d constrain t system . This tec hnique w ould b e similar to the oneused in Pratt , , and to the tree automata tec hnique used in V ardi W olp er , ,impro ving on simple tableaux metho ds for v arian ts of prop ositional dynamic logics . Sinceour calculus considers only one constrain t system at a time , a mo di cation of the calculusw ould b e necessary to accomplish this task in a formal w a y , whic h is outside the scop e ofthis pap er . The formal dev elopmen t of suc h a deterministic exp onen tial time pro cedure willb e a sub ject for future researc h .Notice that , since the domain of the canonical in terpretation ISis alw a ys nite , w eha v e also implicitl y pro v ed that ALC N R kno wledge bases ha v e the nite mo del pr op erty ,i .e . , an y satis able kno wledge base has a nite mo del . This prop ert y has b een extensiv elystudied in mo dal logics Hughes Cressw ell , and dynamic logics Harel , . Inparticular , a tec hnique , called ltr ation , has b een dev elop ed b oth to pro v e the nite mo delprop ert y and to build a nite mo del for a satis able form ula . This tec hnique allo ws one tobuild a nite mo del from an in nite one b y grouping the w orlds of a structure in equiv alenceclasses , based on the set of form ulae that are satis ed in eac h w orld . It is in teresting toobserv e that our calculus , based on witnesses , can b e considered as a v arian t of the ltrationtec hnique where the equiv alence classes are determined on the basis of our S equiv alencerelation . Ho w ev er , b ecause of n um b er restrictions , v ariables that are S equiv alen t cannotb e group ed , since they migh t b e separated e .g . , they migh t ha v e b een in tro duced b y thesame application of the ! rule . Nev ertheless , they can ha v e the same direct successors ,as stated in p oin t . b of the de nition of canonical in terpretation on page . This w ouldcorresp ond to grouping v ariables of an in nite mo del in suc h a w a y that separations arepreserv ed . . Relation to previous w orkIn this section w e discuss the relation of our pap er to previous w ork ab out reasoning with in clusions . In particular , w e rst consider previously prop osed reasoning tec hniques that dealwith inclusions and terminological cycles , then w e discuss the relation b et w een inclusionsand terminological cycles . . Reasoning T ec hniquesAs men tioned in the in tro duction , previous results w ere obtained b y Baader et al . ,Baader , , Neb el , , Sc hild and Dionne et al . , .Neb el , Chapter considers the language T F , con taining concept conjunction ,univ ersal quan ti cation and n um b er restrictions , and TBo xes con taining p ossibly cyclic concept de nitions , role de nitions and disjoin tness axioms stating that t w o concept namesare disjoin t . Neb el sho ws that subsumption of T F concepts w .r .t . a TBo x is decidable .Ho w ev er , the argumen t he uses is non constructiv e He sho ws that it is su cien t to con able Reasoning in Terminological KR Systemssider nite in terpretations of a size b ounded b y the size of the TBo x in order to decidesubsumption .In Baader , the e ect of the three t yp es of seman tics descriptiv e , greatest x p oin t and least xp oin t seman tics for the language F L , con taining concept conjunctionand univ ersal quan ti cation , is describ ed with the help of nite automata . Baader reducessubsumption of F L concepts w .r .t . a TBo x con taining p ossibly cyclic de nitions of theform A C whic h he calls terminological axioms to decision problems for nite automata .In particular , he sho ws that subsumption w .r .t . descriptiv e seman tics can b e decided in p oly nomial space using B uchi automata . Using results from Baader , , in Neb el , a c haracterization of the ab o v e subsumption problem w .r .t . descriptiv e seman tics is giv enwith the help of deterministic automata whereas B uc hi automata are nondeterministic .This also yields a PSP A CE algorithm for deciding subsumption .In Baader et al . , the atten tion is restricted to the language ALC . In particular ,that pap er considers the problem of c hec king the satis abilit y of a single equation of theform C , where C is an ALC concept . This problem , called the universal satis abil ity pr oblem , is sho wn to b e equiv alen t to c hec king the satis abilit y of an ALC TBo x seeProp osition . .In Baader , , an extension of ALC , called ALCr eg , is in tro duced , whic h supp ortsa constructor to express the transitiv e closure of roles . By means of transitiv e closure ofroles it is p ossible to replace cyclic inclusions of the form A v D with equiv alen t acyclicones . The problem of c hec king the satis abilit y of an ALCr eg concept is solv ed in thatpap er . It is also sho wn that using transitiv e closure it is p ossible to reduce satis abilit yof an ALC concept w .r .t . an ALC TBo x T f C v D Cn v Dn g in to the conceptsatis abilit y problem in ALCr eg w .r .t . the empt y TBo x . Since the problem of conceptsatis abilit y w .r .t . a TBo x is trivially harder than c hec king the satis abilit y of a TBo x ,that pap er extends the result giv en in Baader et al . , .The tec hnique exploited in Baader et al . , and Baader , is based on thenotion of c onc ept tr e e . A concept tree is generated starting from a concept C in orderto c hec k its satis abilit y or univ ersal satis abilit y . The w a y a concept tree is generatedfrom a concept C is similar in a v or to the w a y a complete constrain t system is generatedfrom the constrain t system f x C g . Ho w ev er , the extension of the concept tree metho d todeal with n um b er restrictions and individuals in the kno wledge base is neither ob vious , norsuggested in the cited pap ers on the other hand , the extension of the calculus based onconstrain t systems is immediate , pro vided that additional features ha v e a coun terpart inFirst Order Logic .In Sc hild , some results more general than those in Baader , are obtainedb y considering languages more expressiv e than ALCr eg and dealing with the concept satis a bilit y problem in suc h languages . The results are obtained b y establishing a corresp ondenceb et w een concept languages and Prop ositional Dynamic Logics PDL , and reducing thegiv en problem to a satis abilit y problem in PDL . Suc h an approac h allo ws Sc hild to ndsev eral new results exploiting kno wn results in the PDL framew ork . Ho w ev er , it cannot b eused to deal with ev ery concept language . In fact , the corresp ondence cannot b e establishedwhen the language includes some concept constructors ha ving no coun terpart in PDL e .g . ,n um b er restrictions , or individual s in an ABo x . , Donini , SchaerfRecen tly , an algebraic approac h to cycles has b een prop osed in Dionne et al . , , inwhic h p ossibly cyclic de nitions are in terpreted as determining an equiv alence relation o v erthe terms describing concepts . The existence and uniqueness of suc h an equiv alence relationderiv es from Aczel s results on non w ell founded sets . In Dionne et al . , the sameresearc hers pro v e that subsumption based on this approac h is equiv alen t to subsumption ingreatest xp oin t seman tics . The language analyzed is a small fragmen t of the one used in theTKRS k rep , and con tains conjunction and existen tial univ ersal quan ti cations com binedin to one construct hence it is similar to F L . The di cult y of extending these resultslies in the fact that it is not clear ho w individual s can b e in terpreted in this algebraicsetting . Moreo v er , w e b eliev e that constructiv e approac hes lik e the algebraic one , giv ecoun terin tuitiv e results when applied to non constructiv e features of concept languages asnegation and n um b er restrictions .In conclusion , all these approac hes , i .e . , reduction to automata problems , concept trees ,reduction to PDL and algebraic seman tics , deal only with TBo xes and they don t seem to b esuitable to deal also with ABo xes . On the other hand , the constrain t system tec hnique , ev enthough it w as conceiv ed for TBo x reasoning , can b e easily extended to ABo x reasoning , asalso sho wn in Hollunder , Baader Hollunder , Donini et al . , . . Inclusions v ersus Concept De nitionsNo w w e compare the expressiv e p o w er of TBo xes de ned as a set of inclusions as done inthis pap er and TBo xes de ned as a set of p ossibly cyclic concept in tro ductions of theform A D and A D .Unlik e Baader , and Sc hild , , w e consider reasoning problems dealing withTBo x and ABo x together . Moreo v er , w e use the descriptiv e seman tics for the concept in tro ductions , as w e do for inclusions . The result w e ha v e obtained is that inclusion statemen tsand concept in tro ductions actually ha v e the same expressiv e p o w er . In detail , w e sho w thatthe satis abilit y of a kno wledge base hA T i , where T is a set of inclusion statemen ts ,can b e reduced to the satis abilit y of a kno wledge base hA T suc h that T a setof concept in tro ductions . The other direction , from concept in tro ductions to inclusions , istrivial since in tro ductions of the form A D can b e expressed b y the pair of inclusionsA v D and D v A , while a concept name sp eci cation A D can b e rewritten as theinclusion A v D as already men tioned in Section .As a notation , giv en a TBo x T f C v D Cn v Dn g , w e de ne the concept CTas CT C t D u u Cn t Dn . As p oin ted out in Baader , for ALC , anin terpretation satis es a TBo x T if and only if it satis es the equation CT . This resulteasily extends to ALC N R , as stated in the follo wing prop osition .Prop osition . Given an ALC N R TBox T f C v D Cn v Dn g , an interpr eta tion I satis es T if and only if it satis es the e quation CT .Pro of . An in terpretation I satis es an inclusion C v D if and only if it satis es the equation C t D I satis es the set of equations C t D , , Cn t Dn if and onlyif I satis es C t D u u Cn t Dn . The claim follo ws . able Reasoning in Terminological KR SystemsGiv en a kno wledge base hA T i and a concept A not app earing in , w e de ne thekno wledge base hA T as follo ws A A f A b j b is an individual in gT f A CT u P . A u u Pn . A gwhere P P Pn are all the role names app earing in . Note that T a singleinclusion , whic h could b e also though t of as one primitiv e concept sp eci cation .Theorem . hA T i is satis able if and only if hA T is satis able .Pro of . In order to simplify the mac hinery of the pro of , w e will use for T follo wing logically equiv alen t form T f A v CT A v P . A A v Pn . A g Note that w e use the sym b ol v instead of b ecause no w the concept name A app earsas the left hand side of man y statemen ts , w e m ust consider these statemen ts as inclusions . Supp ose hA T i satis able . F rom Theorem . , there exists a completeconstrain t system S without clash , whic h de nes a canonical in terpretation IS whic h is amo del of . De ne the constrain t system S follo ws S S f w A j w is an ob ject in S gand call IS canonical in terpretation asso ciated to S . W e pro v e that IS a mo del of .First observ e that ev ery assertion in A is satis ed b y IS IS equal to IS exceptfor the in terpretation of A , and A do es not app ear in A . Therefore , ev ery assertion in A also satis ed b y IS , either b ecause it is an assertion of A , or if it is an assertion of theform A b b y de nition of S .Regarding T , note that b y de nition of S , w e ha v e A IS IS IS therefore b othsides of the inclusions of the form A v Pi . A i n are in terpreted as IS , hencethey are satis ed b y IS . Since A do es not app ear in CT , w e ha v e that CT IS CT IS .Moreo v er , since IS satis es T , w e also ha v e , b y Prop osition . , that CT IS IS ,therefore CT IS CT IS IS IS . It follo ws that also b oth sides of the inclusionA v CT are in terpreted as IS . In conclusion , IS es T . Supp ose hA T satis able . Again , b ecause of Theorem . , there exists acomplete constrain t system S clash , whic h de nes a canonical in terpretation IS h is a mo del of . W e sho w that IS also a mo del of .First of all , the assertions in A are satis ed b ecause A A , and IS es ev eryassertion in A . T o pro v e that IS es T , w e rst pro v e the follo wing equation A IS IS Equation is pro v ed b y sho wing that , for ev ery ob ject s IS , s is in A IS . In order to dothat , observ e a general prop ert y of constrain t systems Ev ery v ariable in S a successor ofan individual . This comes from the de nition of the generating rules , whic h add v ariablesto the constrain t system only as direct successors of existing ob jects , and at the b eginningS tains only individuals .Then , Equation is pro v ed b y observing the follo wing three facts , Donini , Schaerf . for ev ery individual b in IS , b A IS . if an ob ject s is in A IS , then b ecause IS es the inclusions A IS P . A IS A IS Pn . A IS , ev ery direct successor of s is in A IS . the successor relation is closed under the direct successor relationF rom the F undamen tal Theorem on Induction see e .g . , W and , , page w e con clude that ev ery ob ject s of IS in A IS . This pro v es that Equation holds .F rom Equation , and the fact that IS es the inclusion A IS CT IS , w e deriv ethat CT IS IS , that is IS es the equation CT . Hence , from Prop osition . , IS es T , and this completes the pro of of the theorem .The mac hinery presen t in this pro of is not new . In fact , realizing that the inclusionsA v P . A A v Pn . A sim ulate a transitiv e closure on the roles P Pn , one canrecognize similarities with the pro ofs giv en b y Sc hild and Baader . The di er ence is that their pro ofs rely on the notion of c onne cte d mo del Baader uses the equiv alen tnotion of r o ote d mo del . In con trast , the mo dels w e obtain are not connected , when theindividuals in the kno wledge base are not . What w e exploit is the w eak er prop ert y thatev ery v ariable in the mo del is a successor of an individual .Note that the ab o v e reduction strongly relies on the fact that disjunction t and com plemen t are within the language . In fact , disjunction and complemen t are necessaryin order to express all the inclusions of a TBo x T inside the concept CT . Therefore , thepro of holds for ALC kno wledge bases , but do es not hold for TKRSs not allo wing for theseconstructors of concepts e .g . , ba ck .F urthermore , for the language F L in tro duced in Section . , the opp osite result holds .In fact , McAllester pro v es that computing subsumption w .r .t . a set of inclusions isEXPTIME hard , ev en in the small language F L . Con v ersely , Neb el pro v es thatsubsumption w .r .t . a set of cyclic de nitions in F L can b e done in PSP A CE . Com biningthe t w o results , w e can conclude that for F L subsumption w .r .t . a set of inclusions andsubsumption w .r .t . a set of de nitions are in di eren t complexit y classes , hence assumingEXPTIME PSP A CE inclusion statemen ts are strictly more expressiv e than conceptde nitions in F L .It is still op en whether inclusions and de nitions are equiv alen t in languages whoseexpressivit y is b et w een F L and ALC . . DiscussionIn this pap er w e ha v e pro v ed the decidabilit y of the main inference services of a TKRS basedon the concept language ALC N R . W e b eliev e that this result is not only of theoreticalimp ortance , but b ears some impact on existing TKRSs , b ecause a complete pro cedure canb e easily devised from the calculus pro vided in Section . F rom this pro cedure , one can buildmore e cien t but still complete ones , as describ ed at the end of Section . , and also b yapplying standard optimization tec hniques suc h as those describ ed in Baader , Hollunder ,Neb el , Pro tlic h , F ranconi , . An optimized pro cedure can p erform w ell for smallsublanguages where reasoning is tractable , while still b eing complete when solving morecomplex tasks . Ho w ev er , suc h a complete pro cedure will still tak e exp onen tial time and able Reasoning in Terminological KR Systemsspace in the w orst case , and it ma y b e argued what could b e its practical applicabili t y . W ecommen t in follo wing on this p oin t .Firstly , a complete pro cedure p ossibly optimized o ers a b enc hmark for comparingincomplete pro cedures , not only in terms of p erformance , but also in terms of missed infer ences . Let us illustrate this p oin t in detail , b y pro viding a blatan t parado x consider themostly incomplete constan t time pro cedure , answ ering alw a ys No to an y c hec k . Ob vi ously this useless pro cedure outp erforms an y other one , if missed inferences are not tak enin to accoun t . This parado x sho ws that incomplete pro cedures can b e meaningfully com pared only if missed inferences are considered . But to recognize missed inferences o v er largeexamples , one needs exactly a complete pro cedure ev en if not an e cien t one lik e ours .W e b eliev e that a fair detection of missed inferences w ould b e of great help ev en when thesatisfaction of end users is the primary criterion for judging incomplete pro cedures .Secondly , a complete pro cedure can b e used for an ytime classi cation , as prop osedin MacGregor , . The idea is to use a fast , but incomplete algorithm as a rst stepin analyzing the input kno wledge , and then do more reasoning in bac kground . In thecited pap er , resolution based theorem pro v ers are prop osed for p erforming this bac kgroundreasoning . W e argue that an y sp ecialized complete pro cedure will p erform b etter than ageneral theorem pro v er . F or instance , theorem pro v ers are usually not sp eci cally designedto deal with ltration tec hniques .Moreo v er , our calculus can b e easily adapted to deal with rules . As outlined in thein tro duction , rules are often used in practical TKRSs . Rules b eha v e lik e one w a y conceptinclusions no con trap ositiv e is allo w ed and they are applied only to kno wn individuals .Our result sho ws that rules in ALC N R can b e applied also to unkno wn individuals ourv ariables in a constrain t system without endangering decidabili t y . This result is to b ecompared with the negativ e result in Baader Hollunder , , where it is sho wn thatsubsumption b ecomes undecidable if rules are applied to unkno wn individuals in classic .Finally , the calculus pro vides a new w a y of building incomplete pro cedures , b y mo difyingsome of the propagation rules . Since the rules build up a mo del , mo di cations to themha v e a seman tical coun terpart whic h giv es a precise accoun t of the incomplete pro ceduresobtained . F or example , one could limit the size of the canonical mo del b y a p olynomial inthe size of the KB . Seman tically , this w ould mean to consider only small mo dels , whic his reasonable when the in tended mo dels for the KB are not m uc h bigger than the size of theKB itself . W e b eliev e that this w a y of designing incomplete pro cedures from ab o v e , i .e . ,starting with the complete set of inferences and w eak ening it , is dual to the w a y incompletepro cedures ha v e b een realized so far from b elo w , i .e . , starting with already incompleteinferences and adding inference p o w er b y need .F urther researc h is still needed to address problems issuing from practical systems . F orexample , to completely express role restrictions inside n um b er restrictions , quali ed n um b errestrictions Hollunder Baader , should b e tak en in to accoun t . Also , the languageresulting from the addition of en umerated sets called one of in classic , and role llersto ALC N R is still to b e studied , although it do es not seem to endanger the ltrationmetho d w e used . Instead , a di eren t metho d migh t b e necessary if in v erse roles are addedto ALC N R , since the nite mo del prop ert y is lost as sho wn in Sc hild , . Finally , theaddition of concrete domains Baader Hansc hk e , remains op en . , Donini , SchaerfAc kno wledgemen tsW e thank Maurizio Lenzerini for the inspiration of this w ork , as w ell as for sev eral discus sions that con tributed to the pap er . W erner Nutt p oin ted out to us the observ ation men tioned at the end of Section , and w e thank him and F ranz Baader for helpful commen tson earlier drafts . W e thank also the anon ymous review ers , whose stim ulating commen tshelp ed us in impro ving on the submitted v ersion .The researc h w as partly done while the rst author w as visiting the Dipartimen to di In formatica e Sistemistica , Univ ersit a di Roma La Sapienza . The third author also ac kno wl edges Y oa v Shoham for his hospitalit y at the Computer Science Departmen t of StanfordUniv ersit y , while the author w as dev eloping part of this researc h .This w ork has b een supp orted b y the ESPRIT Basic Researc h Action N . COM PULOG and b y the Progetto Finalizzato Sistemi Informatici e Calcolo P arallelo of theCNR Italian Researc h Council , LdR Ibridi .ReferencesAbrial , J . . Data seman tics . In Klim bie , J . , Ko eman , K . Eds . , Data BaseManagement , pp . . North Holland Publ . Co . , Amsterdam .Baader , F . . Augmen ting concept languages b y transitiv e closure of roles An alter nativ e to terminological cycles . T ec h . rep . RR , Deutsc hes F orsc h ungszen trumf ur K unstlic he In telligenz DFKI , Kaiserslautern , German y . An abridged v ersion ap p eared in Pr o c . of the Int . Joint Conf . on A rti cial Intel ligenc e IJCAI , pp . .Baader , F . . T erminological cycles in KL ONE based kno wledge represen tation lan guages . T ec h . rep . RR , Deutsc hes F orsc h ungszen trum f ur K unstlic he In telligenz DFKI , Kaiserslautern , German y . An abridged v ersion app eared in Pr o c . of the . Conf . on A rti cial Intel ligenc e AAAI , pp . .Baader , F . , B urk ert , H . J . , Hollunder , B . , Nutt , W . , Siekmann , J . H . . Conceptlogics . In Llo yd , J . W . Ed . , Computational L o gics , Symp osium Pr o c e e dings , pp . . Springer V erlag .Baader , F . , Hansc hk e , P . . A sc hema for in tegrating concrete domains in to conceptlanguages . In Pr o c . of the Int . Joint Conf . on A rti cial Intel ligenc e IJCAI ,pp . Sydney .Baader , F . , Hollunder , B . . A terminological kno wledge represen tation system withcomplete inference algorithm . In Pr o c . of the Workshop on Pr o c essing De clar ativeKnow le dge , PDK , Lecture Notes in Arti cial In telligence , pp . . Springer V erlag .Baader , F . , Hollunder , B . . Em b edding defaults in to terminological kno wledgerepresen tation formalisms . In Pr o c . of the d Int . Conf . on Principles of Know le dgeR epr esentation and R e asoning KR , pp . . Morgan Kaufmann , Los Altos . able Reasoning in Terminological KR SystemsBaader , F . , Hollunder , B . , Neb el , B . , Pro tlic h , H . J . , F ranconi , E . . An empiricalanalisys of optimization tec hniques for terminological represen tation systems . In Pr o c .of the d Int . Conf . on Principles of Know le dge R epr esentation and R e asoning KR , pp . . Morgan Kaufmann , Los Altos .Bec k , H . W . , Gala , S . K . , Na v athe , S . B . . Classi cation as a query pro cessingtec hnique in the CANDIDE seman tic data mo del . In Pr o c . of the IEEE Int . Conf .on Data Engine ering .Borgida , A . , Brac hman , R . J . , McGuinness , D . L . , Alp erin Resnic k , L . . CLASSIC A structural data mo del for ob jects . In Pr o c . of the A CM SIGMOD Int . Conf . onManagement of Data , pp . .Brac hman , R . J . , Lev esque , H . J . . The tractabilit y of subsumption in frame based description languages . In Pr o c . of the Nat . Conf . on A rti cial Intel ligenc eAAAI , pp . .Brac hman , R . J . , Pigman Gilb ert , V . , Lev esque , H . J . . An essen tial h ybridreasoning system Kno wledge and sym b ol lev el accoun ts in KR YPTON . In Pr o c . ofthe Int . Joint Conf . on A rti cial Intel ligenc e IJCAI , pp . Los Angeles .Brac hman , R . J . , Sc hmolze , J . G . . An o v erview of the KL ONE kno wledge repre sen tation system . Co gnitive Scienc e , , .Buc hheit , M . , Donini , F . M . , Sc haerf , A . . Decidable reasoning in terminologicalkno wledge represen tation systems . T ec h . rep . RR , Deutsc hes F orsc h ungszen trum f ur K unstlic he In telligenz DFKI , Saarbr uc k en , German y . An abridged v ersionapp eared in Pr o c . of the Int . Joint Conf . on A rti cial Intel ligenc e IJCAI pp . .Catarci , T . , Lenzerini , M . . Represen ting and using in tersc hema kno wledge inco op erativ e information systems . Journal of Intel ligent and Co op er ative Inf . Syst . T oapp ear .Dionne , R . , Ma ys , E . , Oles , F . J . . A non w ell founded approac h to terminologicalcycles . In Pr o c . of the Nat . Conf . on A rti cial Intel ligenc e AAAI , pp . .AAAI Press The MIT Press .Dionne , R . , Ma ys , E . , Oles , F . J . . The equiv alence of mo del theoretic and structuralsubsumption in description logics . In Pr o c . of the Int . Joint Conf . on A rti cialIntel ligenc e IJCAI , pp . Cham b ery , F rance . Morgan Kaufmann , Los Altos .Donini , F . M . , Hollunder , B . , Lenzerini , M . , Marc hetti Spaccamela , A . , Nardi , D . , Nutt ,W . . The complexit y of existen tial quan ti cation in concept languages . A rti cialIntel ligenc e , , .Donini , F . M . , Lenzerini , M . , Nardi , D . , Nutt , W . . The complexit y of conceptlanguages . In Allen , J . , Fik es , R . , Sandew all , E . Eds . , Pr o c . of the Int .Conf . on Principles of Know le dge R epr esentation and R e asoning KR , pp . .Morgan Kaufmann , Los Altos . , Donini , SchaerfDonini , F . M . , Lenzerini , M . , Nardi , D . , Nutt , W . . T ractable concept languages .In Pr o c . of the Int . Joint Conf . on A rti cial Intel ligenc e IJCAI , pp . .Donini , F . M . , Lenzerini , M . , Nardi , D . , Sc haerf , A . . A h ybrid system in tegratingdatalog and concept languages . In Pr o c . of the Conf . of the Italian Asso ciationfor A rti cial Intel ligenc e , No . in Lecture Notes in Arti cial In telligence . Springer V erlag . An extended v ersion app eared also in the W orking Notes of the AAAI F allSymp osium Principles of Hybrid Reasoning .Donini , F . M . , Lenzerini , M . , Nardi , D . , Sc haerf , A . . Deduction in concept lan guages F rom subsumption to instance c hec king . Journal of L o gic and Computation .T o app ear .Fitting , M . . First Or der L o gic and A utomate d The or em Pr oving . Springer V erlag .Garey , M . , Johnson , D . . Computers and Intr actability A guide to NP c ompleteness . W .H . F reeman and Compan y , San F rancisco .Harel , D . . Dynamic logic . In Handb o ok of Philosophic al L o gic , V ol . , pp . .D . Reidel , Dordrec h t , Holland .Heinsohn , J . , Kudenk o , D . , Neb el , B . , Pro tlic h , H . J . . An empirical analysis ofterminological represen tation systems . In Pr o c . of the Nat . Conf . on A rti cialIntel ligenc e AAAI , pp . . AAAI Press The MIT Press .Hollunder , B . . Hybrid inferences in KL ONE based kno wledge represen tation sys tems . In Pr o c . of the German Workshop on A rti cial Intel ligenc e , pp . . Springer V erlag .Hollunder , B . , Baader , F . . Qualifying n um b er restrictions in concept languages .T ec h . rep . RR , Deutsc hes F orsc h ungszen trum f ur K unstlic he In telligenz DFKI ,Kaiserslautern , German y . An abridged v ersion app eared in Pr o c . of the Int . Conf .on Principles of Know le dge R epr esentation and R e asoning KR .Hughes , G . E . , Cressw ell , M . J . . A Comp anion to Mo dal L o gic . Meth uen , London .Kaczmarek , T . S . , Bates , R . , Robins , G . . Recen t dev elopmen ts in NIKL . In Pr o c .of the Nat . Conf . on A rti cial Intel ligenc e AAAI , pp . .Lenzerini , M . , Sc haerf , A . . Concept languages as query languages . In Pr o c . of the Nat . Conf . on A rti cial Intel ligenc e AAAI , pp . .Lev esque , H . J . . F oundations of a functional approac h to kno wledge represen tation .A rti cial Intel ligenc e , , .Lewis , H . R . , P apadimitriou , C . H . . Elements of the The ory of Computation .Pren tice Hall , Englew o o d Cli s , New Jersey .MacGregor , R . . Inside the LOOM description classi er . SIGAR T Bul letin , , . able Reasoning in Terminological KR SystemsMacGregor , R . . What s needed to mak e a description logic a go o d KR citizen . InWorking Notes of the AAAI F al l Symp osium on Issues on Description L o gics Usersme et Develop ers , pp . .MacGregor , R . , Bates , R . . The Lo om kno wledge represen tation language . T ec h .rep . ISI RS , Univ ersit y of Southern California , Information Science Institute ,Marina del Rey , Cal .MacGregor , R . , Brill , D . . Recognition algorithms for the LOOM classi er . InPr o c . of the Nat . Conf . on A rti cial Intel ligenc e AAAI , pp . . AAAIPress The MIT Press .Ma ys , E . , Dionne , R . , W eida , R . . K REP system o v erview . SIGAR T Bul letin , .McAllester , D . . Unpublished man uscript .McGuinness , D . L . . Making description logic based kno wledge represen tation systemsmore usable . In Working Notes of the AAAI F al l Sysmp osium on Issues on DescriptionL o gics Users me et Develop ers , pp . .Mylop oulos , J . , Bernstein , P . , W ong , E . . A language facilit y for designing database in tensiv e applications . A CM T r ans . on Datab ase Syst . , , .Neb el , B . . Computational complexit y of terminological reasoning in BA CK . A rti cialIntel ligenc e , , .Neb el , B . . R e asoning and R evision in Hybrid R epr esentation Systems . Lecture Notesin Arti cial In telligence . Springer V erlag .Neb el , B . . T erminological cycles Seman tics and computational prop erties . In So w a ,J . F . Ed . , Principles of Semantic Networks , pp . . Morgan Kaufmann , LosAltos .Nutt , W . . P ersonal comm unication .P atel Sc hneider , P . F . . Small can b e b eautiful in kno wledge represen tation . In Pr o c .of the IEEE Workshop on Know le dge Base d Systems . An extended v ersion app earedas F airc hild T ec h . Rep . and FLAIR T ec h . Rep . , Octob er .P atel Sc hneider , P . . Undecidabilit y of subsumption in NIKL . A rti cial Intel ligenc e , , .Pratt , V . R . . A practical decision metho d for prop ositional dynamic logic . In Pr o c .of the A CM SIGA CT Symp . on The ory of Computing STOC , pp . .Quan tz , J . , Kindermann , C . . Implemen tation of the BA CK system v ersion . T ec h .rep . KIT Rep ort , FB Informatik , T ec hnisc he Univ ersit at Berlin , Berlin , German y .Ric h , editor , C . . SIGAR T bulletin . Sp ecial issue on implemen ted kno wledge repre sen tation and reasoning systems . . , Donini , SchaerfSc haerf , A . . On the complexit y of the instance c hec king problem in concept lan guages with existen tial quan ti cation . Journal of Intel ligent Information Systems , , . An abridged v ersion app eared in Pr o c . of the Int . Symp . on Metho dolo gies for Intel ligent Systems ISMIS .Sc haerf , A . . Reasoning with individuals in concept languages . T ec h . rep . . ,Dipartimen to di Informatica e Sistemistica , Univ ersit a di Roma La Sapienza . Anabridged v ersion app eared in Pr o c . of the d Conf . of the Italian Asso ciation forA rti cial Intel ligenc e AI IA .Sc hild , K . . Undecidabili t y of subsumption in U . T ec h . rep . KIT Rep ort , FBInformatik , T ec hnisc he Univ ersit at Berlin , Berlin , German y .Sc hild , K . . A corresp ondence theory for terminological logics Preliminary rep ort .In Pr o c . of the Int . Joint Conf . on A rti cial Intel ligenc e IJCAI , pp . .Sc hmidt Sc hau , M . . Subsumption in KL ONE is undecidable . In Brac hman , R . J . ,Lev esque , H . J . , Reiter , R . Eds . , Pr o c . of the Int . Conf . on Principles ofKnow le dge R epr esentation and R e asoning KR , pp . . Morgan Kaufmann ,Los Altos .Sc hmidt Sc hau , M . , Smolk a , G . . A ttributiv e concept descriptions with comple men ts . A rti cial Intel ligenc e , , .V ardi , M . , W olp er , P . . Automata theoretic tec hniques for mo dal logics of pro grams . Journal of Computer and System Scienc e , , . A preliminary v ersionapp eared in Pr o c . of the A CM SIGA CT Symp . on The ory of Computing STOC .Vilain , M . . Deduction as parsing T ractable classi cation in the KL ONE framew ork .In Pr o c . of the Nat . Conf . on A rti cial Intel ligenc e AAAI , pp . .W and , M . . Induction , R e cursion , and Pr o gr amming . North Holland Publ . Co . ,Amsterdam .W o o ds , W . A . , Sc hmolze , J . G . . The KL ONE family . In Lehmann , F . Ed . ,Semantic Networks in A rti cial Intel ligenc e , pp . . P ergamon Press . Publishedas a sp ecial issue of Computers Mathematics with Applic ations , V olume , Num b er . "
" sensors and modelcondition computing circuits bar midline bar center midline zoneA goal location Tmove rotateequal position, loc equal heading, course position, loc KmKm X weights Ki Km. . . . . .. . . . . .. . . . . . input associators AND or weights OR units V V V V "
"Journal of Arti cial In telligence Researc h Submitted published the P ast T ense of English V erbs The Sym b olic P attern Asso ciator vs . Connectionist Mo delsCharles X . Ling ling o .caDep artment of Computer Scienc eThe University of Western OntarioL ondon , Ontario , Canada N the past tense of English v erbs a seemingly minor asp ect of language ac quisition has generated heated debates since , and has b ecome a landmark taskfor testing the adequacy of cognitiv e mo deling . Sev eral arti cial neural net w orks ANNs ha v e b een implemen ted , and a c hallenge for b etter sym b olic mo dels has b een p osed . Inthis pap er , w e presen t a general purp ose Sym b olic P attern Asso ciator SP A based up onthe decision tree learning algorithm ID . W e conduct extensiv e he ad to he ad comparisonson the generalization abilit y b et w een ANN mo dels and the SP A under di eren t represen tations . W e conclude that the SP A generalizes the past tense of unseen v erbs b etter thanANN mo dels b y a wide margin , and w e o er insigh ts as to wh y this should b e the case .W e also discuss a new default strategy for decision tree learning algorithms . . In tro ductionLearning the past tense of English v erbs , a seemingly minor asp ect of language acquisition ,has generated heated debates since the rst connectionist implemen tation in Rumel hart McClelland , . Based on their results , Rumelhart and McClelland claimed thatthe use and acquisition of h uman kno wledge of language can b est b e form ulated b y ANN Arti cial Neural Net w ork mo dels without sym b ol pro cessing that p ostulates the existenceof explicit sym b olic represen tation and rules . Since then , learning the past tense has b e come a landmark task for testing the adequacy of cognitiv e mo deling . Ov er the y ears an um b er of criticisms of connectionist mo deling app eared Pink er Prince , Lac h ter Bev er , Prasada Pink er , Ling , Cherw enk a , Marino v , . These criticismscen tered mainly up on the issues of high error rates and lo w reliabilit y of the exp erimen tal re sults , the inappropriateness of the training and testing pro cedures , hidden features of therepresen tation and the net w ork arc hitecture that facilitate learning , as w ell as the opaquekno wledge represen tation of the net w orks . Sev eral subsequen t attempts at impro ving theoriginal results with new ANN mo dels ha v e b een made Plunk ett Marc hman , Cot trell Plunk ett , MacWhinney Lein bac h , Daughert y Seiden b erg , .Most notably , MacWhinney and Lein bac h constructed a m ultila y er neural net w orkwith bac kpropagation BP , and attempted to answ er early criticisms . On the other hand ,supp orters of the sym b olic approac h b eliev e that sym b ol structures suc h as parse trees ,prop ositions , etc . , and the rules for their manipulations , are critical at the cognitiv e lev el ,while the connectionist approac h ma y only pro vide an accoun t of the neural structuresin whic h the traditional sym b ol pro cessing cognitiv e arc hitecture is implemen ted F o dor Pylysh yn , . Pink er and Prasada and Pink er argue that a prop erc AI Access F oundation and Morgan Kaufmann Publishers . All righ ts reserv ed .Lingaccoun ting for regular v erbs should b e dep enden t up on pro duction rules , while irregularpast tense in ections ma y b e generalized b y ANN lik e asso ciativ e memory .The prop er w a y of debating the adequacy of sym b olic and connectionist mo deling is b ycon trasting comp etitiv e implemen tations . Th us , a sym b olic implemen tation is needed thatcan b e compared with the ANN mo dels . This is , in fact , a c hallenge p osed b y MacWhinneyand Lein bac h , who assert that no sym b olic metho ds w ould w ork as w ell as their o wnmo del . In a section titled Is there a b etter sym b olic mo del ? they claim If there w ere some other approac h that pro vided an ev en more accuratec haracterization of the learning pro cess , w e migh t still b e forced to reject theconnectionist approac h , despite its successes . The prop er w a y of debating con ceptualizations is b y con trasting comp etitiv e implemen tations . T o do this in thepresen t case , w e w ould need a sym b olic implemen tation that could b e con trastedwith the curren t implemen tation . MacWhinney Lein bac h , , page In this pap er , w e presen t a general purp ose Sym b olic P attern Asso ciator SP A basedup on the sym b olic decision tree learning algorithm ID Quinlan , . W e ha v e sho wn Ling Marino v , that the SP A s results are m uc h more psyc hologically realistic thanANN mo dels when compared with h uman sub jects . On the issue of the predictiv e accuracy ,MacWhinney and Lein bac h did not rep ort imp ortan t results of their mo del on unseenregular v erbs . T o reply to our criticism , MacWhinney re implemen ted the ANNmo del , and claimed that its ra w generalization p o w er is v ery close to that of our SP A . Heb eliev ed that this should b e the case b ecause b oth systems learn from the same data set There is a v ery go o d reason for the equiv alen t p erformance of these t w omo dels . . . . When t w o computationally p o w erful systems are giv en the sameset of input data , they b oth extract ev ery bit of data regularit y from that input .Without an y further pro cessing , there is only so m uc h blo o d that can b e squeezedout of a turnip , and eac h of our systems SP A and ANN extracted what theycould . MacWhinney , , page W e will sho w that this is not the case ob viously there ar e reasons wh y one learningalgorithm outp erforms another otherwise wh y do w e study di eren t learning algorithms ? .The Occam s Razor Principle preferring the simplest h yp othesis o v er more complexones creates preference biases for learning algorithms . A pr efer enc e bias is a preferenceorder among comp etitiv e h yp otheses in the h yp othesis space . Di eren t learning algorithms ,ho w ev er , emplo y di eren t w a ys of measuring simplicit y , and th us concepts that they biasto are di eren t . Ho w w ell a learning program generalizes dep ends up on the degree to whic hthe regularit y of the data ts with its bias . W e study and compare the ra w generalizationabilit y of sym b olic and ANN mo dels on the task of learning the past tense of Englishv erbs . W e p erform extensiv e head to head comparisons b et w een ANN and SP A , and sho wthe e ects of di eren t represen tations and enco dings on their generalization abilities . Ourexp erimen tal results demonstrate clearly that . the distributed represen tation , a feature that connectionists ha v e b een adv o cating ,do es not lead to b etter generalization when compared with the sym b olic represen ta tion , or with arbitrary error correcting co des of a prop er length the P ast Tense Symbolic vs Connectionist Models . ANNs cannot learn the iden tit y mapping that preserv es the v erb stem in the pasttense as w ell as the SP A can . a new represen tation suggested b y MacWhinney impro v es the predictiv e accu racy of b oth SP A and ANN , but SP A still outp erforms ANN mo dels . in sum , the SP A generalizes the past tense of unseen v erbs b etter than ANN mo delsb y a wide margin .In Section w e discuss reasons as to wh y the SP A is a b etter learning mo del for thethe task of English past tense acquisition . Our results supp ort the view that man y suc hrule go v erned cognitiv e pro cesses should b e b etter mo deled b y sym b olic , rather than con nectionist , systems . . Review of Previous W orkIn this section , w e review brie y the t w o main connectionist mo dels of learning the pasttenses of English v erbs , and the subsequen t criticisms . . Rumelhart and McClelland s Mo delRumelhart and McClelland s mo del is based on a simple p erceptron based pattern asso ci ator in terfaced with an input output enco ding deco ding net w ork whic h allo ws the mo delto asso ciate v erb stems with their past tenses using a sp ecial Wic k elphone Wic k elfeaturephoneme represen tation format . The learning algorithm is the classical p erceptron con v er gence pro cedure . The training and the testing sets are m utually disjoin t in the exp erimen ts .The errors made b y the mo del during the training pro cess broadly follo w the U shap ed learn ing curv e in the stages of acquisition of the English past tense exhibited b y y oung c hildren .The testing sample consists of unseen lo w frequency v erbs irregular and regular that are not randomly c hosen . The testing sample results ha v e a error rate for theirregulars . The regulars fare b etter with a . error rate . Th us , the o v erall error rate forthe whole testing sample is wrong or am biguous past tense forms out of tested .Rumelhart and McClelland claim that the outcome of their exp erimen t discon rmsthe view that there exist explicit though inaccessible rules that underlie h uman kno wledgeof language . . MacWhinney and Lein bac h s Mo delMacWhinney and Lein bac h rep ort a new connectionist mo del on the learning of thepast tenses of English v erbs . They claim that the results from the new sim ulation are farsup erior to Rumelhart and McClelland s results , and that they can answ er most of the crit icisms aimed at the earlier mo del . The ma jor departure from Rumelhart and McClelland smo del is that the Wic k elphone Wic k elfeature represen tational format is replaced with theUNIBET MacWhinney , phoneme represen tational system whic h allo ws the assign men t of a single alphab etic n umerical letter to eac h of the total phonemes . MacWhinneyand Lein bac h use sp ecial templates with whic h to co de eac h phoneme and its p osition in aw ord . The actual input to the net w ork is created b y co ding the individual phonemes as sets phonetic features in a w a y similar to the co ding of Wic k elphones as Wic k elfeatures cfSection . . The net w ork has t w o la y ers of hidden units fully connected to adjacen tla y ers . This n um b er w as arriv ed at through trial and error . In addition , the net w ork has asp ecial purp ose set of connections that cop y the input units directly on to the output units .Altogether , regular and irregular English v erbs are selected for the exp erimen t of them are used for training regular and irregular , but only lo wfrequency irregular v erbs are used for testing MacWhinney Lein bac h , , page .T raining the net w ork tak es , ep o c hs . A t the end of training there still are errorson the irregular pasts . MacWhinney and Lein bac h b eliev e that if they allo w the net w orkto run for sev eral additional da ys and giv e it additional hidden unit resources , it probablycan reac h complete con v ergence MacWhinney Lein bac h , , page . The onlytesting error rate rep orted is based on a v ery small and biased test sample of unseenirregular v erbs out of are predicted incorrectly . They do not test their mo del on an yof the unseen regular v erbs Unfortunately , w e did not test a similar set of regulars . MacWhinney Lein bac h , , page . . Criticism of the Connectionist Mo delsPrevious and curren t criticisms of the connectionist mo dels of learning the past tenses ofEnglish v erbs cen ter mainly on sev eral issues . Eac h of these issues is summarized in thefollo wing subsections . . . Err or Ra tesThe error rate in pro ducing the past tenses of the unseen test v erbs is v ery high inb oth ANN mo dels , and imp ortan t tests w ere not carried out in MacWhinney and Lein bac h mo del . The exp erimen tal results indicate that neither mo del reac hes the lev el ofadult c omp etenc e . In addition , relativ ely large n um b ers of the errors are not psyc hologicallyrealistic since h umans rarely mak e them . . . Training and Testing Pr oceduresIn b oth Rumelhart and McClelland s mo del , and MacWhinney and Lein bac h s mo del , thegeneralization abilit y is measured on only one training testing sample . F urther , the testingsets are not randomly c hosen , and they are v ery small . The accuracy in testing irregularv erbs can v ary greatly dep ending up on the particular set of testing v erbs c hosen , and th usm ultiple runs with large testing samples are necessary to assess the true generalizationabilit y of a learning mo del . Therefore , the results of the previous connectionist mo dels arenot reliable . In Section , w e set up a reliable testing pro cedure to compare connectionistmo dels with our sym b olic approac h . Previous connectionist sim ulations ha v e also b eencriticized for their crude training pro cesses for example , the sudden increase of regularv erbs in the training set , whic h create suc h b eha vior as the U shap ed learning curv es . . . D a t a Represent a tion and Netw ork Ar chitectureMost of the past criticisms of the connectionist mo dels ha v e b een aimed at the data represen tation formats emplo y ed in the sim ulations . Lac h ter and Bev er p oin ted the P ast Tense Symbolic vs Connectionist Modelsout that the results ac hiev ed b y Rumelhart and McClelland s mo del w ould ha v e b een im p ossible without the use of sev eral TRICS The Represen tations It Crucially Supp oses in tro duced with the adoption of the Wic k elphone Wic k elfeature represen tational format .MacWhinney and Lein bac h claim that they ha v e impro v ed up on the earlier connectionistmo del b y getting rid of the Wic k elphone Wic k elfeature represen tation format , and th usto ha v e resp onded to the man y criticisms that this format en tailed . Ho w ev er , MacWhin ney and Lein bac h also in tro duce sev eral TRICS in their data represen tation format . F orexample , instead of co ding predecessor and successor phonemes as Wic k elphones , they in tro duce sp ecial templates with whic h to co de p ositional information . This means that thenet w ork will learn to asso ciate patterns of phoneme p ositions within a predetermined con sonan t v o w el pattern . F urther , the use of restrictiv e templates gets rid of man y Englishv erbs that do not t the c hosen template . This ma y bias the mo del in fa v our of shorterv erbs , predominan tly of Anglo Saxon origin , and against longer v erbs , predominan tly com p osite or of Latin and F renc h origin . Another TRICS in tro duced is the phonetic featureenco ding a distributed represen tation . It is not clear wh y phonetic features suc h as fron t ,cen tre , bac k , high , etc . are c hosen . Do they represen t ner grained microfeatures thathelp to capture the regularities in English past tenses ? In Section . , w e will sho w thatthe straigh tforw ard sym b olic represen tation leads to b etter generalization than do es thecarefully engineered distributed represen tation . This undermines the claimed adv an tages ofthe distributed represen tation of connectionist mo dels . . . Kno wledge Represent a tion and Integra tion of A cquired Kno wledgePink er and Prince , and Lac h ter and Bev er p oin t out that Rumelhart andMcClelland try to mo del the acquisition of the pro duction of the past tense in isolationfrom the rest of the English morphological system . Rumelhart and McClelland , as w ellas MacWhinney and Lein bac h , assume that the acquisition pro cess establishes a directmapping from the phonetic represen tation of the stem to the phonetic represen tation ofthe past tense form . This direct mapping collapses some w ell established distinctions suc has lexical item vs . phoneme string , and morphological category vs . morpheme . Simplyremaining at the lev el of phonetic patterns , it is imp ossible to express new categoricalinformation in rst order predicate function v ariable format . One of the inheren t de citsof the connectionist implemen tations is that there is no suc h thing as a v ariable for verbstem , and hence there is no w a y for the mo del to attain the kno wledge that one couldadd su x to a stem to get its past tense Pink er Prince , , page . Since theacquired kno wledge in suc h net w orks is a large w eigh t matrix , whic h usually is opaque to theh uman observ er , it is unclear ho w the phonological lev els pro cessing that the connectionistmo dels carry out can b e in tegrated with the morphological , lexical , and syn tactical lev elof pro cessing . Neither Rumelhart and McClelland nor MacWhinney and Lein bac h addressthis issue . In con trast to ANNs whose in ternal represen tations are en tirely opaque , theSP A can represen t the acquired kno wledge in the form of pro duction rules , and allo w forfurther pro cessing , resulting in higher lev el categories suc h as the v erb stem and the v oicedconsonan ts , linguisticall y realistic pro duction rules using these new categories for regularv erbs , and asso ciativ e templates for irregular v erbs Ling Marino v , . . The Sym b olic P attern Asso ciatorW e tak e up MacWhinney and Lein bac h s c hallenge for a b etter sym b olic mo del for learningthe past tense of English v erbs , and presen t a general purp ose Sym b olic P attern Asso ciator SP A can generalize the past tense of unseen v erbs m uc h more accurately thanconnectionist mo dels in this section . Our mo del is symb olic for sev eral reasons . First ,the input output represen tation of the learning program is a set of phoneme sym b ols ,whic h are the basic elemen ts go v erning the past tense in ection . Second , the learningprogram op erates on those phoneme sym b ols directly , and the acquired kno wledge can b erepresen ted in the form of pro duction rules using those phoneme sym b ols as w ell . Third ,those pro duction rules at the phonological lev el can easily b e further generalized in to rst order rules that use more abstract , high lev el sym b olic categories suc h as morphemes andthe v erb stem Ling Marino v , . In con trast , the connectionist mo dels op erateon a distributed represen tation phonetic feature v ectors , and the acquired kno wledge isem b edded in a large w eigh t matrix it is therefore hard to see ho w this kno wledge can b efurther generalized in to more abstract represen tations and categories . . The Arc hitecture of the Sym b olic P attern Asso ciatorThe SP A is based on C . Quinlan , whic h is an impro v ed implemen tation of the ID algorithm cf . Quinlan , . ID is a program for inducing classi cation rules inthe form of decision trees from a set of classi ed examples . It uses information gain ratio asa criterion for selecting attributes as ro ots of the subtrees . The divide and conquer strategyis recursiv ely applied in building subtrees un til all remaining examples in the training setb elong to a single concept class then a leaf is lab eled as that concept . The informationgain guides a greedy heuristic searc h for the lo cally most r elevant or discriminating attributethat maximally reduces the en trop y randomness in the divided set of the examples . Theuse of this heuristic usually results in building smal l decision trees instead of larger onesthat also t the training data .If the task is to learn to classify a set of di eren t patterns in to a single class of sev eralm utually exclusiv e categories , ID has b een sho wn to b e comparable with neural net w orks i .e . , within ab out range on the predictiv e accuracy on man y real w orld learning tasks cf . Sha vlik , Mo oney , T o w ell , F eng , King , Sutherland , Henery , Ripley , W eiss Kulik o wski , . Ho w ev er , if the task is to classify a set of input patternsin to output patterns of man y attributes , ID cannot b e applied directly . The reason isthat if ID treats the di eren t output patterns as m utually exclusiv e classes , the n um b er ofclasses w ould b e exp onen tially large and , more imp ortan tly , an y generalization of individualoutput attributes within the output patterns w ould b e lost .T o turn ID or an y similar N to classi cation system in to general purp ose N to Msym b olic pattern asso ciators , the SP A applies ID on all output attributes and com binesindividual decision trees in to a forest , or set of trees . A similar approac h w as prop osed fordealing with the distributed binary enco ding in m ulticlass learning tasks suc h as NETtalk English text to sp eec h mapping Dietteric h , Hild , Bakiri , . Eac h tree tak es asinput the set of all attributes in the input patterns , and is used to determine the v alue of . The SP A programs and relev an t datasets can b e obtained anon ymously from ftp .csd .u w o .ca underpub SP A . the P ast Tense Symbolic vs Connectionist Modelsone attribute in its output pattern . More sp eci cally , if a pair of input attributes to n and output attributes ! to !m is represen ted as n ! ! !mthen the SP A will build a total of m decision trees , one for eac h output attribute !i i m taking all input attributes n p er tree . Once all of m trees are built , the SP Acan use them join tly to determine the output pattern ! !m from an y input pattern n .An imp ortan t feature of the SP A is explicit kno wledge represen tation . Decision trees foroutput attributes can easily b e transformed in to prop ositional pro duction rules Quinlan , . Since en tities of these rules are sym b ols with seman tic meanings , the acquiredkno wledge often is comprehensible to the h uman observ er . In addition , further pro cessingand in tegration of these rules can yield high lev el kno wledge e .g . , rules using v erb stems Ling Marino v , . Another feature of the SP A is that the trees for di eren t outputattributes con tain iden tical comp onen ts branc hes and subtrees Ling Marino v , .These comp onen ts ha v e similar roles as hidden units in ANNs since they are shared in thedecision trees of more than one output attribute . These iden tical comp onen ts can also b eview ed as high lev el concepts or feature com binations created b y the learning program . . Default StrategiesAn in teresting researc h issue is ho w decision tree learning algorithms handle the defaultclass . A default class is the class to b e assigned to lea v es whic h no training examples areclassi ed in to . W e call these lea v es empty le aves . This happ ens when the attributes ha v eman y di eren t v alues , or when the training set is relativ ely small . In these cases , during thetree construction , only a few branc hes are explored for some attributes . When the testingexamples fall in to the empt y lea v es , a default str ate gy is needed to assign classes to thoseempt y lea v es .F or easier understanding , w e use the sp elling form of v erbs in this subsection to explainho w di eren t default strategies w ork . In the actual learning exp erimen t the v erbs arerepresen ted in phonetic form . If w e use consecutiv e left to righ t alphab etic represen tation ,the v erb stems and their past tenses of a small training set can b e represen ted as follo ws a ,f ,f ,o ,r ,d , , , , , , , , , a ,f ,f ,o ,r ,d ,e ,d , , , , , , , e ,a ,t , , , , , , , , , , , , a ,t ,e , , , , , , , , , , , , l ,a ,u ,n ,c ,h , , , , , , , , , l ,a ,u ,n ,c ,h ,e ,d , , , , , , , l ,e ,a ,v ,e , , , , , , , , , , l ,e ,f ,t , , , , , , , , , , , where is used as a ller for empt y space . The left hand columns are the input patternsfor the stems of the v erbs the righ t hand columns are the output patterns for theircorresp onding correct past tense forms .As w e ha v e discussed , decision trees will b e constructed , one for eac h output attribute .The decision tree for the rst output attribute can b e constructed see Figure a fromthe follo wing examples a ,f ,f ,o ,r ,d , , , , , , , , , ae ,a ,t , , , , , , , , , , , , al ,a ,u ,n ,c ,h , , , , , , , , , l ,e ,a ,v ,e , , , , , , , , , , lwhere the last column is the classi cation of the rst output attribute . Ho w ev er , man yother branc hes suc h as c in Figure a are not explored , since no training examplehas that attribute v alue . If a testing pattern has its rst input attribute equal to c , whatclass should it b e assigned to ? ID uses the majority default . That is , the most p opularclass in the whole subtree under is assigned to the empt y lea v es . In the example ab o v e ,either class a or l will b e c hosen since they eac h ha v e training examples . Ho w ev er , this isclearly not the righ t strategy for this task since a v erb suc h as create w ould b e output asl . . . . . . or a . . . . . . , whic h is incorrect . Because it is unlik ely for a small training set to ha v e allv ariations of attribute v alues , the ma jorit y default strategy of ID is not appropriate forthis task . a x n indicates that there are n examples classified in the leaf labelled as x. x boxed indicates the empty leaves.c l a rl k t d t Passthrough Majority Figure a P assthrough default b V arious defaultF or applications suc h as v erb past tense learning , a new default heuristic p assthr ough ma y b e more suitable . That is , the classi cation of an empt y leaf should b e the sameas the attribute v alue of that branc h . F or example , using the passthrough default strategy ,create will b e output as c . . . . . . . The passthrough strategy giv es decision trees some rst order a v or , since the pro duction rules for empt y lea v es can b e represen ted as If A ttribute Xthen Class X where X can b e an y un used attribute v alues . P assthrough is a domain dep enden t heuristic strategy b ecause the class lab els ma y ha v e nothing to do with theattribute v alues in other applications .Applying the passthrough strategy alone , ho w ev er , is not adequate for ev ery outputattribute . The endings of the regular past tenses are not iden tical to an y of the inputpatterns , and the irregular v erbs ma y ha v e v o w el and consonan t c hanges in the middle ofthe v erbs . In these cases , the ma jorit y default ma y b e more suitable than the passthrough .In order to c ho ose the righ t default strategy ma jorit y or passthrough a decision ismade based up on the training data in the corresp onding subtree . The SP A rst determinesthe ma jorit y class , and coun ts the n um b er of examples from all subtrees that b elong tothis class . It then coun ts the n um b er of examples in the subtrees that coincide with the the P ast Tense Symbolic vs Connectionist Modelspassthrough strategy . These t w o n um b ers are compared , and the default strategy emplo y edb y more examples is c hosen . F or instance , in the example ab o v e see Figure a , thema jorit y class is l or a ha ving instances . Ho w ev er , there are examples coinciding withthe passthrough default t w o l and one a . Th us the passthrough strategy tak es o v er , andassigns all empt y lea v es at this level . The empt y attribute branc h c w ould then b e assignedthe class c . Note that the default strategy for empt y lea v es of attribute X dep ends up ontraining examples falling in to the subtree ro oted at X . This lo calized metho d ensures thatonly related ob jects ha v e an in uence on calculating default classes . As a result , the SP Acan adapt the default strategy that is b est suited at di eren t lev els of the decision trees . F orexample , in Figure b , t w o di eren t default strategies are used at di eren t lev els in thesame tree . W e use the SP A with the adaptiv e default strategy throughout the remainder ofthis pap er . Note that the new default strategy is not a TRICS in the data represen tation rather , it represen ts a bias of the learning program . An y learning algorithm has a defaultstrategy indep enden t of the data represen tation . The e ect of di eren t data represen tationson generalization is discussed in Sections . , . , and . . The passthrough strategy canb e imp osed on ANNs as w ell b y adding a set of cop y connections b et w een the input unitsand the t win output units . See Section . for detail . . Comparisons of Default Strategies of ID , SP A , and ANNWhic h default strategy do neural net w orks tend to tak e in generalizing default classeswhen compared with ID and SP A ? W e conducted sev eral exp erimen ts to determine neuralnet w orks default strategy . W e assume that the domain has only one attribute X whic hma y tak e v alues a , b , c , and d . The class also can b e one of the a , b , c , and d . The trainingexamples ha v e attribute v alues a , b , and c but not d it is reserv ed for testing the defaultclass . The training set con tains m ultiple copies of the same example to form a certainma jorit y class . T able sho ws t w o sets of training testing examples that w e used to testand compare default strategies of ID , SP A and neural net w orks .Data set Data set raining examples T raining examplesV alues of X Class of copies V alues of X Class of copiesa a a c b b b c c c esting example T esting exampled ? d ? able Tw o data sets for testing default strategies of v arious metho ds .The classi cation of the testing examples b y ID and SP A is quite easy to decide . SinceID tak es only the ma jorit y default , the output class is a with training examples forthe rst data set , and c with training examples for the second data set . F or SP A , then um b er of examples using passthrough is for the rst data set , and for the second set . Therefore , the passthrough strategy wins in the rst case with the output classd , and the ma jorit y strategy wins in the second case with the output class c .F or neural net w orks , v arious co ding metho ds w ere used to represen t v alues of the at tribute X . In the dense co ding , w e used to represen t a , for b , for c and ford . W e also tried the standard one p er class enco ding , and real n um b er enco ding . for a , . for b , . for c and . for d . The net w orks w ere trained using as few hidden units asp ossible in eac h case . W e found that in most cases the classi cation of the testing exam ple is not stable it v aries with di eren t random seeds that initialize the net w orks . T able summarises the exp erimen tal results . F or ANNs , v arious classi cations obtained b y eren t random seeds are listed with the rst ones o ccurring most frequen tly . It seemsthat not only do neural net w orks not ha v e a consisten t default strategy , but also that itis neither the ma jorit y default as in ID nor the passthrough default as in SP A . This ma yexplain wh y connectionist mo dels cannot generalize unseen regular v erbs w ell ev en whenthe training set con tains only regular v erbs see Section . . The net w orks ha v e di cult y or are underconstrained in generalizing the iden tit y mapping that copies the attributes ofthe v erb stems in to the past tenses .The classi cation for the testing exampleData set Data set a cSP A d cANN , dense co ding b c bANN , one p er class b c a c bANN , real n um b ers c d d cT able Default strategies of ID , SP A and ANN on t w o data sets . . Head to head Comparisons b et w een Sym b olic and ANN Mo delsIn this section , w e p erform a series of extensiv e head to head comparisons using sev eraldi eren t represen tations and enco ding metho ds , and demonstrate that the SP A generalizesthe past tense of unseen v erbs b etter than ANN mo dels do b y a wide margin . . F ormat of the dataOur v erb set came from MacWhinney s original list of v erbs . The set con tains ab out stem past tense pairs . Learning is based up on the phonological UNIBET repre sen tation MacWhinney , , in whic h di eren t phonemes are represen ted b y di eren talphab etic n umerical letters . There is a total of phonemes . The source le is transferredin to the standard format of pairs of input and output patterns . F or example , the v erbs inT able are represen ted as pairs of input and output patterns v erb stem past tense ,b , ,n ,d , ,n ,b , ,n ,d , ,n ,dI ,k ,s ,E ,l , ,r ,e ,t I ,k ,s ,E ,l , ,r ,e ,t ,I ,d the P ast Tense Symbolic vs Connectionist Models ,r , ,z ,r ,o ,zb ,I ,k , ,m b ,I ,k ,e ,mSee T able The original v erb set is a v ailable in Online App endix . W e k eep only oneform of the past tense among m ultiple past tenses suc h as hang hanged and hang h ung in the data set . In addition , no homophones exist in the original data set . Consequen tly ,there is no noise con tradictory data whic h ha v e the same input pattern but di eren t outputpatterns in the training and testing examples . Note also that information as to whetherthe v erb is regular or irregular is not pro vided in training testing pro cesses .base stem UNIBET b base irregularsp elling form phonetic form d past tense regularabandon nd b nd d ene t bEn b ene ted bEn d b d ecome bIk b ecame bIk em d . . . . . .T able Source le from MacWhinney and Lein bac h . . Exp erimen t SetupT o guaran tee un biased and reliable comparison results , w e use training and testing samplesrandomly dra wn in sev eral indep enden t runs . Both SP A and ANN are pro vided with thesame sets of training testing examples for eac h run . This allo ws us to ac hiev e a reliableestimate of the inductiv e generalization capabilities of eac h mo del on this task .The neural net w ork program w e used is a pac k age called Xerion , whic h w as dev elop edat the Univ ersit y of T oron to . It has sev eral more sophisticated searc h mec hanisms thanthe standard steep est gradien t descen t metho d with momen tum . W e found that trainingwith the conjugate gradien t metho d is m uc h faster than with the standard bac kpropagationalgorithm . Using the conjugate gradien t metho d also a v oids the need to searc h for prop ersettings of parameters suc h as the learning rate . Ho w ev er , w e do need to determine theprop er n um b er of hidden units . In the exp erimen ts with ANNs , w e rst tried v ariousn um b ers of hidden units and c hose the one that pro duced the b est predictiv e accuracy ina trial run , and then use the net w ork with that n um b er of hidden units in the actual runs .The SP A , on the other hand , has no parameters to adjust .One ma jor di erence in implemen tation b et w een ANNs and SP A is that SP A can tak e sym b olic phoneme letters directly while ANNs normally enco de eac h phoneme letter tobinary bits . Of course , SP A also can apply to the binary represen tation . W e studiedv arious binary enco ding metho ds and compared results with SP A using sym b olic letter tation . Since outputs of neural net w orks are real n um b ers , w e need to deco de thenet w ork outputs bac k to phoneme letters . W e used the standard metho d of deco ding thephoneme letter that has the minimal real n um b er Hamming distance smallest angle withthe net w ork outputs w as c hosen . T o see ho w binary enco ding a ects the generalization ,the SP A w as also trained with the binary represen tation . Since the SP A s outputs arebinary , the deco ding pro cess ma y tie with sev eral phoneme letters . In this case , one ofthem is c hosen randomly . This re ects the probabilit y of the correct deco ding at the lev elof phoneme letters . When all of the phoneme letters are deco ded , if one or more letters areincorrect , the whole pattern is coun ted as incorrect at the w ord lev el . . T emplated , Distributed Represen tationThis set of exp erimen ts w as conducted using the distributed represen tation suggested b yMacWhinney and Lein bac h . According to MacWhinney and Lein bac h , the output isa left justi ed template in the format of CCCVV CCCVV CCCVV CCC , where C stands forconsonan t and V for v o w el space holders . The input has t w o comp onen ts a left justi edtemplate in the same format as the input , and a righ t justi ed template in the format ofVV CCC . F or example , the v erb b et , represen ted in UNIBET co ding as bEt , is sho wn in thetemplate format as follo ws is the blank phoneme INPUTbEt b E t E ttemplate CCCVVCCCVVCCCVVCCC VVCCC left justified right justified OUTPUTbEt b E t template CCCVVCCCVVCCCVVCCC left justified A sp eci c distributed represen tation a set of binary phonetic features is usedto enco de all phoneme letters for the connectionist net w orks . Eac h v o w el V in the ab o v etemplates is enco ded b y phonetic features fron t , cen tre , bac k , high , lo w , middle , round ,and diph thong and eac h consonan t C in the ab o v e templates b y phonetic features v oiced , labial , den tal , palatal , v elar , nasal , liquid , trill , fricativ e and in terden tal . Notethat b ecause the t w o feature sets of v o w els and consonan ts are not iden tical , templates areneeded in order to deco de the righ t t yp e of the phoneme letters from the outputs of thenet w ork .In our exp erimen tal comparison , w e decided not to use the righ t justi ed template VV CCC since this information is redundan t . Therefore , w e used only the left justi edtemplate CCCVV CCCVV CCCVV CCC in b oth input and output . The whole v erb setin the templated phoneme represen tation is a v ailable in Online App endix . It con tains pairs of v erb stems and past tenses that t the template . T o ease implemen tation ,w e added t w o extra features that alw a ys w ere assigned to in the v o w el phonetic featureset . Therefore , b oth v o w els and consonan ts w ere enco ded b y binary bits . The ANNth us had input bits and output bits , and w e found that one la y er of units same as MacWhinney mo del reac hed the highest predictiv e accuracyin a trial run . See Figure for the net w ork arc hitecture used . the P ast Tense Symbolic vs Connectionist Models . . . . . . . . . . . . input units hidden units output units C CCCVVCCCVV C C C C C V V... ... ... ... . . . . . . ... ... ...CCCVVCCCVV C C C C C V V... ... ... ... . . . . . . ... ... ... C full connection between the two layers full connection between the two layers Figure The arc hitecture of the net w ork used in the exp erimen t .The SP A w as trained and tested on the same data sets but with phoneme letters directly that is , decision trees w ere built for eac h of the phoneme letters in the output templates .T o see ho w phonetic feature enco ding a ects the generalization , w e also trained the SP Awith the the same distributed represen tation binary bit patterns of input bits and output bits exactly the same as those in the ANN sim ulation . In addition , to see ho wthe sym b olic enco ding w orks in ANN , w e also train another neural net w ork with units with the one p er class enco ding . That is , eac h phoneme letter total of phoneme letters plus one for blank is enco ded b y bits , one for eac h phoneme letter .W e used v erb pairs including b oth regular and irregular v erbs in the training andtesting sets . Sampling w as done randomly without replacemen t , and training and testingsets w ere disjoin t . Three runs of SP A and ANN w ere conducted , and b oth SP A and ANNw ere trained and tested on the same data set in eac h run . T raining reac hed accuracyfor SP A and around for ANN .T esting accuracy on no v el v erbs pro duced some in teresting results . The ANN mo deland the SP A using the distributed represen tation ha v e v ery similar accuracy , with ANNsligh tly b etter . This ma y w ell b e caused b y the binary outputs of SP A that suppress the ne di erences in prediction . On the other hand , the SP A using phoneme letters directlypro duces m uc h higher accuracy on testing . The SP A outp erforms neural net w orks witheither distributed or one p er class represen tations b y p ercen tage p oin ts ! The testingresults of ANN and SP A can b e found in T able . Our ndings clearly indicate that theSP A using sym b olic represen tation leads to m uc h b etter generalization than ANN mo dels . . Learning Regular V erbsPredicting the past tense of an unseen v erb , whic h can b e either regular or irregular , isnot an easy task . Irregular v erbs are not learned b y rote as traditionally though t since represen tation Sym b olic represen tationANN Correct SP A Correct ANN Correct SP A CorrectReg Irrg Com b Reg Irrg Com b Reg Irrg Com b Reg Irrg Com b . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . able Comparisons of testing accuracy of SP A and ANN with distributed and sym b olicrepresen tations .c hildren and adults o ccasionally extend irregular in ection to irregular sounding regularv erbs or pseudo v erbs suc h as cleef cleft Prasada Pink er , . The more similarthe no v el v erb is to the cluster of irregular v erbs with similar phonological patterns , themore lik ely the prediction of an irregular past tense form . Pink er and Prasada andPink er argue that regular past tenses are go v erned b y rules , while irregulars ma yb e generated b y the asso ciated memory whic h has this graded e ect of irregular past tensegeneralization . It is w ould b e in teresting , therefore , to compare SP A and ANN on thepast tense generalization of regular v erbs only . Because b oth SP A and ANN use the same ,p osition sp eci c , represen tation , learning regular past tenses w ould require learning di eren tsu xes di er ent p ositions , and to learn the iden tit y mapping that copies the v erb stemto the past tenses for v erbs of di eren t lengths .W e used the same templated represen tation as in the previous section , but b oth trainingand testing sets con tained only regular v erbs . Again samples w ere dra wn randomly withoutreplacemen t . T o maximize the size of the testing sets , testing sets simply consisted of allregular v erbs that w ere not sampled in the training sets . The same training and testing setsw ere used for eac h of the follo wing metho ds compared . T o see the e ect of the adaptiv edefault strategy as discussed in Section . on generalization , the SP A with the ma jorit ydefault only and with the adaptiv e default w ere b oth tested . The ANN mo dels w ere similarto those used in the previous section except with one la y er hidden units , whic h turnedout to ha v e the b est predictiv e accuracy in a test run . The passthrough default strategy canb e imp osed on neural net w orks b y adding a set of cop y connections that connect directlyfrom the input units to the t win output units . MacWhinney and Lein bac h usedsuc h cop y connections in their sim ulation . W e therefore tested the net w orks with the cop yconnection to see if generalization w ould b e impro v ed as w ell .The results on the predictiv e accuracy of the SP A and ANNs on one run with withrandomly sampled training and testing sets are summarized in T able . As w e can see ,the SP A with the adaptiv e default strategy , whic h com bines the ma jorit y and passthroughdefault , outp erforms the SP A with only the ma jorit y default strategy used in ID . The . In phonological form there are three di eren t su xes for regular v erbs . When the v erb stem ends witht or d UNIBET phonetic represen tations , then the su x is Id . F or example , extend extended insp elling form . When the v erb stem ends with a un v oiced consonan t , the su x is t . F or example , talk talk ed . When the v erb stem ends with a v oiced consonan t or v o w el , the su x is d . F or example ,solv e solv ed . the P ast Tense Symbolic vs Connectionist ModelsANNs with cop y connections do generalize b etter than the ones without . Ho w ev er , ev enANN mo dels with cop y connections ha v e a lo w er predictiv e accuracy than the SP A ma jorit y . In addition , the di erences in the predictiv e accuracy are larger with smaller setsof training examples . Smaller training sets mak e the di erence in testing accuracy moreeviden t . When the training set con tains patterns out of , the testing accuracyb ecomes v ery similar , and w ould approac h asymptotically to with larger training sets .Up on examination , most of the errors made in ANN mo dels o ccur in the iden tit y mapping i .e . , strange phoneme c hange and drop the v erb stems cannot b e preserv ed in the pasttense if the phonemes are not previously seen in the training examples . This con tradicts the ndings of Prasada and Pink er , whic h sho w that nativ e English sp eak ers generateregular su x adding past tenses equally w ell with unfamiliar sounding v erb stems as longas these v erb stems do not sound close to irregular v erbs . This also indicates that the biasof the ANN learning algorithms is not suitable to this t yp e of task . See further discussionin Section .T raining P ercen t correct on testingsize SP A adaptiv e SP A ma jorit y ANN cop y con . ANN normal . . . . . . . . . . . . . . . . . . . . able Predictiv e accuracy on learning the past tense of regular v erbs . Error Correcting Co desDietteric h and Bakiri rep orted an increase in the predictiv e accuracy when error correcting co des of large Hamming distances are used to enco de v alues of the attributes .This is b ecause co des with larger Hamming distance d allo w for correcting few er than d of errors . Th us , learning programs are allo w ed to mak e some mistak es at the bit lev elwithout their outputs b eing misin terpreted at the w ord lev el .W e w an ted to nd if p erformances of the SP A and ANNs are impro v ed with the error correcting co des enco ding all of the phonemes . W e c hose error correcting co des rangingfrom ones with small Hamming distance to ones with v ery large Hamming distance usingthe BHC co des , see Dietteric h and Bakiri . Because the n um b er of attributes foreac h phoneme is to o large , the data represen tation w as c hanged sligh tly for this exp erimen t .Instead of phoneme holders with templates , consecutiv e , left to righ t phoneme holdersw ere used . V erbs with stems or past tenses of more than phonemes w ere remo v ed from thetraining testing sets . The whole v erb set in the this represen tation is a v ailable in OnlineApp endix . It con tains pairs of v erb stems and past tenses whose lengths are shorterthan . Both SP A and ANN tak e exactly the same training testing sets , eac h con tains of v erb stems and past tenses , with the error correcting co des enco ding eac h phoneme . Still , training net w orks with bit or longer error correcting co des tak es to o long torun there are input attributes and output attributes . Therefore , onlyt w o runs with and bit co des w ere conducted . Consisten t with Dietteric h and Bakiri s ndings , w e found that the testing accuracy generally increases when the Hammingdistance increases . Ho w ev er , w e also observ ed that the testing accuracy decreases v erysligh tly when the co des b ecome to o long . The accuracy using bit co des with Hammingdistance of reac hes the maxim um v alue . , whic h is quite close to the accuracy . of SP A using the direct phoneme letter represen tation . It seems there is a trade o b et w een tolerance of errors with large Hamming distance and di cult y in learning withlonger co des . In addition , w e found the testing accuracy of ANNs to b e lo w er than the oneof SP A for b oth bit and bit error correcting co des . The results are summarized inT able .ANN Hamming Distance Correct at bit lev el Correct at w ord lev el bit co des . . bit co des . . SP A Hamming Distance Correct at bit lev el Correct at w ord lev el bit co des . . bit co des . . bit co des . . bit co des . . T able Comparisons of the testing accuracy of SP A and ANNs with error correcting co desOur results in this and the previous t w o subsections undermine the adv an tages of thedistributed represen tation of ANNs , a unique feature adv o cated b y connectionists . W e ha v edemonstrated that , in this task , the distributed represen tation actually do es not allo w foradequate generalization . Both SP A using direct sym b olic phoneme letters and SP A witherror correcting co des outp erform ANNs with distributed represen tation b y a wide margin .Ho w ev er , neither phoneme sym b ols nor bits in the error correcting co des enco de , implicitlyor explicitly , an y micro features as in the distributed represen tation . It ma y b e that thedistributed represen tation used w as not optimally designed . Nev ertheless , straigh tforw ardsym b olic format requires little represen tation engineering compared with the distributedrepresen tation in ANNs . . Righ t justi ed , Isolated Su x Represen tationMacWhinney and Lein bac h did not rep ort imp ortan t results of the predictiv e ac curacy of their mo del on unseen regular v erbs . In his reply MacWhinney , to ourpap er Ling Marino v , , MacWhinney re implemen ted the ANN mo del . In his newimplemen tation , , v erb stem and past tense pairs w ere in the training set , among whic h w ere regular and w ere irregular . T raining to ok , ep o c hs , and reac hed correct on regulars and on irregulars . The testing set consisted of regulars and . The p ercen t correct on testing at ep o c h , w as for regulars and forirregulars , with a com bined . on the testing set . MacWhinney claimed that the ra w the P ast Tense Symbolic vs Connectionist Modelsgeneralization p o w er of ANN mo del is v ery close to that of our SP A . He b eliev es that thisshould b e the case simply b ecause b oth systems w ere trained on the same data set .W e realize via priv ate comm unication that a new represen tation used in MacWhinney srecen t implemen tation pla ys a critical role in the impro v ed p erformance . In MacWhinney snew represen tation , the input for v erb stems is co ded b y the right justi ed templateCCCVV CCCVV CCCVV CCC . The output con tains t w o parts a righ t justi ed templatethat is the same as the one in the input , and a co da in the form of VV CCC . The righ t justi ed template in the output is used to represen t the past tense without including thesu x for the regular v erbs . The su x of the regular past tense alw a ys sta ys in the co da ,whic h is isolate d from the main , righ t justi ed templates . F or the irregular past tense , theco da is left empt y . F or example , the input and output templated patterns for the past tenseof v erbs in T able are represen ted as INPUT OUTPUT right justified right justified suffix only CCCVVCCCVVCCCVVCCC CCCVVCCCVVCCCVVCCC VVCCC b nd n b nd n d for abandon abandoned b E n f I t b E n f I t I d for benefit benefited r z r o z for arise arose b I k m b I k e m for become became Suc h data represen tation clearly facilitates learning . F or the regular v erbs , the outputpatterns are alw a ys iden tical to the input patterns . In addition , the v erb ending phonemeletters alw a ys app ear at a few xed p ositions i .e . , the righ t most VV CCC section in theinput template due to the righ t justi ed , templated represen tation . F urthermore , the su xalw a ys o ccupies the co da , isolated from the righ t justi ed templates .W e p erformed a series of exp erimen ts to see ho w m uc h impro v emen t w e could accom plish using the new represen tation o v er MacWhinney s recen t ANN mo del and o v er theleft justi ed represen tation discussed in Section . . Our SP A with an a v eraged predictiv eaccuracy of . outp erforms MacWhinney s recen t ANN implemen tation with the pre dictiv e accuracy of . b y a wide margin . In addition , the predictiv e accuracy is alsoimpro v ed from an a v erage of . from the left justi ed represen tation to . of therigh t justi ed , isolated su x one . See results in T able . . General Discussion and ConclusionsTw o factors con tribute to the generalization abilit y of a learning program . The rst isthe data represen tation , and the other is the bias of the learning program . Arriving atthe righ t , optimal , represen tation is a di cult task . As argued b y Prasada and Pink er , regular v erbs should b e represen ted in a coarse grain in terms of the v erb stemand su xes while irregular v erbs in a ner grain in terms of phonological prop erties .Admittedly , SP A w orks uniformly at the lev el of phoneme letters , as ANNs do . Ho w ev er ,b ecause SP A pro duces simple pro duction rules that use these phoneme letters directly , thoserules can b e further generalized to rst order rules with new represen tations suc h as stemsand the v oiced consonan ts whic h can b e used across the b oard in other suc h rule learningmo dules Ling Marino v , . This is one of the ma jor adv an tages o v er ANN mo dels . e accuracy with righ t justi ed , isolated su x represen tationSP A MacWhinney s ANN mo deltraining testing training testing training testing . . . . . . erage . . . one run T able Comparisons of testing accuracy of SP A and ANN with righ t justi ed , isolatedsu x represen tation It seems quite conceiv able that c hildren acquire these high lev el concepts suc h as stemsand v oiced consonan ts through learning noun plurals , v erb past tense , v erb third p ersonsingular , comparativ e adjectiv es , and so on . With a large w eigh t matrix as the result oflearning , it is hard to see ho w this kno wledge can b e further generalized in ANN mo delsand shared in other mo dules .Ev en with exactly the same data represen tation , there exist some learning tasks thatsym b olic metho ds suc h as the SP A generalize categorically b etter than ANNs . The con v erse also is true . This fact re ects the di eren t inductiv e biases of the di eren t learningalgorithms . The Occam s Razor Principle preferring the simplest h yp othesis o v er morecomplex ones creates a preference bias , a preference of c ho osing certain h yp otheses o v erothers in the h yp othesis space . Ho w ev er , di eren t learning algorithms c ho ose di eren t h y p otheses b ecause they use di eren t measuremen ts for simplicit y . F or example , among allp ossible decision trees that t the training examples , ID and SP A induce simple decisiontrees instead of complicated ones . Simple decision trees can b e con v erted to small sets ofpro duction rules . Ho w w ell a learning algorithm generalizes dep ends up on the degree towhic h the underlying regularities of the target concept t its bias . In other w ords , if theunderlying regularities can b e represen ted c omp actly in the format of h yp otheses pro ducedb y the learning algorithm , the data can b e generalized w ell , ev en with a small set of trainingexamples . Otherwise , if the underlying regularities only ha v e a large h yp othesis , but thealgorithm is lo oking for compact ones as p er the Occam s Razor Principle , the h yp othe ses inferred will not b e accurate . A learning algorithm that searc hes for h yp otheses largerthan necessary i .e . , that do es not use the Occam s Razor Principle is normally under constrained it do es not kno w , based on the training examples only , whic h of the man ycomp etitiv e h yp otheses of the large size should b e inferred .W e also can describ e the bias of a learning algorithm b y lo oking at ho w training examplesof di eren t classes are separated in the n dimensional h yp erspace where n is the n um b erof attributes . A decision no de in a decision tree forms a h yp erplane as describ ed b y alinear function suc h as X a . Not only are these h yp erplanes p erp endicular to the axis ,they are also p artial sp ac e h yp erplanes that extend only within the subregion formed b ythe h yp erplanes of their paren ts no des . Lik ewise , hidden units with a threshold function inANNs can b e view ed as forming h yp erplanes in the h yp erspace . Ho w ev er , unlik e the onesin the decision trees , they need not b e p erp endicul ar to an y axis , and they are ful l sp ac e the P ast Tense Symbolic vs Connectionist Modelsh yp erplanes that extend through the whole space . If ID is applied to the concepts that tANN s bias , esp ecially if their h yp erplanes are not p erp endicul ar to an y axis , then man yzigzag h yp erplanes that are p erp endicul ar to axes w ould b e needed to separate di eren tclasses of the examples . Hence , a large decision tree w ould b e needed , but this do es not tID s bias . Similarly , if ANN learning algorithms are applied to the concepts that t ID sbias , esp ecially if their h yp erplanes form man y separated , partial space regions , then man yhidden units ma y b e needed for these regions .Another ma jor di erence b et w een ANNs and ID is that ANNs ha v e a larger v ariationand a w eak er bias cf . Geman , Bienensto c k , Doursat , than ID . Man y moreBo olean functions e .g . , linearly separable functions can t a small net w ork e .g . , one withno hidden units than they can a small decision tree . This is sometimes attributed to theclaimed v ersatilit y and exibilit y of ANNs they can learn but not necessarily predict reli ably w ell man y functions , while sym b olic metho ds are brittle . Ho w ev er , it is m y b elief thatw e h umans are v ersatile , not b ecause w e ha v e a learning algorithm with a large v ariation ,but rather b ecause w e ha v e a set of str ong biase d learning algorithms , and w e can someho wsearc h in the bias space and add new mem b ers in to the set for the new learning tasks . Sym b olic learning algorithms ha v e clear seman tic comp onen ts and explicit represen tation , andth us w e can more easily construct strong based algorithms motiv ated from v arious sp eci clearning tasks . The adaptiv e default strategy in the SP A is suc h an example . On the otherhand , w e still largely do not kno w how to e ectiv ely strengthen the bias of ANNs for man ysp eci c tasks suc h as the iden tit y mapping , k term DNF , etc . . Some tec hniques suc has adding cop y connections and w eigh t deca ying exist , but their exact e ects on biasingto w ards classes of functions are not clear .F rom our analyses Ling Marino v , , the underlying regularities go v erning thein ection of the past tense of English v erbs do form a small set of pro duction rules withphoneme letters . This is esp ecially so for regular v erbs all the rules are either iden tit yrules or the su x adding rules . F or example , decision trees can b e con v erted in to a set ofpr e c e denc e or der e d pro duction rules with more complicated rules rules with more condi tions listed rst . As an example , using consecutiv e , left to righ t phonetic represen tation , at ypical su x adding rule for v erb stems with phoneme letters suc h as talk talk ed is If k and , then ! tThat is , if the fourth input phoneme is k and the fth is blank i .e . , if w e are at a v erbending then the fth output phoneme is t . On the other hand , the iden tit y mapping rulesha v e only one condition . A t ypical iden tit y rule lo oks lik e If l , then ! lIn fact , the passthrough default strategy allo ws all of the iden tit y mapping rules to b e rep resen ted in a simple rst order format If X , then ! Xwhere X can b e an y phoneme . Clearly , the kno wledge of forming regular past tenses canth us b e expressed in simple , conjunctiv e rules whic h t the bias of the SP A ID , andtherefore , the SP A has a m uc h b etter generalization abilit y than the ANN mo dels .T o conclude , w e ha v e demonstrated , via extensiv e head to head comparisons , that theSP A has a more realistic and b etter generalization capacit y than ANNs on learning thepast tense of English v erbs . W e ha v e argued that sym b olic decision tree pro duction rul elearning algorithms should outp erform ANNs . This is b ecause , rst , the domain seems to b e v erned b y a compact set of rules , and th us ts the bias of our sym b olic learning algorithm second , the SP A directly manipulates on a represen tation b etter than ANNs do i .e . , thesym b olic phoneme letters vs . the distributed represen tation and third , the SP A is ableto deriv e high lev el concepts used throughout English morphology . Our results supp ort theview that man y suc h high lev el , rule go v erned cognitiv e tasks should b e b etter mo deled b ysym b olic , rather than connectionist , systems .Ac kno wledgemen tsI gratefully thank Stev e Pink er for his constan t encouragemen t , and Marin Marino v , Stev eCherw enk a and Huaqing Zeng for discussions and for help in implemen ting the SP A . Ithank Brian MacWhinney for pro viding the v erb data used in his sim ulation . Discussionswith T om Dietteric h , Da v e T ouretzky and Brian MacWhinney , as w ell as commen ts fromreview ers , ha v e b een v ery helpful . The researc h is conducted with supp ort from the NSER CResearc h Gran t and computing facilities from our Departmen t .ReferencesCottrell , G . , Plunk ett , K . . Using a recurren t net to learn the past tense . InPr o c e e dings of the Co gnitive Scienc e So ciety Confer enc e .Daughert y , K . , Seiden b erg , M . . Bey ond rules and exceptions A connectionistmo deling approac h to in ectional morphology . In Lima , S . Ed . , The R e ality ofLinguistic R ules . John Benjamins .Dietteric h , T . , Bakiri , G . . Error correcting output co des A general metho d forimpro ving m ulticlass inductiv e learning programs . In AAAI Pr o c e e dings of NinthNational Confer enc e on A rti cial Intel ligenc e .Dietteric h , T . , Hild , H . , Bakiri , G . . A comparativ e study of ID and bac kprop agation for English text to sp eec h mapping . In Pr o c e e dings of the InternationalConfer enc e on Machine L e arning . Morgan Kaufmann .F eng , C . , King , R . , Sutherland , A . , Henery , R . . Comparison of sym b olic , statis tical and neural net w ork classi ers . Man uscript . Departmen t of Computer Science ,Univ ersit y of Otta w a .F o dor , J . , Pylysh yn , Z . . Connectionism and cognitiv e arc hitecture A criticalanalysis . In Pink er , S . , Mehler , J . Eds . , Conne ctions and Symb ols , pp . .Cam bridge , MA MIT Press .Geman , S . , Bienensto c k , E . , Doursat , R . . Neural net w orks and the bias v ariancedilemma . Neur al Computation , , .Lac h ter , J . , Bev er , T . . The relation b et w een linguistic structure and asso ciativ etheories of language learning a constructiv e critique of some connectionist learningmo dels . In Pink er , S . , Mehler , J . Eds . , Conne ctions and Symb ols , pp . .Cam bridge , MA MIT Press . the P ast Tense Symbolic vs Connectionist ModelsLing , X . , Cherw enk a , S . , Marino v , M . . A sym b olic mo del for learning the pasttenses of English v erbs . In Pr o c e e dings of IJCAI Thirte enth International Con fer enc e on A rti cial Intel ligenc e , pp . . Morgan Kaufmann Publishers .Ling , X . , Marino v , M . . Answ ering the connectionist c hallenge a sym b olic mo delof learning the past tense of English v erbs . Co gnition , , .MacWhinney , B . . The CHILDES Pr oje ct T o ols for A nalyzing T alk . Hillsdale , NJ Erlbaum .MacWhinney , B . . Connections and sym b ols closing the gap . Co gnition , , .MacWhinney , B . , Lein bac h , J . . Implemen tations are not conceptualizations Re vising the v erb mo del . Co gnition , , .Pink er , S . . Rules of language . Scienc e , , .Pink er , S . , Prince , A . . On language and connectionism Analysis of a paralleldistributed pro cessing mo del of language acquisition . In Pink er , S . , Mehler , J . Eds . , Conne ctions and Symb ols , pp . . Cam bridge , MA MIT Press .Plunk ett , K . , Marc hman , V . . U shap ed learning and frequency e ects in a m ul tila y ered p erceptron Implications for c hild language acquisition . Co gnition , , .Prasada , S . , Pink er , S . . Generalization of regular and irregular morphologicalpatterns . L anguage and Co gnitive Pr o c esses , , .Quinlan , J . . Induction of decision trees . Machine L e arning , , .Quinlan , J . . C . Pr o gr ams for Machine L e arning . Morgan Kaufmann San Mateo ,CA .Ripley , B . . Statistical asp ects of neural net w orks . In vited lectures for SemStat Seminaire Europ een de Statistique , Sandb jerg , Denmark , April .Rumelhart , D . , McClelland , J . . On learning the past tenses of English v erbs .In Rumelhart , D . , McClelland , J . , the PDP Researc h Group Eds . , Par al lel Dis tribute d Pr o c essing V ol , pp . . Cam bridge , MA MIT Press .Sha vlik , J . , Mo oney , R . , T o w ell , G . . Sym b olic and neural learning algorithms Anexp erimen tal comparison . Machine L e arning , , .W eiss , S . , Kulik o wski , C . . Computer Systems that L e arn classi c ation and pr e dic tion metho ds fr om statistics , neur al networks , machine le arning , and exp ert systems .Morgan Kaufmann , San Mateo , CA . "
"Journal of Arti cial In telligence Researc h Submitted published Disco v ery Using Minim um DescriptionLength and Bac kground Kno wledgeDiane J . Co ok cook a .eduLa wrence B . Holder holder a .eduDep artment of Computer Scienc e Engine eringBox of T exas at A rlingtonA rlington , TX USAAbstractThe abilit y to iden tify in teresting and rep etitiv e substructures is an essen tial comp o nen t to disco v ering kno wledge in structural data . W e describ e a new v ersion of our Sub due substructure disco v ery system based on the minim um description length principle .The Subdue system disco v ers substructures that compress the original data and represen tstructural concepts in the data . By replacing previously disco v ered substructures in thedata , m ultiple passes of Subdue pro duce a hierarc hical description of the structural reg ularities in the data . Subdue uses a computationally b ounded inexact graph matc h thatiden ti es similar , but not iden tical , instances of a substructure and nds an appro ximatemeasure of closeness of t w o substructures when under computational constrain ts . In addi tion to the minim um description length principle , other bac kground kno wledge can b e usedb y Subdue to guide the searc h to w ards more appropriate substructures . Exp erimen ts ina v ariet y of domains demonstrate Subdue s abilit y to nd substructures capable of com pressing the original data and to disco v er structural concepts imp ortan t to the domain . . In tro ductionThe large amoun t of data collected to da y is quic kly o v erwhelming researc hers abilities toin terpret the data and disco v er in teresting patterns within the data . In resp onse to thisproblem , a n um b er of researc hers ha v e dev elop ed tec hniques for disco v ering concepts indatabases . These tec hniques w ork w ell for data expressed in a non structural , attribute v alue represen tation , and address issues of data relev ance , missing data , noise and uncer tain t y , and utilization of domain kno wledge . Ho w ev er , recen t data acquisition pro jectsare collecting structural data describing the relationships among the data ob jects . Corre sp ondingly , there exists a need for tec hniques to analyze and disco v er concepts in structuraldatabases .One metho d for disco v ering kno wledge in structural data is the iden ti cation of com mon substructures within the data . The motiv ation for this pro cess is to nd substructurescapable of compressing the data and to iden tify conceptually in teresting substructures thatenhance the in terpretation of the data . Substructure disco v ery is the pro cess of iden tifyingconcepts describing in teresting and rep etitiv e substructures within structural data . Oncedisco v ered , the substructure concept can b e used to simplify the data b y replacing instancesof the substructure with a p oin ter to the newly disco v ered concept . The disco v ered sub structure concepts allo w abstraction o v er detailed structure in the original data and pro videc AI Access F oundation and Morgan Kaufmann Publishers . All righ ts reserv ed .Cook Holdernew , relev an t attributes for in terpreting the data . Iteration of the substructure disco v eryand replacemen t pro cess constructs a hierarc hical description of the structural data in termsof the disco v ered substructures . This hierarc h y pro vides v arying lev els of in terpretation thatcan b e accessed based on the goals of the data analysis .W e describ e a system called Subdue Holder , Co ok , Bunk e , Holder Co ok , that disco v ers in teresting substructures in structural data based on the minim umdescription length principle . The Subdue system disco v ers substructures that compressthe original data and represen t structural concepts in the data . By replacing previously disco v ered substructures in the data , m ultiple passes of Subdue pro duce a hierarc hical de scription of the structural regularities in the data . Subdue uses a computationally b oundedinexact graph matc h that iden ti es similar , but not iden tical , instances of a substructure and nds an appro ximate measure of closeness of t w o substructures when under computationalconstrain ts . In addition to the minim um description length principle , other bac kgroundkno wledge can b e used b y Subdue to guide the searc h to w ards more appropriate substruc tures .The follo wing sections describ e the approac h in detail . Section describ es the pro cess ofsubstructure disco v ery and in tro duces needed de nitions . Section compares the Subduedisco v ery system to other w ork found in the literature . Section in tro duces the minim umdescription length enco ding used b y this approac h , and Section presen ts the inexactgraph matc h algorithm emplo y ed b y Subdue . Section describ es metho ds of incorp oratingbac kground kno wledge in to the substructure disco v ery pro cess . The exp erimen ts detailedin Section demonstrate Subdue s abilit y to nd substructures that compress the data andto re disco v er kno wn concepts in a v ariet y of domains . Section details the hierarc hicaldisco v ery pro cess . W e conclude with observ ations and directions for future researc h . . Substructure Disco v eryThe substructure disco v ery system represen ts structured data as a lab eled graph . Ob jectsin the data map to v ertices or small subgraphs in the graph , and relationships b et w eenob jects map to directed or undirected edges in the graph . A substructur e is a connectedsubgraph within the graphical represen tation . This graphical represen tation serv es as inputto the substructure disco v ery system . Figure sho ws a geometric example of suc h an inputgraph . The ob jects in the gure e .g . , T , S , R b ecome lab eled v ertices in the graph , andthe relationships e .g . , on T ,S , shape C ,circle b ecome lab eled edges in the graph .The graphical represen tation of the substructure disco v ered b y Subdue from this data isalso sho wn in Figure .An instanc e of a substructure in an input graph is a set of v ertices and edges fromthe input graph that matc h , graph theoretically , to the graphical represen tation of thesubstructure . F or example , the instances of the substructure in Figure are sho wn inFigure .The substructure disco v ery algorithm used b y Subdue is a computationally constrainedb eam searc h . The algorithm b egins with the substructure matc hing a single v ertex in thegraph . Eac h iteration through the algorithm selects the b est substructure and expands theinstances of the substructure b y one neigh b oring edge in all p ossible w a ys . The new uniquegenerated substructures b ecome candidates for further expansion . The algorithm searc hes ucture Disco ver y Input Graph onshape shapetriangle squareFigure Example substructure in graph form . Instance Instance Instance Instances of the substructure .for the b est substructure un til all p ossible substructures ha v e b een considered or the totalamoun t of computation exceeds a giv en limit . The ev aluation of eac h substructure is guidedb y the MDL principle and other bac kground kno wledge pro vided b y the user .T ypically , once the description length of an expanding substructure b egins to increase ,further expansion of the substructure will not yield a smaller description length . As aresult , Subdue mak es use of an optional pruning mec hanism that eliminates substructureexpansions from consideration when the description lengths for these expansions increases . . Related W orkSev eral approac hes to substructure disco v ery ha v e b een dev elop ed . Winston s Ar ch pro gram Winston , disco v ers substructures in order to deep en the hierarc hical descriptionof a scene and to group ob jects in to more general concepts . The Ar ch program searc hes fort w o t yp es of substructure in the blo c ks w orld domain . The rst t yp e in v olv es a sequenceof ob jects connected b y a c hain of similar relations . The second t yp e in v olv es a set ofob jects eac h ha ving a similar relationship to some grouping ob ject . The main di erenceb et w een the substructure disco v ery pro cedures used b y the Ar ch program and Subdue isthat the Ar ch program is designed sp eci cally for the blo c ks w orld domain . F or instance ,the sequence disco v ery metho d lo oks for supported by and in front of relations only .Subdue s substructure disco v ery metho d is domain indep enden t , although the inclusion ofdomain sp eci c kno wledge w ould impro v e Subdue s p erformance .Motiv ated b y the need to construct a kno wledge base of c hemical structures , Levinson Levinson , dev elop ed a system for storing lab eled graphs in whic h individual graphs Holderare represen ted b y the set of v ertices in a univ ersal graph . In addition , the individual graphsare main tained in a partial ordering de ned b y the subgraph of relation , whic h impro v esthe p erformance of graph comparisons . The univ ersal graph represen tation pro vides ametho d for compressing the set of graphs stored in the kno wledge base . Subgraphs ofthe univ ersal graph used b y sev eral individual graphs suggest common substructure in theindividual graphs . One di erence b et w een the t w o approac hes is that Levinson s systemis designed to incremen tally pro cess smaller individual graphs whereas , Subdue pro cesseslarger graphs all at once . Also , Levinson s system disco v ers common substructure onlyas an indirect result of the univ ersal graph construction whereas , Subdue s main goalis to disco v er and output substructure de nitions that reduce the minim um descriptionlength enco ding of the graph . Finally , the subgraph of partial ordering used b y Levinson ssystem is not included in Subdue , but main taining this partial ordering w ould impro v e thep erformance of the graph matc hing pro cedure b y pruning the n um b er of p ossible matc hinggraphs .Segen Segen , describ es a system for storing graphs using a probabilistic graphmo del to represen t subsets of the graph . Alternativ e mo dels are ev aluated based on a min im um description length measure of the information needed to represen t the stored graphsusing the mo del . In addition , Segen s system clusters the graphs in to classes based onminimizing the description length of the graphs according to the en tire clustering . Apartfrom the probabilistic represen tation , Segen s approac h is similar to Levinson s system inthat b oth metho ds tak e adv an tage of commonalities in the graphs to assist in graph stor age and matc hing . The probabilistic graphs con tain information for iden tifying commonsubstructure in the exact graphs they represen t . The p ortion of the probabilistic graphwith high probabilit y de nes a substructure that app ears frequen tly in the exact graphs .This notion w as not emphasized in Segen s w ork , but pro vides an alternativ e metho d tosubstructure disco v ery b y clustering subgraphs of the original input graphs . As with Levin son s approac h , graphs are pro cessed incremen tally , and substructure is found across sev eralgraphs , not within a single graph as in Subdue .The Labyrinth system Thompson Langley , extends the Cobweb incremen talconceptual clustering system Fisher , to handle structured ob jects . Labyrinth usesCobweb to form hierarc hical concepts of the individual ob jects in the domain based ontheir primitiv e attributes . Concepts of structured ob jects are formed in a similar mannerusing the individual ob jects as attributes . The resulting hierarc h y represen ts a comp onen tialmo del of the structured ob jects . Because Cobweb s concepts are probabilistic , Labyrinthpro duces probabilistic mo dels of the structured ob jects , but with an added hierarc hicalorganization . The upp er lev el comp onen ts of the structured ob ject hierarc h y pro duced b yLabyrinth represen t substructures common to the examples . Therefore , although not theprimary fo cus , Labyrinth is disco v ering substructure , but in a more constrained con textthan the general graph represen tation used b y Subdue .Conklin et al . Conklin Glasgo w , ha v e dev elop ed the i mem system for con structing an image hierarc h y , similar to that of Labyrinth , used for disco v ering commonsubstructures in a set of images and for e cien t retriev al of images similar to a giv en image .Images are expressed in terms of a set of relations de ned b y the user . Sp eci c and general conceptual images are stored in the hierarc h y based on a subsumption relation similar ucture Disco ver yto Levinson s subgraph of partial ordering . Image matc hing utilizes a transformationalapproac h similar to Subdue s inexact graph matc h as a measure of image closeness .As with the approac hes of Segen and Levinson , i mem is designed to pro cess individualimages . Therefore , the general image concepts that app ear higher in i mem s hierarc h ywill represen t common substructures across sev eral images . Subdue is designed to disco v ercommon substructures within a single image . Subdue can mimic the individual approac hof these systems b y pro cessing a set of individual images as one disconnected graph . Thesubstructures found will b e common to the individual images . The hierarc h y also represen tsa comp onen tial view of the images . This same view can b e constructed b y Subdue usingm ultiple passes o v er the graph after replacing p ortions of the input graph with substructuresdisco v ered during previous passes . i mem has p erformed w ell in a simple c hess domainand molecular c hemistry domains Conklin Glasgo w , . Ho w ev er , i mem requiresdomain sp eci c relations for expressing images in order for the hierarc h y to nd relev an tsubstructures and for image matc hing to b e e cien t . Again , main taining the concepts images , graphs in a partially ordered hierarc h y impro v es the e ciency of matc hing andretriev al , and suggests a p ossible impro v emen t to Subdue .The CLiP system Y oshida , Moto da , Indurkh y a , for graph based induction ismore similar to Subdue than the previous systems . CLiP iterativ ely disco v ers patterns ingraphs b y expanding and com bining patterns disco v ered in previous iterations . P atternsare group ed in to views based on their collectiv e abilit y to compress the original inputgraph . During eac h iteration CLiP uses existing views to con tract the input graph andthen considers adding to the views new patterns consisting of t w o v ertices and an edge fromthe con tracted graph . The compression of the new prop osed views is estimated , and theb est views according to a giv en b eam width are retained for the next iteration .CLiP disco v ers substructures patterns di eren tly than Subdue . First , CLiP pro ducesa set of substructures that collectiv ely compress the input graph whereas , Subdue pro ducesonly single substructures ev aluated using the more principled minim um description length .CLiP has the abilit y to gro w substructures agglomerativ ely i .e . , merging t w o substructurestogether whereas , Subdue alw a ys pro duces new substructures using incremen tal gro wthalong one new edge . CLiP initially estimates the compression v alue of new views based onthe compression v alue of the paren t view whereas , Subdue p erforms an exp ensiv e exactmeasuremen t of compression for eac h new substructure . Finally , CLiP emplo ys an e cien tgraph matc h based on graph iden tit y , not graph isomorphism as in Subdue . Graph iden tit yassumes an ordering o v er the inciden t edges of a v ertex and do es not consider all p ossiblemappings when lo oking for o ccurrences of a pattern in an input graph . These di erencesin CLiP suggest p ossible enhancemen ts to Subdue .Researc h in pattern recognition has b egun to in v estigate the use of graphs and graphgrammars as an underlying represen tation for structural problems Sc halk o , . Man yresults in grammatical inference are applicable to constrained classes of graphs e .g . , trees F u , Miclet , . The approac h b egins with a set of sample graphs and pro duces ageneralized graph grammar capable of deriving the original sample graphs and man y others .The pro duction rules of this general grammar capture regularities substructures in thesample graphs . Jeltsc h and Kreo wski Jeltsc h Kreo wski , describ e an approac h thatb egins with a maximally sp eci c grammar and iterativ ely iden ti es common subgraphs inthe righ t hand sides of the pro duction rules . These common subgraphs are used to form Holdernew , more general pro duction rules . Although their metho d do es not address the underlyingcom binatorial nondeterminism , heuristic approac hes could pro vide a feasible metho d forextracting substructures in the form of graph grammars . F urthermore , the graph grammarpro duction rule ma y pro vide a suitable represen tation for bac kground kno wledge during thesubstructure disco v ery pro cess . . Minim um Description Length Enco ding of GraphsThe minim um description length principle MDLP in tro duced b y Rissanen Rissanen , states that the b est theory to describ e a set of data is that theory whic h minimizesthe description length of the en tire data set . The MDL principle has b een used for decisiontree induction Quinlan Riv est , , image pro cessing P ednault , P en tland , Leclerc , , concept learning from relational data Derthic k , , and learning mo delsof non homogeneous engineering domains Rao Lu , .W e demonstrate ho w the minim um description length principle can b e used to disco v ersubstructures in complex data . In particular , a substructure is ev aluated based on ho w w ellit can compress the en tire dataset using the minim um description length . W e de ne theminim um description length of a graph to b e the n um b er of bits necessary to completelydescrib e the graph .According to the minim um description length MDL principle , the theory that b estaccoun ts for a collection of data is the one that minimizes I S I G j S , where S is thedisco v ered substructure , G is the input graph , I S is the n um b er of bits required to enco dethe disco v ered substructure , and I G j S is the n um b er of bits required to enco de the inputgraph G with resp ect to S .The graph connectivit y can b e represen ted b y an adjacency matrix . Consider a graphthat has n v ertices , whic h are n um b ered n BnZr . An n n adjacency matrix A canb e formed with en try A i j set to or . If A i j , then there is no connection fromv ertex i to v ertex j . If A i j , then there is at least one connection from v ertex i tov ertex j . Undirected edges are recorded in only one en try of the matrix . The adjacencymatrix for the graph in Figure is sho wn b elo w .xtr iang l eysq uar err ectang l e enco ding of the graph consists of the follo wing steps . W e assume that the deco derhas a table of the lu unique lab els in the original graph G . . Determine the n um b er of bits vbits needed to enco de the v ertex lab els of the graph .First , w e need lg v bits to enco de the n um b er of v ertices v in the graph . Then ,enco ding the lab els of all v v ertices requires v lg lu bits . W e assume the v ertices aresp eci ed in the same order they app ear in the adjacency matrix . The total n um b erof bits to enco de the v ertex lab els isv bits lg v v lg lu ucture Disco ver y shapeshapetriangle squarex on y on shaperectangle rFigure MDL example graph .F or the example in Figure , v , and w e assume that there are lu uniquelab els in the original graph . The n um b er of bits needed to enco de these v ertices islg lg bits . . Determine the n um b er of bits rbits needed to enco de the ro ws of the adjacency matrixA . T ypically , in large graphs , a single v ertex has edges to only a small p ercen tage ofthe v ertices in the en tire graph . Therefore , a t ypical ro w in the adjacency matrix willha v e m uc h few er than v , where v is the total n um b er of v ertices in the graph . W eapply a v arian t of the co ding sc heme used b y Quinlan Riv est , to enco de bitstrings with length n consisting of k and n BnZr k , where k n BnZr k . In ourcase , ro w i i v can b e represen ted as a bit string of length v con taining ki . If w e let b maxi ki , then the i thro w of the adjacency matrix can b e enco ded asfollo ws . a Enco ding the v alue of ki requires lg b bits . b Giv en that only ki o ccur in the ro w bit string of length v , only vki stringsof and are p ossible . Since all of these strings ha v e equal probabilit y ofo ccurrence , lg vki bits are needed to enco de the p ositions of in ro w i . Thev alue of v is kno wn from the v ertex enco ding .Finally , w e need an additional lg b bits to enco de the n um b er of bits needed tosp ecify the v alue of ki for eac h ro w . The total enco ding length in bits for the adjacencymatrix isr bits lg b vXi lg b lg vki v lg b vXi lg vki HolderF or the example in Figure , b , and the n um b er of bits needed to enco de theadjacency matrix is lg lg lg lg lg lg lg . . Determine the n um b er of bits ebits needed to enco de the edges represen ted b y theen tries A i j of the adjacency matrix A . The n um b er of bits needed to enco deen try A i j is lg m e i j lg lu , where e i j is the actual n um b er of edgesb et w een v ertex i and j in the graph and m maxi j e i j . The lg m bits are neededto enco de the n um b er of edges b et w een v ertex i and j , and lg lu bits are neededp er edge to enco de the edge lab el and whether the edge is directed or undirected . Inaddition to enco ding the edges , w e need to enco de the n um b er of bits lg m neededto sp ecify the n um b er of edges p er en try . The total enco ding of the edges isebits lg m vXi vXj lg m e i j lg lu lg m e lg lu vXi vXj A i j lg m e lg lu K lg mwhere e is the n um b er of edges in the graph , and K is the n um b er of in the adjacencymatrix A . F or the example in Figure , e , K , m , lu , and the n um b erof bits needed to enco de the edges is lg lg .The total enco ding of the graph tak es v bits r bits ebits bits . F or the example inFigure , this v alue is bits .Both the input graph and disco v ered substructure can b e enco ded using the ab o v esc heme . After a substructure is disco v ered , eac h instance of the substructure in the inputgraph is replaced b y a single v ertex represen ting the en tire substructure . The disco v eredsubstructure is represen ted in I S bits , and the graph after the substructure replacemen t isrepresen ted in I G j S bits . Subdue searc hes for the substructure S in graph G minimizingI S I G j S . . Inexact Graph Matc hAlthough exact structure matc h can b e used to nd man y in teresting substructures , man yof the most in teresting substructures sho w up in a sligh tly di eren t form throughout thedata . These di erences ma y b e due to noise and distortion , or ma y just illustrate sligh tdi erences b et w een instances of the same general class of structures . Consider the imagesho wn in Figure . The p encil and the cub e w ould mak e ideal substructures in the picture ,but an exact matc h algorithm ma y not consider these as strong substructures , b ecause theyrarely o ccur in the same form and lev el of detail throughout the picture .Giv en an input graph and a set of de ned substructures , w e w an t to nd those subgraphsof the input graph that most closely resem ble the giv en substructures . F urthermore , w e w an tto asso ciate a distance measure b et w een a pair of graphs consisting of a giv en substructureand a subgraph of the input graph . W e adopt the approac h to inexact graph matc h giv enb y Bunk e and Allermann Bunk e Allermann , . ucture Disco ver y BB BA aba b aFigure Tw o similar graphs g and g .In this inexact matc h approac h , eac h distortion of a graph is assigned a cost . A distortionis describ ed in terms of basic transformations suc h as deletion , insertion , and substitutionof v ertices and edges . The distortion costs can b e determined b y the user to bias the matc hfor or against particular t yp es of distortions .An inexact graph matc h b et w een t w o graphs g and g maps g to g suc h that g isin terpreted as a distorted v ersion of g . F ormally , an inexact graph matc h is a mappingf N ! N f g , where N and N are the sets of v ertices of g and g , resp ectiv ely . Av ertex v N that is mapp ed to i .e . , f v is deleted . That is , it has no corresp ondingv ertex in g . Giv en a set of particular distortion costs as discussed ab o v e , w e de ne the costof an inexact graph matc h cost f , as the sum of the cost of the individual transformationsresulting from f , and w e de ne matchcost g g as the v alue of the least cost function thatmaps graph g on to graph g .Giv en g , g , and a set of distortion costs , the actual computation of matchcost g g can b e determined using a tree searc h pro cedure . A state in the searc h tree corresp onds toa partial matc h that maps a subset of the v ertices of g to a subset of the v ertices in g .Initially , w e start with an empt y mapping at the ro ot of the searc h tree . Expanding a statecorresp onds to adding a pair of v ertices , one from g and one from g , to the partial mappingconstructed so far . A nal state in the searc h tree is a matc h that maps all v ertices of g tog or to . The complete searc h tree of the example in Figure is sho wn in Figure . F orthis example w e assign a v alue of to eac h distortion cost . The n um b ers in circles in this gure represen t the cost of a state . As w e are ev en tually in terested in the mapping withminim um cost , eac h state in the searc h tree gets assigned the cost of the partial mappingthat it represen ts . Th us the goal state to b e found b y our tree searc h pro cedure is the nal state with minim um cost among all nal states . F rom Figure w e conclude that theminim um cost inexact graph matc h of g and g is giv en b y the mapping f , f .The cost of this mapping is .Giv en graphs g with n v ertices and g with m v ertices , m n , the complexit y of thefull inexact graph matc h is O n m . Because this routine is used hea vily throughout the Holder , , , , , , , , , , , , , , , , , Searc h tree for computing matc hcost g , g from Figure .disco v ery and ev aluation pro cess , the complexit y of the algorithm can signi can tly degradethe p erformance of the system .T o impro v e the p erformance of the inexact graph matc h algorithm , w e extend Bunk e sapproac h b y applying a branc h and b ound searc h to the tree . The cost from the ro ot of thetree to a giv en no de is computed as describ ed ab o v e . No des are considered for pairings inorder from the most hea vily connected v ertex to the least connected , as this constrains theremaining matc h . Because branc h and b ound searc h guaran tees an optimal solution , thesearc h ends as so on as the rst complete mapping is found .In addition , the user can place a limit on the n um b er of searc h no des considered b ythe branc h and b ound pro cedure de ned as a function of the size of the input graphs .Once the n um b er of no des expanded in the searc h tree reac hes the de ned limit , the searc hresorts to hill clim bing using the cost of the mapping so far as the measure for c ho osing theb est no de at a giv en lev el . By de ning suc h a limit , signi can t sp eedup can b e realized atthe exp ense of accuracy for the computed matc h cost .Another approac h to inexact graph matc h w ould b e to enco de the di erence b et w eent w o graphs using the MDL principle . Smaller enco dings w ould indicate a lo w er matc h costb et w een the t w o graphs . W e lea v e this as a future researc h direction . . Guiding the Disco v ery Pro cess with Bac kground Kno wledgeAlthough the principle of minim um description length is useful for disco v ering substruc tures that maximize compression of the data , scien tists ma y realize more b ene t from thedisco v ery of substructures that exhibit other domain sp eci c and domain indep endent c har acteristics .T o mak e Subdue more p o w erful across a wide v ariet y of domains , w e ha v e added theabilit y to guide the disco v ery pro cess with bac kground kno wledge . Although the minim umdescription length principle still driv es the disco v ery pro cess , the bac kground kno wledge canb e used to input a bias to w ard certain t yp es of substructures . This bac kground kno wledgeis enco ded in the form of rules for ev aluating substructures , and can represen t domain indep enden t or domain dep enden t rules . Eac h time a substructure is ev aluated , these input ucture Disco ver yrules are used to determine the v alue of the substructure under consideration . Becauseonly the most fa v ored substructures are k ept and expanded , these rules bias the disco v erypro cess of the system .Eac h bac kground rule can b e assigned a p ositiv e , zero , or negativ e w eigh t , that biasesthe pro cedure to w ard a t yp e of substructure , eliminates the use of the rule , or biases thepro cedure a w a y from a t yp e of substructure , resp ectiv ely . The v alue of a substructure isde ned as the description length DL of the input graph using the substructure m ulti plied b y the w eigh ted v alue of eac h bac kground rule from a set of rules R applied to thesubstructure .v al ue s D L G s j R jYr ruler s er Three domain indep enden t heuristics that ha v e b een incorp orated as rules in to the Sub due system are compactness , connectivit y , and co v erage . F or the de nitions of these rules ,w e will let G represen t the input graph , s represen t a substructure in the graph , and Irepresen t the set of instances of the substructure s in G . The instance w eigh t w of aninstance i I of a substructure s is de ned to b ew i s BnZr matchcost i s siz e i where siz e i v er tices i edg es i . If the matc h cost is greater than the size of thelarger graph , then w i s . The instance w eigh ts are used in these rules to compute aw eigh ted a v erage o v er instances of a substructure . A v alue of is added to eac h form ula sothat the exp onen tial w eigh ts can b e used to con trol the rule s signi cance .The rst rule , c omp actness , is a generalization of W ertheimer s F actor of Closur e , whic hstates that h uman atten tion is dra wn to closed structures W ertheimer , . A closedsubstructure has at least as man y edges as v ertices , whereas a non closed substructurehas few er edges than v ertices Prather , . Th us , closed substructures ha v e a highercompactness v alue . Compactness is de ned as the w eigh ted a v erage of the ratio of then um b er of edges in the substructure to the n um b er of v ertices in the substructure .compactness s I j Xi I w i s edg es i v er tices i The second rule , c onne ctivity , measures the amoun t of external connection in the in stances of the substructure . The connectivit y rule is a v arian t of W ertheimer s F actorof Pr oximity W ertheimer , , and is related to earlier n umerical clustering tec hniques Zahn , . These w orks demonstrate the h uman preference for isolated substructures ,that is , substructures that are minimally related to adjoining structure . Connectivit y mea sures the isolation of a substructure b y computing the in v erse of the a v erage n um b er ofexternal connections o v er all the w eigh ted instances of the substructure in the input graph .An external c onne ction is de ned here as an edge that connects a v ertex in the substructureto a v ertex outside the substructure . The form ula for determining the connectivit y of asubstructure s with instances I in the input graph G is giv en b elo w . Holderconnectiv ity s I j Xi I w i s num exter nal conns i The third rule , c over age , measures the fraction of structure in the input graph describ edb y the substructure . The co v erage rule is motiv ated from researc h in inductiv e learning andpro vides that concept descriptions describing more input examples are considered b etter Mic halski Stepp , . Although MDL measures the amoun t of structure , the co v eragerule includes the relev ance of this sa vings with resp ect to the size of the en tire input graph .Co v erage is de ned as the n um b er of unique v ertices and edges in the instances of thesubstructure divided b y the total n um b er of v ertices and edges in the input graph . In thisform ula , the unique structur e i of an instance i is the n um b er of v ertices and edges in ithat ha v e not already app eared in previous instances in the summation .cov er ag e s Pi I w i s uniq ue str uctur e i siz e G Domain dep enden t rules can also b e used to guide the disco v ery pro cess in a domainwhere scien tists can con tribute their exp ertise . F or example , CAD circuits generally consistof t w o t yp es of comp onen ts , activ e and passiv e comp onen ts . The activ e comp onen ts arethe main driving comp onen ts . Iden tifying the activ e comp onen ts is the rst step in under standing the main function of the circuit . T o add this kno wledge to Subdue w e includea rule that assigns higher v alues to substructures circuit comp onen ts represen ting activ ecomp onen ts and lo w er v alues to substructures represen ting passiv e comp onen ts . Since theactiv e comp onen ts ha v e higher scores , they are exp ected to b e selected . The system canthen fo cus the atten tion on the activ e comp onen ts whic h will b e expanded to the functionalsubstructures .Another metho d of biasing the disco v ery pro cess with bac kground kno wledge is to letbac kground rules a ect the prior probabilities of p ossible substructures . Ho w ev er , c ho osingthe appropriate prior probabilities to express desired prop erties of substructures is di cult , but indicates a future direction for the inclusion of bac kground kno wledge in to thesubstructure disco v ery pro cess . . Exp erime n tsThe exp erimen ts in this section ev aluate Subdue s substructure disco v ery capabilit y insev eral domains , including c hemical comp ound analysis , scene analysis , CAD circuit designanalysis , and analysis of an arti cially generated structural database .Tw o goals of our substructure disco v ery system are to nd substructures that can reducethe amoun t of information needed to describ e the data , and to nd substructures that areconsidered in teresting for the giv en database . As a result , w e ev aluate the Subdue systemin this section along these t w o criteria . First , w e measure the amoun t of compression thatSubdue pro vides across a v ariet y of databases . Second , w e use the Subdue system with theadditional bac kground kno wledge rules to re disco v er substructures that ha v e b een iden ti edas in teresting b y exp erts in eac h sp eci c domain . Section . describ es the domains usedin these exp erimen ts , and Section . presen ts the exp erimen tal results . ucture Disco ver y OCH OHFigure Cortisone . C C H C C H C C H Natural rubb er all cis p olyisoprene . . Domains . . Chemical Compound Anal ysisChemical comp ounds are ric h in structure . Iden ti cation of the common and in terestingsubstructures can b ene t scien tists b y iden tifying recurring comp onen ts , simplying the datadescription , and fo cusing on substructures that stand out and merit additional atten tion .Chemical comp ounds are represen ted graphically b y mapping individual atoms , suc h ascarb on and o xygen , to lab eled v ertices in the graph , and b y mapping b onds b et w een theatoms on to lab eled edges in the graph . Figures , , and sho w the graphs represen tingthe c hemical comp ound databases for cortisone , rubb er , and a p ortion of a DNA molecule . . . Scene Anal ysisImages and scene descriptions pro vide a ric h source of structure . Images that h umansencoun ter , b oth natural and syn thesized , ha v e man y structured sub comp onen ts that dra wour atten tion and that help us to in terpret the data or the scene .Disco v ering common structures in scenes can b e useful to a computer vision system .First , automatic substructure disco v ery can help a system in terpret an image . Instead ofw orking from lo w lev el v ertices and edges , Subdue can pro vide more abstract structuredcomp onen ts , resulting in a hierarc hical view of the image that the mac hine can analyze atman y lev els of detail and fo cus , dep ending on the goal of the analysis . Second , substructuredisco v ery that mak es use of an inexact graph matc h can help iden tify ob jects in a imageof a scene where noise and orien tation di erences are lik ely to exist . If an ob ject ap p ears often in the scene , the inexact graph matc h driving the Subdue system ma y capturesligh tly di eren t views of the same ob ject . Although an ob ject ma y b e di cult to iden tify Holder NNN N HHHO N N O PO OH OO PO OH OO PO O PO HO HHO ON ONN N N N PO HO OO ONH NNO H PO HO OO NN O H NNN N HNadenine guanine thymineadeninecytosinethymineFigure P ortion of a DNA molecule . Figure Scene analysis example . ucture Disco ver y f a l k x pt mFigure P ossible v ertices and lab els . l l l l ll l l l l l l ll ll t tt t tl tl t l ttm a lll a afaFigure P ortion of graph represen ting scene in Figure .from just one picture , Subdue will matc h instances of similar ob jects , and the di er ences b et w een these instances can pro vide additional information for iden ti cation . Third ,substructure disco v ery can b e used to compress the image . Replacing common in terestingsubstructures b y a single v ertex simpli es the image description and reduces the amoun t ofstorage necessary to represen t the image .T o apply Subdue to image data , w e extract edge information from the image andconstruct a graph represen ting the scene . The graph represen tation consists of eigh t t yp esof v ertices and t w o t yp es of arcs e dge and sp ac e . The v ertex lab els f , a , l , t , k , x , p , andm follo w the W altz lab elings W altz , of junctions of edges in the image and represen tthe t yp es of v ertices sho wn in Figure . An e dge arc represen ts the edge of an ob ject in theimage , and a sp ac e arc links non connecting ob jects together . The e dge arcs represen t anedge in the scene that connects t w o v ertices , and the sp ac e arcs connect the closest v erticesfrom t w o disjoin t neigh b oring ob jects . Distance , curv e , and angle information has not b eenincluded in the graph represen tation , but can b e added to giv e additional information ab outthe scene . Figure sho ws the graph represen tation of a p ortion of the scene depicted inFigure . In this gure , the e dge arcs are solid and the sp ac e arcs are dashed . Holder drain drain GNDgate gatesourceVCC ext pin n mosfet connect ext pinn mosfetdrain gate source drain gate sourceconnectFigure Ampli er circuit and graph represen tation . . . CAD Cir cuit Anal ysisIn this domain , w e emplo y Subdue to nd circuit comp onen ts in CAD circuit data . Disco v ery of substructures in circuit data can b e a v aluable to ol to an engineer who is attempting toiden tify common reusable parts in a circuit la y out . Replacing individual comp onen ts in thecircuit description b y larger substructure descriptions will also simplify the represen tationof the circuit .The data for the circuit domain w as obtained from National Semiconductor , and con sists of a set of comp onen ts making up a circuit as output b y the Cadence Design System .The particular circuit used for this exp erimen t is a p ortion of an analog to digital con v erter . Figure presen ts a circuit for an ampli er and giv es the corresp onding graphrepresen tation . . . Ar tificial DomainIn the nal domain , w e arti cially generate graphs to ev aluate Subdue s abilit y to disco v ersubstructures capable of compressing the graph . F our substructures are created of v aryingsizes with randomly selected v ertices and edges see Figure . The name of a substructurere ects the n um b er of v ertices and edges in its graph represen tation . Next , these substruc tures are em b edded in larger graphs whose size is times the size of the substructure .The graphs v ary across four parameters n um b er of p ossible v ertex and edge lab els onetimes and t w o times the n um b er of lab els used in the substructure , connectivit y of thesubstructure or external connections , co v erage of the instances and , and ucture Disco ver y F our arti cial substructures used to ev aluate Subdue .the amoun t of distortion in the instances , or distortions . This yields a total of for eac h di eren t substructure . . Exp erimen tal Results . . Experiment D a t a compressionIn the rst exp erimen t , w e test Subdue s abilit y to compress a structural database . Usinga b eam width of and Subdue s pruning mec hanism , w e applied the disco v ery algorithm toeac h of the databases men tioned ab o v e . W e rep eat the exp erimen t with matc h thresholdsranging from . to . in incremen ts of . . T able sho ws the description length DL of theoriginal graph , the description length of the b est substructure disco v ered b y Subdue , andthe v alue of compression . Compression here is de ned as DL of compressed graphDL of original graph . Figure ,sho ws the actual disco v ered substructures for the rst four datasets .As can b e seen from T able , Subdue w as able to reduce the database to sligh tlylarger than of its original size in the b est case . The a v erage compression v alue o v erall of these domains treating the arti cial graphs as one v alue is . . The results ofthis exp erimen t demonstrate that the substructure disco v ered b y Subdue can signi can tlyreduce the amoun t of data needed to represen t an input graph . W e exp ect that compressingthe graph using com binations of substructures and hierarc hies of substructures will realizeev en greater compression in some databases . HolderDatabase DLoriginal Thresholdoptimal DLcompressed CompressionRubb er . . . . . . . . . . . . encils . . . . M . . . . S . . . . S . . . . BlankSub . . . . And . . . . cial a vg . o v er graphs . . . . . able Graph compression results . la OCCO C CC C H a b c d Figure Best substructure for a rubb er database , b cortisone database , c DNAdatabase , and d image database . ucture Disco ver yFigure Benzene ring disco v ered b y Subdue . . . Experiment Re disco ver y of kno wn substr uctures using ba ck gr oundkno wledgeAnother w a y of ev aluating the disco v ery pro cess is to ev aluate the inter estingness of thedisco v ered substructures . The determination of this v alue will c hange from domain todomain . As a result , in this second set of exp erimen ts w e test Subdue s abilit y to disco v ersubstructures that ha v e already b een lab eled as imp ortan t b y exp erts in the domains underconsideration .In the c hemical comp ound domain , c hemists frequen tly describ e comp ounds in terms ofthe building bl o c k comp onen ts that are hea vily used . F or example , in the rubb er comp ounddatabase sho wn in Figure , the comp ound is made up of a c hain of structures that arelab eled b y c hemists as isopr ene units . Subdue s abilit y to re disco v er this structure isexempli ed in Figure . This substructure , whic h w as disco v ered using the MDL principlewith no extra bac kground kno wledge , represen ts an isoprene unit .Although Subdue w as able to re disco v er isoprene units without extra bac kgroundkno wledge , the substructure a ording the most compression will not alw a ys b e the most in teresting or imp ortan t substructure in the database . F or example , in the cortisone databasethe b enzene ring whic h consists of a ring of carb ons is not disco v ered using only the MDLprinciple . Ho w ev er , the additional bac kground rules can b e used to increase the c hance of nding in teresting substructures in these domains . In the case of the cortisone comp ound ,w e kno w that the in teresting structures exhibit a c haracteristic of closure . Therefore , w egiv e a strong w eigh t . to the c omp actness bac kground rule and use a matc h threshold of . to allo w for deviations in the b enzene ring instances . In the resulting output , Subdue nds the b enzene ring sho wn in Figure .In the same w a y , w e can use the bac kground rules to nd the p encil substructure inthe image data . When the image in Figure is view ed , the substructure of in terest is thep encil in its v arious forms . Ho w ev er , the substructure that a orded the most compressiondo es not mak e up an en tire p encil . W e kno w that the p encils ha v e a high degree of closureand of co v erage , so the w eigh ts for these rules are set to . . With these w eigh ts , Subdueis able to nd the p encil substructure sho wn in Figure for all tested matc h thresholdsb et w een . and . . . Hierarc hical Concept Disco v eryAfter a substructure is disco v ered , eac h instance of the substructure in the input graph canb e replaced b y a single v ertex represen ting the en tire substructure . The disco v ery pro cedurecan then b e rep eated on the compressed data set , resulting in new in teresting substructures .If the newly disco v ered substructures are de ned in terms of existing substructure concepts ,the substructure de nitions form a hierarc h y of substructure concepts . Holder ll l a aFigure P encil substructure disco v ered b y Subdue .Hierarc hical concept disco v ery also adds the capabilit y to impro v e Subdue s p erfor mance . When Subdue is applied to a large input graph , the complexit y of the algorithmprev en ts consideration of larger substructures . Using hierarc hical concept disco v ery , Sub due can rst disco v er those smaller substructures whic h b est compress the data . Applyingthe compression reduces the graph to a more manageable size , increasing the c hance thatSubdue will nd the larger substructures on the subsequen t passes through the database .Once Subdue selects a substructure , all v ertices that comprise the exact instances ofthe substructure are replaced in the graph b y a single v ertex represen ting the disco v eredsubstructure . Edges connecting v ertices outside the instance to v ertices inside the instanceno w connect to the new v ertex . Edges in ternal to the instance are remo v ed . The disco v erypro cess is then applied to the compressed data . If a hierarc hical description of concepts isparticularly desired , hea vier w eigh t can b e giv en to substructures whic h utilize previouslydisco v ered substructures . The increased w eigh t re ects increased atten tion to this substruc ture . Figure illustrates the compressed rubb er comp ound graph using the substructuresho wn in Figure .T o demonstrate the abilit y of Subdue to nd a hierarc h y of substructures , w e let the sys tem mak e m ultiple passes through a database that represen ts a p ortion of a DNA molecule .Figure sho ws a p ortion of t w o c hains of a double helix , using three pairs of bases whic hare held together b y h ydrogen b onds . Figure sho ws the substructures found b y Subdueafter eac h of three passes through the data . Note that , on the third pass , Subdue link edtogether the instances of the substructure in the second pass to nd the c hains of the doublehelix .Although replacing p ortions of the input graph with the disco v ered substructures com presses the data and pro vides a basis for disco v ering hierarc hical concepts in the data , thesubstructure replacemen t pro cedure b ecomes more complicated when concepts with inexactinstances are disco v ered . When inexact instances of a disco v ered concept are replaced b ya single v ertex in the data , all distortions of the graph di erences b et w een the instancegraph and the substructure de nition m ust b e attac hed as annotations to the v ertex lab el . ucture Disco ver y S C C H valued substructure S SS SS C C H C C H C C H G graph using discovered substructureFigure Compressed graph for rubb er comp ound data . Holder O PO S O PO OH OO PO OH OO PO OHO OH O O Highest valued substructure after First Pass Highest valued substructure after Second Pass Highest valued substructure after Third PassOFigure Hierarc hical disco v ery in DNA data . ucture Disco ver y . ConclusionsExtracting kno wledge from structural databases requires the iden ti cation of rep etitiv e sub structures in the data . Substructure disco v ery iden ti es in teresting and rep etitiv e structurein structural data . The substructures represen t concepts found in the data and a means ofreducing the complexit y of the represen tation b y abstracting o v er instances of the substruc ture . W e ha v e sho wn ho w the minim um description length MDL principle can b e used top erform substructure disco v ery in a v ariet y of domains . The substructure disco v ery pro cesscan also b e guided b y bac kground kno wledge . The use of an inexact graph matc h allo wsdeviation in the instances of a substructure . Once a substructure is disco v ered , instancesof the substructure can b e replaced b y the concept de nition , a ording compression of thedata description and pro viding a basis for disco v ering hierarc hically de ne d structures .F uture w ork will com bine structural disco v ery with disco v ery of concepts using a linear based represen tation suc h as AutoClass Cheeseman , Kelly , Self , Stutz , T a ylor , F reeman , . In particular , w e will use Subdue to compress the data fed to AutoClass , andlet Subdue ev aluate the in teresting structures in the classes generated b y AutoClass . Inaddition , w e will b e dev eloping a parallel implemen tation of the A utoClass Subduesystem that will enable application of substructure disco v ery to larger structural databases .Ac kno wledgemen tsThis pro ject is supp orted b y NASA gran t NAS . The authors w ould lik e to thankMik e Sha y at National Semiconductor for pro viding the circuit data . W e w ould also lik eto thank Surnjani Djok o and T om Lai for their help with this pro ject . Thanks also to thereview ers for their n umerous insigh tful commen ts .ReferencesBunk e , H . , Allermann , G . . Inexact graph matc hing for structural pattern recog nition . Pattern R e c o gnition L etters , , .Cheeseman , P . , Kelly , J . , Self , M . , Stutz , J . , T a ylor , W . , F reeman , D . . Auto class A ba y esian classi cation system . In Pr o c e e dings of the Fifth International Workshopon Machine L e arning , pp . .Conklin , D . , Glasgo w , J . . Spatial analogy and subsumption . In Pr o c e e dings of theNinth International Machine L e arning Workshop , pp . .Derthic k , M . . A minimal enco ding approac h to feature disco v ery . In Pr o c e e dings ofthe Ninth National Confer enc e on A rti cial Intel ligenc e , pp . .Fisher , D . H . . Kno wledge acquisition via incremen tal conceptual clustering . MachineL e arning , , .F u , K . S . . Syntactic Pattern R e c o gnition and Applic ations . Pren tice Hall .Holder , L . B . , Co ok , D . J . , Bunk e , H . . F uzzy substructure disco v ery . In Pr o c e e dingsof the Ninth International Machine L e arning Confer enc e , pp . . HolderHolder , L . B . , Co ok , D . J . . Disco v ery of inexact concepts from structural data .IEEE T r ansactions on Know le dge and Data Engine ering , , .Jeltsc h , E . , Kreo wski , H . J . . Grammatical inference based on h yp eredge replace men t . In F ourth International Workshop on Gr aph Gr ammars and Their Applic ationto Computer Scienc e , pp . .Leclerc , Y . G . . Constructing simple stable descriptions for image partitioning . In ternational journal of Computer Vision , , .Levinson , R . . A self organizing retriev al system for graphs . In Pr o c e e dings of theSe c ond National Confer enc e on A rti cial Intel ligenc e , pp . .Mic halski , R . S . , Stepp , R . E . . Learning from observ ation Conceptual clustering .In Mic halski , R . S . , Carb onell , J . G . , Mitc hell , T . M . Eds . , Machine L e arning A n A rti cial Intel ligenc e Appr o ach , V ol . I , pp . . Tioga Publishing Compan y .Miclet , L . . Structur al Metho ds in Pattern R e c o gnition . Chapman and Hall .P ednault , E . P . D . . Some exp erimen ts in applying inductiv e inference principlesto surfa ce reconstruction . In Pr o c e e dings of the International Joint Confer enc e onA rti cial Intel ligenc e , pp . .P en tland , A . . P art segmen tation for ob ject recognition . Neur al Computation , , .Prather , R . . Discr ete Mathemetic al Structur es for Computer Scienc e . Hough tonMi n Compan y .Quinlan , J . R . , Riv est , R . L . . Inferring decision trees using the minim um descrip tion length principle . Information and Computation , , .Rao , R . B . , Lu , S . C . . Learning engineering mo dels with the minim um descrip tion length principle . In Pr o c e e dings of the T enth National Confer enc e on A rti cialIntel ligenc e , pp . .Rissanen , J . . Sto chastic Complexity in Statistic al Inquiry . W orld Scien ti c PublishingCompan y .Sc halk o , R . J . . Pattern R e c o gnition Statistic al , Structur al and Neur al Appr o aches .John Wiley Sons .Segen , J . . Graph clustering and mo del learning b y data compression . In Pr o c e e dingsof the Seventh International Machine L e arning Workshop , pp . .Thompson , K . , Langley , P . . Concept formation in structured domains . In Fisher ,D . H . , P azzani , M . Eds . , Conc ept F ormation Know le dge and Exp erienc e in Un sup ervise d L e arning , c hap . . Morgan Kaufmann Publishers , Inc .W altz , D . . Understanding line dra wings of scenes with shado ws . In Winston , P . H . Ed . , The Psycholo gy of Computer Vision . McGra w Hill . ucture Disco ver yW ertheimer , M . . La ws of organization in p erceptual forms . In Ellis , W . D . Ed . , ASour c eb o ok of Gestalt Psycholo gy , pp . . Harcourt , Brace and Compan y .Winston , P . H . . Learning structural descriptions from examples . In Winston , P . H . Ed . , The Psycholo gy of Computer Vision , pp . . McGra w Hill .Y oshida , K . , Moto da , H . , Indurkh y a , N . . Unifying learning metho ds b y coloreddigraphs . In Pr o c e e dings of the L e arning and Know le dge A c quisition Workshop atIJCAI .Zahn , C . T . . Graph theoretical metho ds for detecting and describing gestalt clusters .IEEE T r ansactions on Computers , , . "
"Journal of Articial Intelligence Research Submitted published Bias DrivenRevision of Logical Domain Theories Moshe Koppel KOPPEL Ronen Feldman FELDMAN Department of Mathematics and Computer Science ,Bar Ilan University, Ramat Gan, Israel Alberto Maria Segre SEGRE Department of Computer Science ,Cornell University, Ithaca, NY , USA Abstract The theory revision problem is the problem of ho wbest to go about revising a decient domain theory using information contained in examples that expose inaccuracies. In this paper we present our approach to the theory revision problem for propositional domain theories. The approach described here, called PTR, uses probabilities associated with domain theory elements to numerically track the owo fproof through the theory .This allows us to measure the precise role of a clause or literal in allowing or pre venting a desired or undesired deri vation for a gi ven example. This information is used to efciently locate and repair a wed elements of the theory . PTR is pro vedt oconverget oatheory which correctly classies all examples, and sho wn experimentally to be fast and accurate e venfor deep theories. . Introduction One of the main problems in b uilding expert systems is that models elicited from experts tend to be only approximately correct. Although such hand coded models might mak eagood rst approximation to the real w orld, theytypically contain inaccuracies that are exposed when a f act is asserted that does not agree with empirical observation. The theory revision problemis the problem of ho wbest to go about re vising a knowledge base on the basis of a collection of examples, some of which expose inaccuracies in the original kno wledge base. Of course, there may be man ypossible revisions that suf ciently account for all of the observed examples ideally , one would nd a revised knowledge base which is both consistent with the examples and as faithful as possible to the original knowledge base. Consider,for example, the follo wing simple propositional domain theory ,.This theory , although a wed and incomplete, is meant to recognize situations where an in vestor should b uy stock in a soft drink compan y. buy stockincreased demand product liability product liability popular product unsafe packaging increased demand popular product established market increased demand new market superior avor . The theory essentially states that buying stock in this compan yisagood idea if demand for its product is expected to increase and the compan yi snot expected to face product liability la wsuits. In this theory ,product liability lawsuits may result if the product is popular and therefore may present an attracti ve target for sabotage and if the packaging is not tamper proof. Increased product demand results if the product is popular and enjoys a large market share, or if there are AI Access Foundation and Mor ganKaufmann Publishers. All rights reserved.KOPPEL,FELDMAN, SEGRE newmarket opportunities and the product boasts a superior a vor. Using the closed w orld assumption, buy stockis derivable giventhat the set of true observable propositions is precisely , say, popular product ,established market ,celebrity endorsement ,or popular product ,established market ,colorful label butnot if theyare, say, unsafe packaging ,new market ,or popular product ,unsafe packaging ,established market . Suppose no wthat we are told for various examples whether buy stockshould be deri vable. Forexample, suppose we are told that if the set of true observable propositions is popular product ,unsafe packaging ,established market thenbuy stockis false, unsafe packaging ,new market thenbuy stockis true, popular product ,established market ,celebrity endorsement thenbuy stockis true, popular product ,established market ,superior avor thenbuy stockis false, popular product ,established market ,ecologically correct thenbuy stockis false, and new market ,celebrity endorsement thenbuy stockis true. Observethat examples , , and are misclassied by the current theory .Assuming that the explicitly gi veninformation re garding the e xamples is correct, the question is ho wt orevise the theory so that all of the examples will be correctly classied. .. Two Paradigms One approach to this problem consists of enumerating partial proofs of the various examples in order to nd a minimal set of domain theory elements i.e., literals or clauses the repair of which will satisfy all the e xamples EITHER,Ourston Moone y, inpress . One problem with this approach is that proof enumeration e venfor asingleexample is potentially exponential in the size of the theory .Another problem with this approach is that it is unable to handle ne gated internal literals, and is restricted to situations where each example must belong to one and only one class. These problems suggest that it w ould be worthwhile to circumvent proof enumeration by employing incremental numerical schemes for focusing blame on specic elements. Acompletely different approach to the re vision problem is based on the use of neural networks KBANN, Towell Sha vlik, . The idea is to transform the original domain theory into netw ork form, assigning weights in the graph according to some pre established scheme. The connection weights are then adjusted in accordance with the observ ed examples using standard neural network backpropagation techniques. The resulting network is then translated back into clausal form. The main disadvantage of this method that it lacks representational transparency the neural network representation does not preserv ethe structure of the original knowledge base while revising it. As a result, a great deal of structural information may be lost translating back and forth between representations. Moreover, such translation imposes the limitations of both representations for example, since neural netw orks are typically slo wto converge, the method is practical for only v ery shallo wdomain theories. Finally,revised domain theories obtained via translation from neural networks tend to be signicantly lar ger than their corresponding original domain theories. Other approaches to theory revision which are much less closely related to the approach we will espouse here are RTLS Ginsber g, , KR FOCL Pazzani Brunk, , and ODYSSEUS W ilkins, . .. Probabilistic Theory Revision Probabilistic Theory Revision PTR is a ne wapproach to theory re vision which combines the best features of the tw oapproaches discussed abo ve.The starting point for PTR is the observation that an ymethod for choosing among se veral possible revisions is based on some implicit bias, namely the a priori probability that each element clause or literal of the domain theory requires revision. In PTR this bias is made explicit right from the start. That is, each element in the theory is assigned some a priori probability that it is not a wed. These probabilities might be assigned by an expert or simply chosen by default. The mere existence of such probabilities solves tw ocentral problems at once. First, these probabilities v ery naturally dene the best i.e., most probable revision out of a gi venset of possible re visions. Thus, our objecti ve iswell dened there is no need to impose articial syntactic or semantic criteria for identifying the optimal re vision. Second, these probabilities can be adjusted in response to newly obtained information. Thus the yprovide a frame work for incremental revision of the awed domain theory. Briey,then, PTR is an algorithm which uses a set of pro vided examples to incrementally adjust probabilities associated with the elements of a possibly a wed domain theory in order to nd the most probable set of revisions to the theory which will bring it into accord with the examples., PTR incrementally adjusts weights associated with domain theory elements lik eEITHER, all stages of PTR are carried out within the symbolic logic frame work and the obtained theories are not probabilistic. As a result PTR has the following features itcan handle a broad range of theories including those with ne gated internal literals and multiple roots. itis linear in the size of the theory times the number of gi venexamples. itproduces relati vely small, accurate theories that retain much of the structure of the original theory. itcan exploit additional user provided bias. In the next section of this paper we formally dene the theory re vision problem and discuss issues of data representation. We lay the foundations for an yfuture approach to theory re vision by introducing very sharply dened terminology and notation. In Section we propose an efcient algorithm for nding awed elements of a theory ,and in Section we sho whow to revise these elements. Section describes ho wthese twocomponents are combined to form the PTR algorithm. In Section , we also discuss the termination and con vergence properties of PTR and walk through a simple example of PTR in action. In Section we experimentally e valuate PTR and compare it to other theory revision algorithms. In Section , we sum up our results and the following section we will mak eprecise the notion of most probable set of revisions. ,FELDMAN, SEGRE indicate directions for further research. The formal presentation of the work described here is, unfortunately ,necessarily dense. T o aid the more casual reader ,w ehav emovedall formal proofs to three separate appendices. In particular ,i nthe third appendix we pro ve that, under appropriate conditions, PTR con verges. Reading of these appendices can safely be postponed until after the rest of the paper has been read. In addition, we provide in Appendix D, a quick reference guide t othe notation used throughout the paper .W ewould suggest that a more casual reader might prefer to focus on Section , followed by a cursory reading of Sections and , and a more thorough reading of Section . . Representing the Problem Apropositional domain theory ,denoted,i sastratied set of clauses of the form Ci HiBi whereCiis a clause label, Hiis a proposition called the headofCi andBiis a set of positi ve and negative literals called the bodyofCi . As usual, the clause Ci HiBirepresents the assertion that the proposition Hiis implied by the conjunction of literals in Bi.The domain theory is simply the conjunction of its clauses. It may be con venient to think of this as a propositional logic program without facts but with ne gation allowed . Aproposition which does not appear in the head of an yclause is said to be observable. A proposition which appears in the head of some clause but does not appear in the body of an y clause is called a root.Anexample,E,isatruth assignment to all observable propositions. It is convenient to think of Eas a set of true observable propositions. Letbe a domain theory with roots ,...,rn.For an example,E,wedene the v ector E E ,...,n E wherei E ri using resolution and i E E ri.Intuitively, E tells us which of the conclusions ,...,rncan be drawn by the e xpert system when gi venthe truth assignment E. Let thetargetdomain theory ,,b esome domain theory which accurately models the domain of interest. In other w ords,represents the correct domain theory .Anordered pair ,E, E , is called an exemplarof the domain if i E the exemplar is said to be an IN exemplar ofri,while ifi E the e xemplar is said to be an OUT exemplarofri.Typically,in theory revision, we know E without knowing . Letbe some possibly incorrect theory for a domain which is in turn correctly modeled by the target theory .Any inaccuracies in will be reected by e xemplars for which E E . Such exemplars are said to be misclassied by.Thus, amisclassied IN exemplar for ri,orfalse negative for ri,will havei E E , while a misclassied OUT exemplar for ri,or false positive for ri,will havei E E .,i ntheory revision we kno w E without knowing . Consider,for example, the domain theory ,T,and example set introduced in Section . The theoryThas only a single root, buy stock.The observable propositions mentioned in the examples are popular product ,unsafe packaging ,established market ,new market ,celebrity prefer the ne wterminology IN OUT t othe more standard positive negative because the lat ter is often used to refer to the classication of the example by the gi ventheory,while we use IN OUT to refer specically to the actual classication of the example. endorsement ,superior avor ,andecologically correct .For the e xample E unsafe packaging ,new market we have E E .Nev ertheless, we are told that E E .Thus,E unsafe packaging ,new market , a misclassied IN e xemplar of the root buy stock. Now, giv enmisclassied e xemplars, there are four re vision oper atorsavailable for use with propositional domain theories add aliteral to an existing clause, delete an existing clause, add anew clause, and delete aliteral from an existing clause. Forneg ation free domain theories, the rst tw ooperations result in specializing ,since theymay allowsome IN e xemplars to become OUT e xemplars. The latter twooperations result in generalizing ,since theymay allowsome OUT e xemplars to become IN e xemplars. We say that a set of revisions to isadequate for a set of e xemplars if, after the re vision operators are applied, all the e xemplars are correctly classied by the revised domain theory . Note that we are not implying that is identical to ,but rather that for e very exemplar E, E , E E . Thus, there may be more than one adequate revision set. The goal of anytheory revision system, then, is to nd the bestrevision set for ,which is adequate for a givenaset of exemplars. .. Domain Theories as Graphs In order to dene the problem e venmore precisely and to set the stage for its solution, we will showhow torepresent a domain theory in the form of a weighted digraph. W ebegin by dening a more general v ersion of the standard A NDORproof tree, which collapses the distinction between ANDnodes and O Rnodes. Forany set of propositions ,...,Pn ,let NAND ,...,Pn b eaBoolean formula which is false if and only if ,...,Pn are all true. Anydomain theory can be translated into an equivalent domain theory consisting of N ANDequations as follows For each clause Ci HiBi,the equation Ci NAND Bi i sin. For each non observable proposition Pappearing in the equation P NAND CP i sin ,whereCP CiHi P , i.e., the set consisting of the label of each clause in whose head isP. For each ne gative literalPappearing in ,the equation P NAND P i sin. contains no equations other than these. Observethat the literals of are the literals of together with the ne wliterals Ci which correspond to the clauses of .Most important, is equivalent toin the sense that for each literal linand anyassignment Eof truth values to the observable propositions of ,E lif and only if E l. the event that ne gative literals appear in the domain theory ,the consequences of applying these operators are slightly less ob vious. This will be made precise in the second part of this section. ,FELDMAN, SEGRE Consider,for example, the domain theory of Section . The set of N ANDequations is buy stock NAND , NAND increased demand ,product liability , product liability NAND product liability , increased demand NAND , , product liability NAND , NAND popular product ,unsafe packaging , NAND popular product ,established market , and NAND new market ,superior avor . Observethatbuy stockis true in for precisely those truth assignments to the observ ables for whichbuy stockis true inT. We now useto obtain a useful graph representation of .For an equation iin,leth i refer to the left side of iand letb i refer to the set of literals which appear on the right side of i.I nother words, h i NAND b i . Denition Adt graph for a domain theory consists of a set of nodes which correspond to the literals of and a set of directed edges corresponding to the set of ordered pairs x,yx h i ,yb i ,i . In addition, for each root rwe add an edge, er,leading into r from some articial node . In other w ords,consists of edges from each literal in to each of its antecedents. The dt graph representation of is shown in Figure . Letnebe the node to which the edge eleads and let nebe the node from which it comes. If neis a clause, then we say that eis aclause edg e ifneis a root, then we say that eis aroot edge ifneis a literal and neis a clause, then we say that eis aliteral edge ifneis a proposition and ne is its negation, then we say that eis anegation edge . The dt graph is very much lik ea nANDORgraph for .I thas, however, a very signicant advantage overANDORgraphs because it collapses the distinction between clause edges and literal edges which is central to the A NDORgraph representation. In fact, e venneg ation edges which do not appear at all in the A NDORrepresentation are not distinguished from literal edges and clause edges in the dt graph representation. In terms of the dt graph ,there are tw obasic revision operators deleting edges or adding edges. What are the effects of adding or deleting edges from ?Ifthe length of e very path from arootrto a node nis even odd then nis said to be an e ven odd node for ri.Ifneis even odd forri,theneis said to be e ven odd forri. Of course it is possible that the depth of an edge is neither evennor odd. Deleting an e venedge forrispecializes the denitions of riin the sense that ifis the result of the deletion, then i E i E for all exemplarsE, E likewise, adding an e venedge forrigeneralizes the denition of riin the sense that if is the result of adding the edge to theni E i E . Analogously ,deleting an odd edge for rigeneralizes the denition of ri,while adding an odd edge for rispecializes the denition of ri. Deleting or adding an edge which is neither odd nor e venforrimight result in a ne wdenition of riwhich is neither strictly more general nor strictly more specic. To understand this intuiti vely,rst consider the case in which there are no ne gation edges in .Then an evenedge inrepresents a clause in ,s othat deleting is specialization and adding is generalization. An odd edge in represents a literal in the body of a clause in so that deleting is generalization and adding a specialization. Now, ifa nodd number of ne gation edges liability product liability stock increased demand new market popular product unsafe packagingsuperior avorestablished market Figure The dt graph, ,ofthe theory . are present on the path from rito an edge then the role of the edge is re versed. .. Weighted Graphs Aweighted dt gr aphis an ordered pair ,wwhereis a dt graph wand is an assignment of values in , to each node and edge in .For an edge e,w e i smeant to represent the usersdegree of condence that the edge eneed not be deleted to obtain the correct domain theory.For a node n,w n i sthe usersdegree of condence that no edge leading from the node nneed be added in order to obtain the correct domain theory .Thus, for e xample, the assignment w n that it is certain that no edge need be added to the node nand the assignment w e means that it is certain that eshould not be deleted. Observethat if the node nis labeled by aneg ative literal or an observable proposition then w n ydenition, since graphs obtained by adding edges to such nodes do not correspond to an ydomain theory .Likewise, ifeis a root edge or a ne gation edge, then w e . ,FELDMAN, SEGRE Forpractical reasons, we conate the weight w e o fa nedgeeand the weight, w ne , of the nodene,into a single v alue,p e w e w ne , associated with the edge e.The valuep e is the userscondence that eneed not be repaired, either by deletion or by dilution via addition of child edges. There are man yways that these values can be assigned. Ideally,theycan be provided by the expert such that the yactually reect the e xpertsdegree of condence in each element of the theory.Howev er, eveninthe absence of such information, values can be assigned by default for example, all elements can be assigned equal v alue. Amore sophisticated method of assigning values is to assign higher values to elements which ha ve greater semantic impact e.g., those closer to the roots . The details of one such method are gi veni nAppendix A. It is also, of course, possible for the expert to assign some weights and for the rest to be assigned according to some default scheme. Forexample, in the weighted dt graph, ,p,shown in Figure , some edges have been assigned weight near and others ha ve been assigned weights according to a simple default scheme. The semantics of the values associated with the edges can be made clear by considering the case in which it is kno wn that the correct dt graph is a subset of the gi vendt graph,.Consider a probability function on the space of all subgraphs of .The weight of an edge is simply the sum of the probabilities of the subgraphs in which the edge appears. Thus the weight of an edge is the probability that the edge does indeed appear in the target dt graph. We easily extend this to the case where the target dt graph is not necessarily a subgraph of the gi venone. Conversely,giv enonly the probabilities associated with edges and assuming that the deletion of different edges are independent e vents, we can compute the probability of a subgraph, . Sincep e i sthe probability that eis not deleted and p e i sthe probability that eis deleted, it follows that p ep e e . LettingS ,w erewrite this as p eSp e e . We use this formula as a basis for assigning a v alue to each dt graph obtainable from via revision of the set of edges S,eveninthe case where edge independence does not hold and e ven in the case in which is not a subset of .Wesimply dene w eSp e e . In the event thatandare such that Sis not uniquely dened, choose Ssuch that w is maximized. Note that where independence holds and is subgraph of ,w ehav e order to a void confusion it should be emphasized that the meaning of the weights associated with edges is completely dif ferent than that associated with edges of Pearl sBayesian networks . Forus, these weights represent a meta domain theory concept the probability that this edge appears in some un known target domain theory .For Pearl the yrepresent conditional probabilities within a probabilistic do main theory .Thus, the updating method we are about to introduce is totally unrelated to that of Pearl. . . . . . .. . . .... new popular demand product liabilityproduct stock superior avor unsafe packagingestablished market. Figure The weighted dt graph, ,p. w p . .. Objecti vesofTheory Revision Noww ecan formally dene the proper objecti ve ofatheory revision algorithm Given a weighted dt gr aph,pand a set of e xemplars ,nd a dt gr aphsuchthat correctly classies every exemplar in and w is maximal over all suc hdt graphs. Restating this in the terminology of information theory ,w edene the radicalityof a dt graph relative toa ninitial weighted dt graph ,pas Rad eSlog p e eSlog e whereSis the set of edges of which need to be revised in order to obtain .Thus givena weighted dt graph and a set of e xemplars,w ewish to nd the least radical dt graph relati ve ,FELDMAN, SEGRE towhich correctly classies the set of e xemplars. Note that radicality is a straightforw ard measure of the quality of a revision set which neatly balances syntactic and semantic considerations. It has been often noted that minimizing syntactic change alone can lead to counter intuitive results by giving preference to changes near the root which radically alter the semantics of the theory .Onthe other hand, re gardless of the distrib ution of examples, minimizing semantic change alone results in simply appending to the domain theory the correct classications of the gi venmisclassied examples without affecting the classication of anyother examples. Minimizing radicality automatically tak es into account both these criteria. Thus, for e xample, by assigning higher initial weights to edges with greater semantic impact as in our def ault scheme of Appendix A , the syntactic adv antage of revising close to the root is offset by the higher cost of such re visions. F or example, suppose we are gi venthe theory of the introduction and the single misclassied e xemplar unsafe packaging ,new market ,. There are se veral possible revisions which would bring into accord with the e xemplar.We could, for example, add a ne wclause buy stockunsafe packaging new market , deletesuperior avor from clause , deletepopular product andestablished market from clause , or delete increased demand from clause . Giventhe weights of Figure , the deletion of superior avor from clause the least radical revision. Observethat in the special case where all edges are assigned identical initial weights, regardless of their semantic strength, minimization of radicality does indeed reduce to a form of minimization of syntactic change. W ewish to point out, ho wever, that eveni nthis case our denition of syntactic change differs from some previous denitions Wogulis Pazzani, . Whereas those denitions count the number of deleted and added edges, we count the number of edges deleted or added to.T ounderstand wh ythis is preferable, consider the case in which some internal literal, which happens to ha ve a large denition, is omitted from one of the clause in the tar get theory .Methods which count the number of added edges will be strongly biased against restoring this literal, prefering instead to mak eseveraldifferent repairs which collecti vely involvefewer edges than to mak easinglerepair involving more edges. Nevertheless, gi venthe assumption that the probabilities of the various edges in the gi ventheory being mistaken are equal, it is far more intuiti ve torepair only at a single edge, as PTR does. W e agree, though, that once an edge has been chosen for repair ,the chosen repair should be minimal overall equally effecti ve repairs. . Finding Flawed Elements PTR is an algorithm which nds an adequate set of re visions of approximately minimum radicality.Itachievesthis by locating awed edges and then repairing them. In this section we give the algorithm for locating awed edges in the next section we sho whow torepair them. The underlying principle of locating awed edges is to process e xemplars one at a time, in each case updating the weights associated with edges in accordance with the information contained in the e xemplars. W emeasure the owo faproof or refutation through the edges of the graph. The more an edge contrib utes to the correct classication of an example, the more its weight is raised the more it contributes to the misclassication of the example, the more its weight is lo wered. If the weight of an edge drops belo waprespecied revision threshold ,i tis revised. The core of the algorithm is the method of updating the weights. Recall that the weight represents the probability that an edge appears in the tar get domain theory .The most natural w ay to update these weights, then, is to replace the probability that an edge need not be re vised with the conditional probability that it need not be re visedgiven the classication of an e xemplar.As we shall see later ,the computation of conditional probabilities ensures man ydesirable properties of updating which ad hoc methods are liable to miss. .. Processing a Single Exemplar One of the most important results of this paper is that under certain conditions the conditional probabilities of all the edges in the gr aph can be computed in a single bottom up then top down sweep through the dt gr aph.W eshall emplo ythis method of computation e venwhen those conditions do not hold. In this w ay,updating is performed in highly efcient f ashion while, at the same time, retaining the rele vant desirable properties of conditional probabilities. More precisely ,the algorithm proceeds as follo ws. Wethink of the nodes of which represent observable propositions as input nodes, and we think of the v alues assigned by an exampleEto each observ able proposition as inputs. Recall that the assignment of weights to the edges is associated with an implicit assignment of probabilities to various dt graphs obtainable via revision of .For some of these dt graphs, the root riis provable from the e xampleE,while for others it is not. We wish to mak eabottom up pass through ,pin order to compute or at least approximate for each root ri,the probability that the tar get domain theory is such that riis true for the e xampleE.The obtained probability can then be compared with the desired result,i E , and the resulting difference can be used as a basis for adjusting the weights, w e , for each edge e. Let E P Pis true in E if Pis false in E . We say that a node nistrueif the literal of which labels it is true. No w, a node passes the value trueu pthe graph if it is either true or deleted, i.e., if it is not both undeleted and f alse. Thus, for an edge esuch that neis the observable proposition P,the value uE e p e P is the probability of the value truebeing passed up the graph frome. Now, recalling that a node in represents a N ANDoperation, if the truth of a node in is independent of the truth of an yo fits brothers, then for an yedgee,the probability of truebeing passed up the graph is that, in principle, the updating can be performed exactly the same way e veni E P . Thus, the algorithm extends naturally to the case in which there is uncertainty re garding the truth value of some of the observable propositions. ,FELDMAN, SEGRE uE e e schildren e uE s . We calluE e theowofEthroughe. We hav edened the o wuE e such that, under appropriate independence conditions, for an y nodene,uE e i si nfact the probability that neis true given,wandE. Foraformal proof of this, see Appendix B. In particular ,for a rootri,the owuE eri is, eveni nthe absence of the independence conditions, a good approximation of the probability that the target theory is such thatriis true given,wandE. In the second stage of the updating algorithm, we propag ate the difference between each computed v alueuE eri which lies somewhere between and and its target v aluei E which is either or top down through in a process similar to backpropag ation in neural networks. As we proceed, we compute a ne wvaluevE e a swell as an updated value for p e , for every edgeein.The newvaluevE e represents an updating of uE e where the correct classication, E , of the example Ehas been taken into account. Thus, we be gin by setting each v aluevE ri t oreect the correct classication of the example. Let some very small let vE eri E ifi E . Noww eproceed top down through ,computing vE e for each edge in .I neach case we computevE e o nthe basis of uE e , that is, on the basis of ho wmuch of the proof or refutation ofEows through the edge e.The precise formula is vE e e vE f e uE f e wheref e i sthat parent of efor which vE f e ,uE f e min vE f e ,uE f e is greatest. We showin Appendix B wh ythis formula works. Finally,w ecomputepnew e , the newvalues ofp e , using the current value of p e and the values ofvE e anduE e just computed pnew e e vE e uE e . If the deletion of different edges are independent e vents andis known to be a subgraph of ,thenpnew e i sthe conditional probability that the edge eappears in ,giv enthe exemplar E, E see proof in Appendix B . Figure gi vesthe pseudo code for processing a single exemplar. speaking, for the computation of conditional probabilities, we need to use . However, in order to ensure con vergence of the algorithm in all cases, we choose see Appendix C . In the experi ments reported in Section , we use the value .. function BottomUp ,p weighted dt graph ,E exemplar array of real begin S VLeaves foreLeaves do begin ifeEthenu e elseu e e SMerge S,Parents e, end whileSdo begin ePopSuitableParent S,V VAddElement e,V u e p e dChildren e, u d SMerge S,Parents e, end returnu end function TopDown ,p weighted dt graph ,u array of real , E exemplar, real weighted dt graph begin S VRoots forriRoots do begin ifi E ri elsev ri SMerge S,Children ri, end whileSdo begin ePopSuitableChild S,V VAddElement e,V fMostChangedParent e, v e e v f u f p e e v e u e SMerge S,Children e, end return,p end Figure Pseudo code for processing a single e xemplar.The functions BottomUp andTopDown sweep the dt graph. BottomUp returns an array on edges representing proof o w, whileTopDown returns an updated weighted dt graph. We are assuming the dt graph datastructure has been de ned and initialized appropriately .FunctionsChildren,Parents,Roots,andLeavesreturn sets of edges corresponding to the corresponding graph relation on the dt graph. Function MergeandAd dElement operate on sets, and functions PopSuitableParent andPopSuitableChild return an ele ment of its rst ar gument whose children or parents, respecti vely,are all already elements of its second argument while simultaneously deleting the element from the rst set, thus guaranteeing the appropriate graph tra versal strategy. ,FELDMAN, SEGRE Consider the application of this updating algorithm to the weighted dt graph of Figure . We are giventhe exemplar unsafe packaging ,new market ,,i.e., the example in which unsafe packaging andnew market are true and all other observables are false should yield a derivation of the root buy stock.The weighted dt graph obtained by applying the algorithm is shown in Figure . This example illustrates some important general properties of the method. Given an INexemplar,the weight of an odd edg ecannot decr ease and the weight of an even edgecannot incr ease. The analogous property holds for an OUT e xemplar. In the case where no ne gation edge appears in ,this corresponds to the fact that a clause cannot help pre vent a proof, and literals in the body of a clause cannot help complete a .. . . . . .. .. . ... stock product liability product liability popular new marketincreased demand superior avorestablished market unsafe packaging Figure The weighted dt graph of Figure after processing the e xemplar unsafe packaging ,new market ,. proof. Note in particular that the weights of the edges corresponding to the literals popular product andestablished market in clause by the same amount, reecting the identical roles played by them in this e xample. Ho wever, the weight of the edge corresponding to the literal superior avor in clause a great deal more than both those edges, reecting the f act that the deletion of superior avor alone would allo w aproof ofbuy stock,while the deletion of either popular product alone orestablished marketalone would not allo waproof ofbuy stock. An edgewith initial weight is immutable its weight remains for ever.Thus although an edge with weight , such as that corresponding to the literal increased demand in clause , may contribute to the pre vention of a desired proof, its weight is not diminished since we are told that there is no possibility of that literal being awed. If the processed e xemplar can only be correctly classied if a particular edg eeis revised, then the updated pr obability of ewill ewill be immediately r evised. Thus, for e xample, were the initial weights of the edge corresponding to established marketandpopular product oapproach , the weight of the edge corresponding to superior avor approach . Since we use weights only as a temporary device for locating awed elements, this property renders our updating method more appropriate for our purposes then standard backpropagation techniques which adjust weights gradually to ensure con vergence. The computational complexity of pr ocessing a single exemplar is linear in the size of the theory.Thus, the updating algorithm is quite ef cient when compared to re vision techniques which rely on enumerating all proofs for a root. Note further that the computation required to update a weight is identical for e very edge of regardless of edge type. Thus, PTR is well suited for mapping onto ne grained SIMD machines. .. Processing Multiple Exemplars As stated abo ve,the updating method is applied iterati vely to one e xample at a time in random order until some edge drops belo wthe revision threshold, .I fafter a complete cycle no edge has dropped belo wthe revision threshold, the examples are reordered randomly and the updating is continued. Forexample, consider the weighted dt graph of Figure . After processing the e xemplars unsafe packaging ,new market ,, popular product ,established market ,superior avor ,,and popular product ,established market ,celebrity endorsement , we obtain the dt graph shown in Figure . If our threshold is, say , .,then we ha ve torevise the edge corresponding to the clause . This reects the fact that the clause contrib uted we were to choose denition of vE er , then the updated probability would equal . course, by processing the examples one at a time we abandon an ypretense that the algorithm is Bayesian. In this respect, we are proceeding in the spirit of connectionist learning algorithms in which it is assumed that the sequential processing of examples in random order ,asi ftheywere actually independent, approximates the collecti ve effect of the examples. ,FELDMAN, SEGRE . .. . ....... . . . .. . stock product liability product liability popular productestablished market new demand superior avor unsafe packaging Figure The weighted dt graph of Figure after processing e xemplars unsafe packaging ,new market ,, popular product ,established market ,superior avor ,,and popular product ,established market ,celebrity endorsement ,. The clause dropped belo wthe threshold. substantially to the misclassication of the second and third e xamples from the list abo ve while not contributing substantially to the correct classication of the rst. . Revising a Flawed Edge Once an edge has been selected for revision, we must decide ho wt orevise it. Recall that p e represents the product of w e andw ne . Thus, the drop in p e indicates either that eneeds to be deleted or that, less dramatically ,asubtree needs to be appended to the node ne.Thus, we need to determine whether to delete an edge completely or to simply weak en it by adding children intuitively,adding edges to a clause node weak ens the clause by adding conditions to its body , while adding edges to a proposition node weakens the proposition srefutation power by adding clauses to its denition. Further ,i fw edecide to add children, then we need to determine which children to add. .. Finding Relevant Exemplars The rst stage in making such a determination consists of establishing, for each e xemplar,the role of the edge in enabling or pre venting a deri vation of a root. More specically ,for an IN exemplar,E, E ,o fsome root, r,a nedgeemight play a positi ve role by facilitating a proof ofr,o rplay a destructi ve role by pre venting a proof of r,o rmay simply be irrele vant to a proof ofr. Once the sets of e xemplars for which eplays a positi ve role or a destructi ve role are determined, it is possible to append to ean appropriate subtree which ef fectively redenes the role ofesuch that it is used only for those e xemplars for which it plays a positi ve role., then, can we measure the role of ein allowing or pre venting a proof of rfromE? At rst glance, it would appear that it is sufcient to compare the graph with the graph e which results from deleting efrom.IfE randE er or vice versa then it is clear that e is responsible forrbeing pro vable or not pro vable giventhe exemplarE, E .But, this criterion is too rigid. In the case of an OUT e xemplar,eveni fi ti sthe case that E er,i ti sstill necessary to modify ein the event thateallowed anadditional proof ofrfromE.And, in the case of an IN e xemplar,eveni fi tisthe case that E rit is still necessary notto modify ein such a way as to further pre vent a proof of rfromE,since ultimately some proof is needed. Fortunately,the weights assigned to the edges allo wu sthe exibility to not merely determine whether or not there is a proof of rfromEgivenorebutalso to measure numerically the o w ofEthroughrboth with and without e.This is just what is needed to design a simple heuristic which captures the degree to which econtributes to a proof of rfromE. Let ,pbe the weighted dt graph which is being re vised. Let e ,pwherep is identical with p,except that p e . Lete ,pwherepis identical with p,except thatp e that is, eis obtained from by deleting the edge e. Then dene for each root ri Ri E, E ,e, E ue E eri E ue E eri . Then if Ri E, E ,e, ,w esay that eisneededforEandriand if Ri E, E ,e, we say that eisdestructive forEandri. is not strictly incremental in the sense that when an edge is revised its role in proving or refut ingeachexemplar is check ed. Ifstrict incrementality is a desideratum, PTR can be slightly modied so that an edge is revised on the basis of only those e xemplars which ha ve already been processed. Moreo ver, it is generally not necessary to check all e xemplars for rele vance. For example, if eis an odd edge and Eis acorrectly classied IN e xemplar,thenecan be neither needed for E since odd edges can only mak e derivations more difcult nor destructi ve forE sinceEis correctly classied despite e . ,FELDMAN, SEGRE Intuitively,this means, for example, that the edge eis needed for an IN e xemplar,E,ofri,if most of the deri vation ofrifromEpasses through the edge e.W ehav esimply gi venformal denition to the notion that mosto fthe derivation passes through e,namely,that the o w, ue E eri , ofEthroughriwithout e is less than half of the o w,ue E eri , ofEthroughriwith e. Forneg ation free theories, this corresponds to the case where the edge erepresents a clause which is critical for the deri vation ofrifromE.The intuition for destructi ve edges and for OUT exemplars is analogous. Figure gi vesthe pseudo code for computing the needed and destructi ve sets for a gi venedgeeand exemplar set . In order to understand this better ,let us nowreturn to our example dt graph in the state in which we left it in Figure . The edge corresponding to the clause dropped belo wthe threshold. No wlet us check for which e xemplars that edge is needed and for which it is destructive.Computing R E, E ,, for each example Ewe obtain the following R popular product ,unsafe packaging ,established market ,,, . R unsafe packaging ,new market ,,, . R popular product ,established market ,celebrity endorsement ,,, . R popular product ,established market ,superior avor ,,, . R popular product ,established market ,ecologically correct ,,, . R new market ,celebrity endorsement ,,, . function Relevance ,p weighted dt graph , exemplar set ,e edge tuple of set begin N D psavedCopy p forEdo forriRoots do p e uBottomUp ,p,E ue Eu ri ppsaved p e uBottomUp ,p,E ue Eu ri ppsaved ifi E E ue E E E ifRi E ifRi E end end returnN,D end Figure Pseudo code for computing the rele vant sets i.e., the needed and destructi ve sets for a givenedgeeand exemplar set .The general idea is to compare proof ow computed using functionBottomUp both with and without the edge in question for each e xemplar in the e xemplar set. Note that the original weights are sa vedand later restored at the end of the computation. The high value of R popular product ,established market ,celebrity endorsement ,,, reects the fact that without the clause , there is scant hope of a deri vation ofbuy stockfor this example. Of course, in principle, both new market andsuperior avor might still be deleted from the body of clause , thus obviating the need for , but the high weight associated with the literalnew market that this is unlikely . Thelowvalues of R popular product ,established market ,superior avor ,,, and R popular product ,established market ,ecologically correct ,,, reect the fact that eliminating the clause greatly diminish the currently undesirably high owthroughbuy stock i.e., probability of a deri vation ofbuy stock from each of these examples. An interesting case to examine is that of popular product ,unsafe packaging ,established market ,. It is true that the elimination of shelpful in pre venting an unwanted deri vation ofbuy stock because it pre vents a deri vation ofincreased demand which is necessary for buy stockin clause . Nevertheless, Rcorrectly reects the fact that the clause for this exemplar since e veni nthe presence of ,buy stockis not deri vable due to the failure of the literalproduct liability . .. Appending a Subtree LetNbe the set of examples for which eis needed for some root and let Dbe the set of e xamples for which eis destructi ve for some root and not needed for an yother root . Having found the setsNandD,how dow erepaire? At this point, if the set Dis non empty and the set Nis empty,w esimply delete the edge from.W ejustify this deletion by noting that no e xemplars require e,sodeletion will not compromise the performance of the theory .Onthe other hand, if Nis not empty ,w eapply some inductive produce a disjuncti ve normal form DNF logical expression constructed from observable propositions which is true for each e xemplar in Dbutn oexemplar in N.We reformulate this DNF expression as a conjunction of clauses by taking a single ne wliterallas the head of each clause, and using each conjunct in the DNF e xpression as the body of one of the clauses. This set of clauses is con verted into dt graph nwithlas its root. We then suture ntoe by adding to anew nodet,anedge from etot,and another edge from tto the root, l,ofn. In order to understand wh ythis works, rst note the important fact that lik eevery other subroutine of PTR , this method is essentially identical whether the edge, e,being repaired is a clause edge, literal edge or ne gation edge. However, when translating back from dt graph form to domain theory form, the ne wnodetwill be interpreted dif ferently depending on whether neis a clause or a literal. Ifneis a literal, then tis interpreted as the clause nel.Ifneis a clause, algorithm for constructing decision trees from positi ve and negative examples can be used. Our implementation of PTR uses Quinlan, . The use of an inducti ve component to add newsubstructure is due to Ourston and Moone y Ourston Moone y, inpress . ,FELDMAN, SEGRE thentis interpreted as the ne gative literall. Nowi ti splain that those e xemplars for which eis destructi ve will use the graph rooted at tto overcome the effect of e.Ifneis a literal which undesirably e xcludesE,thenEwill get by neby satisfying the clause t ifneis a clause which undesirably allo wsE,thenEwill be stopped by the function Revise ,p weighted dt graph , set of exemplars ,e edge, real weighted dt graph begin N,DRelevance ,p,,e ifDthen begin ifN thenp e else begin p e lNewLiteral DTGraph l,DNF D,N tNewNode AddNode ,t ifClause? ne thenLabel t l elseLabel t NewClause AddEdge ,ne,t p ne,t AddEdge ,t,Root p t,Root e end end return,p end Figure Pseudo code for performing a revision. The function Revisetakes a dt graph, a set of e x emplars,a nedge to be re visede,and a parameter as inputs and produces a revised dt graph as output. The function DNF is an inducti ve learning algorithm that produces a DNF formula that accepts elements of Dbutnot ofN,while the function DTGraph produces a dt graph with the givenroot from the gi venDNF expression as described in the te xt. For the sak eo fexpository sim plicity,w ehav enot shown the special cases in which neis a leaf or eis a negation edge, as dis cussed in Footnote . course, if we were willing to sacrice some ele gance, we could allo wseparate sub routines for the clause case and the literal case. This would allo wu st om akethe dt graphs to be sutured considerably more compact. In particular ,ifneis a literal we could suture the children of linndirectly to ne.Ifneis a clause, we could use the inducti ve algorithm to nd a DNF expression which excludes examples in Dand includes those in N rather than the other way around as we no wd oit . Translating this expression to a dt graphwith root l,w ecould suture ntoby simply adding an edge from the clause neto the root l. Moreover, ifnrepresents a single clause ,...,lmthen we can simply suture each of the leaf nodes ,...,lmdirectly to ne.Note that if neis a leaf or a ne gative literal, it is inappropriate to append child edges tone.I nsuch cases, we simply replace newith a newliteralland append to lbothnand the graph of the clause lne. newliteralt l. Wheneveragraphnis sutured into ,w emust assign weights to the edges of n.Unlike the original domain theory ,howev er, the newsubstructure is really just an artifact of the inducti ve algorithm used and the current rele vant exemplar set. Forthis reason, it is almost certainly inadvisable to try to revise it as ne wexemplars are encountered. Instead, we would prefer that this newstructure be remo vedand replaced with a more appropriate ne wconstruct should the need arise. To ensure replacement instead of revision, we assign unit certainty factors to all edges of the substructure. Since the internal edges of the ne wstructure ha ve weights equal to , the y will neverb erevised. Finally ,w eassign a default weight to the substructure root edge ne,t, that connects the ne wcomponent to the e xistingand we reset the weight of the re vised edge, e,t othe same v alue.Figure gi vesthe pseudo code for performing the re vision step just described. Consider our example from abo ve.Weare repairing the clause . Wehav ealready found that the set Dconsists of the examples popular product ,established market ,superior avor and popular product ,established market ,ecologically correct while the set Nconsists of the single example popular product ,established market ,celebrity endorsement . Using to nd a formula which e xcludesNand includes D,w eobtain celebrity endorsement which translates into the single clause, lcelebrity endorsement .Translating into dt graph form and suturing and simplifying using the technique of F ootnote , we obtain the dt graph shown in Figure . Observenow that the domain theory represented by this dt graph correctly classies the examples popular product ,established market ,superior avor and popular product ,established market ,ecologically correct which were misclassied by the original domain theory . . ThePTR Algorithm In this section we gi ve the details of the control algorithm which puts the pieces of the pre vious twosections together and determines termination. .. Contr ol The PTR algorithm is shown in Figure . We can briey summarize its operation as follows PTR process e xemplars in random order ,updating weights and performing re visions when necessary. Whene verarevision is made, the domain theory which corresponds to the newly re vised graph is checked against all e xemplars. PTR terminates if i All e xemplars are correctly classied, or ii Every edge in the newly revised graph has weight . ,FELDMAN, SEGRE . .. . ... ..... . . .. . . stock product liability product liability popular established market new demand superior avor unsafe packagingcelebrity endorsement Figure The weighted dt graph of Figure after revising the clause the graph has been slightly simplied in accordance with the remark in Footnote . If, after a re vision is made, PTR does not terminate, then it continues processing exemplars in random order. if, after a complete cycle of e xemplars has been processed, there remain misclassied exemplars, then we i Increment the revision threshold so that min , , and ii Increment the v alueassigned to a re vised edge and to the root edge of an added component, so that min , . No ww ebegin anew, processing the e xemplars in new random order. It is easy to see that PTR is guaranteed to terminate. The argument is as follows. W ithin max , cycles, both andwill reach . At this point, e very edge with weight less than be revised and will either be deleted or ha ve its weight reset to . Moreover, any edges added during revision will also be assigned certainty f actor . Thus all edges will ha ve weight the algorithm terminates by the termination criterion ii . Now, wewish to sho wthat PTR not only terminates, but that it terminates with e very exemplar correctly classied. That is, we wish to sho wthat, in fact, termination criterion ii can neverb esatised unless termination criterion i is satised as well. We call this property convergence.InAppendix C we pro ve that, under certain very general conditions, PTR is guaranteed to con verge. .. AComplete Example Let us nowreviewthe example which we ha ve been considering throughout this paper. We begin with the awed domain theory and set of e xemplars introduced in Section . buy stockincreased demand product liability product liability popular product unsafe packaging increased demand popular product established market increased demand new market superior avor . We translate the domain theory into the weighted dt graph ,pof Figure , assigning weights via a combination of user provided information and default values. F or example, the user has indicated that their condence in the rst literal increased demand i nthe body of clause is greater than their condence in the second literal product liability . function PTR ,p weighted dt graph , set of exemplars , ,,,, ve tuple of real weighted dt graph begin whileEsuch that E E do begin forERandomlyPermute do begin uBottomUp ,p,E ,pTopDown ,p,u,E, ifesuch that p e then,pRevise ,p,,, ife,p e , E E then return ,p end max , max , end end Figure The PTR control algorithm. Input to the algorithm consists of a weighted dt graph ,p,aset of exemplars,and vereal valued parameters ,,,,and.The algorithm produces a revised weighted dt graph whose implicit theory correctly classies all e xemplars in . ,FELDMAN, SEGRE We set the revision threshold to ., the reset v alueinitially to . and their respecti ve increments andto .. W enow start updating the weights of the edges by processing the exemplars in some random order. We rst process the e xemplar unsafe packaging ,new market ,. First, the lea veso fthe dt graph are labeled according to their presence or absence in the e xemplar. Second,uE e values proof ow are computed for all edges of the dt graph in bottom up fashion. Ne xt,vE eri values are set to reect the vector of correct classications for the e xample E . Newvalues for vE e are computed in top down fashion for each edge in the dt graph. As these values are computed, ne wvalues for p e are also computed. Processing of this rst exemplar produces the updated dt graph shown in Figure . Processing of e xemplars continues until either an edge weight f alls below indicating a awed domain theory element has been located , a cycle processing of all kno wn exemplars is completed, or the PTR termination conditions are met. For our e xample, after processing the additional e xemplars popular product ,established market ,superior avor , popular product ,established market ,ecologically correct , the weight of the edge corresponding to clause below see Figure , indicating that this edge needs to be revised. We proceed with the revision by using the heuristic in Section . in order to determine for which set of e xemplars the edge in question is needed and for which it is destructi ve.The edge corresponding to the clause sneeded for popular product ,established market ,celebrity endorsement , and is destructi ve for popular product ,established market ,ecologically correct ,, popular product ,established market ,superior avor , . Since the set for which the edge is needed is not empty ,PTR chooses to append a subtree weakening clause than simply deleting the clause outright. Using these sets as input to , we determine that the f actcelebrity endorsement suitably discriminates between the needed and destructi ve sets. Wethen repair the graph to obtain the weighted dt graph sho wn in Figure . This graph corresponds to the theory in which the literal celebrity endorsement has been added to the body of . We now check the newly obtained theory embodied in the dt graph of Figure i.e., ignoring weights against all the e xemplars and determine that there are still misclassied e xemplars, namely unsafe packaging ,new market , new market ,celebrity endorsement ,. Thus, we continue processing the remaining e xemplars in the original random order. After processing the e xemplars popular product ,unsafe packaging ,established market ,, popular product ,established market ,celebrity endorsement ,,and new market ,celebrity endorsement ,, the weight of the edge corresponding to the literal superior avor in clause belowthe revision threshold .W ethen determine that this edge is not needed for an yexemplar and thus the edge is simply deleted. At this point, no misclassied e xemplars remain. The nal domain theory is buy stockincreased demand product liability product liability popular product unsafe packaging increased demand popular product established market celebrity endorsement increased demand new market . This theory correctly classies all known e xemplars and PTR terminates. . Experimental Evaluation In this section we will e xamine experimental evidence that illustrates se veral fundamental hypotheses concerning PTR. W ewish to sho wthat theories produced by PTR are of high quality in three respects the yare of lowradicality, theyare of reasonable size, and the yprovide accurate information re garding exemplars other than those used in the training. PTR converges rapidly that is, it requires fe wcycles to nd an adequate set of revisions. well chosen initial weights pro vided by a domain expert can signicantly impro ve the performance of PTR. More precisely ,giv enatheoryobtained by using PTR to revise a theory on the basis of a set of training examplars, we will test these hypotheses as follows. Radicality .Our claim is that Rad i stypically close to minimal o verall theories which correctly classify all the e xamples. F or cases where the target theory ,,i sknown, we measure Rad Rad .Ifthis value is less than , then PTR can be said to ha ve done evenbetterthan nding the target theory in the sense that it w as able to correctly classify all training e xamples using less radical revisions than those required to restore the tar get theory .Ifthe value is greater than , then PTR can be said to ha ve over revisedthe theory. Cross validation .Weperform one hundred repetitions of cross validation using nested sets of training e xamples. It should be noted that our actual objecti ve ist ominimize radicality ,and that often there are theories that are less radical than the target theory which also satisfy all training e xamples. Thus, while cross validation gi vessome indication that theory revision is being successfully performed, it is not a primary objecti ve oftheory revision. Theory size .W ecount the number of clauses and literals in the revised theory merely to demonstrate that theories obtained using PTR are comprehensible. Of course, the precise size of the theory obtained by PTR is largely an artifact of the choice of inducti ve component. Complexity .Processing a complete c ycle of exemplars is O nd wherenis the number of edges in the graph and dis the number of e xemplars. Lik ewise repairing an edge is O nd . We will measure the number of cycles and the number of repairs made until con vergence. Recall that the number of cycles until con vergence is in an yevent bounded by max , .W ewill showthat, in practice, the number of cycles is small e venif . ,FELDMAN, SEGRE Utility of Bias .Wewish to sho wthat user provided guidance in choosing initial weights leads to faster and more accurate results. Forcases in which the target theory ,,i sknown, letS be the set of edges of which need to be revised in order to restore the target theory .Dene p e such that for each eS, e e and for each e S,p e p e . That is, each edge which needs to be revised to obtain the intended theory has its initial weight diminished and each edge which need not be revised to obtain the intended theory has its weight increased. Let ,p.Then, for each , Rad log eS e e S p e Rad . Here, we compare the results of cross validation and number of cycles experiments for with their unbiased counterparts i.e., . .. Comparison with other Methods In order to put our results in perspecti ve wecompare them with results obtained by other methods. Quinlan, is the inducti ve component we use in PTR. Thus using is equivalent to learning directly from the examples without using the initial awed domain theory.Bycomparing results obtained using with those obtained using PTR we can gauge the usefulness of the gi ventheory. EITHER Ourston Moone y, inpress uses enumeration of partial proofs in order to nd aminimal set of literals, the repair of which will satisfy all the e xemplars. Repairs are then made using an inducti ve component. EITHER is exponential in the size of the theory.Itcannot handle theories with ne gated internal literals. It also cannot handle theories with multiple roots unless those roots are mutually exclusi ve. KB ANN Towell Sha vlik, translates a symbolic domain theory into a neural net, uses backpropagation to adjust the weights of the net sedges, and then translates back from net form to partially symbolic form. Some of the rules in the theory output by KBANN might be numerical, i.e., not strictly symbolic. RAPTURE Mahoney Mooney, uses a variant of backpropagation to adjust certainty factors in a probabilistic domain theory .Ifnecessary,itcan also add a clause to aroot. Allthe rules produced by RAPTURE are numerical. LikeEITHER, RAPTURE cannot handle ne gated internal literals or multiple roots which are not mutually e xclusive. Observethat, relati ve tothe other methods considered here, PTR is liberal in terms of the theories it can handle, in that lik eKBANN, but unlik eEITHER and RAPTURE it can handle negated literals and non mutually e xclusive multiple roots it is also strict in terms of the theories it yields in that lik eEITHER, but unlik eKBANN and RAPTURE it produces strictly symbolic theories. are other interesting theory revision algorithms, such as RTLS Ginsber g, , for which no comparable data is a vailable. We hav enoted that both KBANN and RAPTURE output numerical rules. Inthe case of KBANN, a numerical rule is one which res if the sum of weights associated with satised antecedents exceeds a threshold. In the case of RAPTURE, the rules are probabilistic rules using certainty f actors along the lines of MYCIN Buchanan Shortlif fe, . One might ask, then, to what extent are results obtained by theory revision algorithms which output numerical rules merely artifacts of the use of such numerical rules? In other w ords, can we separate the effects of using numerical rules from the effects of learning? To makethis more concrete, consider the follo wing simple method for transforming a symbolic domain theory into a probabilistic domain theory and then reclassifying e xamples using the obtained probabilistic theory .Suppose we are gi vensome possibly a wed domain theory . Suppose further that we are not gi venthe classication of e venasingle example. Assign aweight p e t oeach edge of according to the default scheme of Appendix A. Now, using the bottom up subroutine of the updating algorithm, compute uE er for each test e xampleE. Recall that uE er i sameasure of ho wclose to a deri vation ofrfromEthere is, gi venthe weighted dt graph ,p. Now, for some chosen cutoffvalue , such that er lies in the upper n o fthe set of v alues uE er then conclude that is true for otherwise conclude thatis false for . This method, which for the purpose of discussion we call PTR , does not use an ytraining examples at all. Thus if the results of theory revision systems that emplo ynumerical rules can be matched by PTR whichperforms no learning then it is clear that the results are merely artifacts of the use of numerical rules. .. Results on the PROMOTER Theory We rst consider the PR OMOTER theory from molecular biology Murph y Aha, , which is of interest solely because it has been e xtensively studied in the theory revision literature Towell Sha vlik, , thus enabling e xplicit performance comparison with other algorithms. The PROMOTER theory is a a wed theory intended to recognize promoters in DN Anucleotides. The theory recognized none of a set of e xamples as promoters despite the fact that precisely half of them are indeed promoters. Unfortunately ,the PROMOTER theory lik emanyothers used in the theory re vision literature is trivial in that it is very shallo w. Moreover, iti satypical of a wed domains in that it is overly specic but not o verly general. Giventhe shortcomings of the PR OMOTER theory ,we will also test PTR on a synthetically generated theory in which errors ha ve been articially introduced. These synthetic theories are signicantly deeper than those used to test pre vious methods. Moreo ver, the fact that the intended theory is known will enable us to perform experiments in volving radicality and bias. our experiments, we use the default initial weights assigned by the scheme of Appendix A. In ad dition, the clause whose head is the proposition contactis treated as a denition not subject to re vision but only deletion as a whole. ,FELDMAN, SEGRE ... Cr oss validation In Figure we compare the results of cross validation for PR OMOTER. W edistinguish between methods which use numerical rules top plot and those which are purely symbolic bottom plot . The lower plot in Figure highlights the fact that, using the v aluen , PTR achie ves better accurac y,using no tr aining examples,than anyo fthe methods considered here achie ve using training e xamples. In particular ,computing uE er for each example, we obtain that of the highest ranking examples are indeed promoters and, therefore, of the lo west ranking examples are indeed non promoters . Thus, PTR achie . accuracy. In fact, all of the highest ranking examples are promoters and all of the lo west ranking are not promoters. Thus, amore conserv ative version of PTR which classies the, say , highest ranking examples as IN and the lo west ranking as OUT ,would indeed achie ve accuracyoverthe examples for which it ventured a prediction. This merely shows that the original PR OMOTER theory is very accurate provided that it is givenanumerical interpretation. Thus we conclude that the success of RAPTURE and KB ANN for this domain is not a consequence of learning from e xamples but rather an artifact of the use of numerical rules. As for the three methods EITHER, PTR and which yield symbolic rules, we see in the top plot of Figure that, as reported in Ourston Moone y, inpress Towell Shavlik, , the methods which exploit the gi venawed theory do indeed achie ve better results on PR OMOTER than , which does not e xploit the theory .Moreover, asthe size of the training set grows, the performance of PTR is increasingly better than that of EITHER. Finally,w ewish to point out an interesting fact about the example set. There is a set of out of the e xamples which each contain information substantially different than that in the rest of the e xamples. Experiments showthat using ten fold cross validation on the good examples yields . accurac y, while training on all of these examples and testing on the badexamples yields belo accurac y. ... Theory size The size of the output theory is an important measure of the comprehensibility of the output theory.Ideally,the size of the theory should not gro wtoo rapidly as the number of training examples is increased, as lar ger theories are necessarily harder to interpret. This observ ation holds both for the number of clauses in the theory as well as for the a verage number of antecedents in each of those clauses. Theory sizes for the theories produced by PTR are shown in Figure . The most striking aspect of these numbers is that all measures of theory size are relati vely stable with respect to training set size. Naturally,the exact values are to a large degree an artif act of the inducti ve learning component used. In contrast, for EITHER, theory size increases with training set size readers familiar with the PR OMOTER theory should note that the impro vement overEI THER is a consequence of PTR repairing one a wa tatime and using a sharper rele vance criterion. This results in PTR al ways deleting the e xtraneous conformation literal, while EITHER occasionallly fails to do so, particularly as the number of training exmaple increases. Exemplars Misclassied EITHER PTR Exemplars Misclassied RAPTURE KBANN PTR Figure PR OMOTER Error rates using nested training sets for purely symbolic theories top plot and numeric theories bottom plot . Results for EITHER, RAPTURE, and KBANN are tak en from Mahone y Mooney, , while results for and PTR were generated using similar e x perimental procedures. Recall that PTR is a non learning numerical rule system the PTR line is extended horizontally for clarity. ,FELDMAN, SEGRE Training Mean Mean Mean Mean Set Size Clauses in Literals in Revisions to Exemplars to Output Output Convergence Con vergence Original Theory . . . . . Figure PR OMOTER Results. Numbers reported for each training set size are a verage values overone hundred trials ten trials for each of ten example partitions . Ourston, . Forexample, for training examples the output theory size clauses plus literals is , while for training examples, the output theory size is . Unfortunately ,making direct comparisons with KB ANN or RAPTURE is difcult. In the case of KBANN and RAPTURE, which allo wnumerical rules, comparison is impossible gi ven the differences in the underlying representation languages. Nevertheless, it is clear that, as expected, KBANN produces signicantly lar ger theories than PTR. Forexample, using training examples from the PR OMOTER theory ,KBANN produces numerical theories with, on av erage, clauses and literals T owell Sha vlik, . These numbers would gro w substantially if the theory were con verted into strictly symbolic terms. RAPTURE, on the other hand, does not change the theory size, but, lik eKBANN, yields numerical rules Mahone y Mooney, . ... Complexity EITHER is exponential in the size of the theory and the number of training e xamples. F or KBANN, each cycle of the training by backpropagation subroutine is O dn wheredis the size of the network and nis the number of e xemplars , and the number of such cycles typically numbers in the hundreds e venfor shallownets. Likebackpropag ation, the cost of processing an example with PTR is linear in the size of the theory.Incontrast, ho wever, PTR typically con verges after processing only a tin yfraction of the number of e xamples required by standard backpropagation techniques. Figure shows the av erage number of e xemplars not cycles! processed by PTR until con vergence as a function of training set size. The only other cost incurred by PTR is that of revising the theory .Each such revision in O dn . The average number of revisions to con vergence is also shown in Figure . .. Results on Synthetic Theories The character of the PR OMOTER theory mak ei tless than ideal for testing theory re vision algorithms. W ewish to consider theories which i are deeper ,which ii mak esubstantial use of negated internal literals and which iii are o verly general as well as o verly specic. As opposed to shallowtheories which can generally be easily repaired at the leaf le vel, deeper theories often require repairs at internal le vels of the theory .Therefore, a theory revision algorithm which may perform well on shallo wtheories will not necessarily scale up well to larger theories. Moreo ver, as theory size increases, the computational complexity of an algorithm might preclude its application altogether .Wewish to sho wthat PTR scales well to larger ,deeper theories. Since deeper ,propositional, real world theories are scarce, we ha ve generated them synthetically .Asa nadded bonus, we no wknowthe target theory so we can perform controlled experiments on bias and radicality .In Feldman, the aggre gate results of e xperiments performed on a collection of synthetic theories are reported. In order to a void the dubious practice of a veraging results o verdifferent theories and in order to highlight signicant features of aparticular application of PTR, we consider here one synthetic theory typical of those studied in Feldman, . rA,BL T, rC,D L ,, AE,FM Z, ,G,,, , , ,H N ,, , , CI,JZ , ,K Z ,,,, , ,,,, ,,LO , ,,M Y , EN,, ,, EO,, , , FQ,R Q ,,, GS,, , , , HU,VR ,, , , , IWS ,,,, , JX, ,,,, JYT KP,, ,,,,, , Figure The synthetic domain theory used for the experiments of Section . ,FELDMAN, SEGRE The theory is shown is Figure . Observethatincludes four le vels of clauses and has manyneg ated internal nodes. It is thus substantially deeper than theories considered before in testing theory re vision algorithms. We articially introduce, in succession, errors into the theory.The errors are shown in Figure . Foreach of these theories, we use the default initial weights assigned by the scheme of Appendix A. Letibe the theory obtained after introducing the rst iof these errors. In Figure we showthe radicality ,Radi , ofrelative toeach of the awed theories, ifori , , , , , as well as the number of e xamples misclassied by each of those theories. Note that, in general, the number of misclassied examples cannot necessarily be assumed to increase monotonically with the number of errors introduced since introducing an error may either generalize or specialize the theory .For example, the fourth error introduced is undoneb ythe fth error . Nevertheless, it is the case that for this particular set of errors, each successi ve theory is more radical and misclassies a larger number of examples with respect to . To measure radicality and accurac y, wechoose e xemplars which are classied according to.Now for eachi i , , , , , we withhold test examples and train on nested sets of , , , and training e xamples. W echoose ten such partitions and run ten trials for each partition. In Figure , we graph the a verage value ofRadi Radi ,whereis the theory produced by PTR. As can be seen, this value is consistently belo .This indicates that the revisions found clause clause clause , literal clause , clause ,, clause clause , literal clause AE,F clause Added , Deleted ,,, Deleted ,, Added Deleted clause Deleted clause ,H Figure The errors introduced into the synthetic theory in order to produce the awed syn thetic theories i.Note that the fth randomly generated error obviates the fourth. Number of Errors Rad . . . . . Misclassied IN Misclassied OUT Initial Accurac . . . Figure Descripti ve statistics for the awed synthetic theories i i , , , , . .... ExemplarsNormalized Radicality Figure The normalized radicality ,Radi Radi ,for the output theories produced by PTR from i i , , , , . Error bars reect standard error. by PTR are less radical than what is needed to restore the original .Thus by the criterion of success that PTR set for itself ,minimizing r adicality,PTR does better than r estoring.A si sto be expected, the larger the training set the closer this value is to . Also note that as the number of errors introduced increases, the saving in radicality achie vedb yPTR increases as well, since a larger number of opportunities are created for more parsimonious re vision. More precisely,the ,FELDMAN, SEGRE av erage number of re visions made by PTR to ,,,, a element training set are ., ., ., ., and ., respecti vely. An example will sho whow PTR achievesthis. Note from Figure that the errors introduced the additions of the rules ,. In most cases, PTR quickly locates the extraneous clause ,and discovers that deleting it results in the correct classication of all e xemplars in the training set. In fact, this change also results in the correct classication of all test examples as well. The other tw oadded rules do not affect the classication of an ytraining examples, and therefore are not deleted or repaired by PTR. Thus the radicality of the changes made by PTR is lo wer than that required for restoring the original theory .I naminority of cases, PTR rst deletes the clause only then deletes the clause .Since the literal Bis higher in the tree than the literal S,the radicality of these changes is marginally higher that that required to restore the original theory. In Figure , we graph the accurac yofon the test set. As expected, accurac ydegenerates somewhat as the number of errors is increased. Nevertheless, e ,PTR yields theories which generalize accurately. Figure shows the a verage number of e xemplars required for con vergence. As expected, the fewer errors in the theory ,the fewer e xemplars PTR requires for con vergence. Moreo ver, the Exemplars Misclassied Figure Error rates for the output theories produced by PTR from i i , , , , . ExemplarsExemplars to Convergence Figure Number of e xemplars processed until con vergence fori i , , , , . number of e xemplars processed grows less than linearly with the training set size. In fact, in no case was the a verage number of e xamples processed greater than times the training set size. In comparison, backpropagation typically requires hundreds of cycles when it con verges. Next we wish sho wthe effects of positi ve bias, i.e., to sho wthat user provided guidance in the choice of initial weights can impro ve speed of con vergence and accurac yi ncross validation. Foreach of the awed theories ,w ecompare the performance of PTR using def ault initial weights and biased initial weights . InFigure , we sho whow cross validation accuracyincreases when bias is introduced. In Figure , we sho whow the number of e xamples which need to be processed until con vergence decreases when bias is introduced. Returning to the example abo ve,w esee that the introduction of bias allo ws PTR to immediately nd the awed clause to delete it straight a way. Infact, PTR ne ver requires the processing of more than e xemplars to do so. Thus, in this case, the introduction of bias both speeds up the re vision process and results in the consistent choice of the optimal revision. Moreover, ithas also been shown in Feldman, that PTR is rob ust with respect to random perturbations in the initial weights. In particular ,i ntests on thirty different synthetically generated theories, introducing small random perturbations to each edge of a dt graph before training resulted in less than of test examples being classied differently than when training wasperformed using the original initial weights. ,FELDMAN, SEGRE Exemplars Misclassied bias Figure Error rates for the output theories produced by PTR from i i , , , , , using favorably biased initial weights. .. Summary Repairing internal literals and clauses is as natural for PTR as repairing lea ves. Moreo ver, PTR converges rapidly .Asaresult, PTR scales up to deep theories without dif culty.Evenfor very badly awed theories, PTR quickly nds repairs which correctly classify all kno wn exemplars. These repairs are typically lessradical than restoring the original theory and are close enough to the original theory to generalize accurately to test examples. Moreover, although PTR is rob ust with respect to initial weights, user guidance in choosing these weights can signicantly impro ve both speed of con vergence and cross validation accurac y. . Conclusions In this paper ,w ehav epresented our approach, called PTR, to the theory revision problem for propositional theories. Our approach uses probabilities associated with domain theory elements to numerically track the owo fproof through the theory ,allowing us to efciently locate and repair awed elements of the theory .Weprove that PTR con verges to a theory which correctly classies all e xamples, and sho wexperimentally that PTR is fast and accurate e venfor deep theories. There are se veral ways in which PTR can be extended. First order theories .The updating method at the core of PTR assumes that pro vided exemplars unambiguously assign truth values to each observable proposition. In rst order theory revision the truth of an observ able predicate typically depends on variable assignments. ExemplarsExemplars to Convergence bias bias Figure Number of e xemplars processed until con vergence using f avorably biased initial weights. Thus, in order to apply PTR to rst order theory revision it is necessary to determine optimal variable assignments on the basis of which probabilities can be updated. One method for doing so is discussed in Feldman, . Inductive bias .PTR uses bias to locate a wed elements of a theory .Another type of bias can be used to determine which revision to mak e. For example, it might be known that a particular clause might be missing a literal in its body b ut should under no circumstances be deleted, or that only certain types of literals can be added to the clause but not others. Likewise, it might be known that a particular literal is replaceable b ut not deletable, etc. It has been shown Feldman et al., that by modifying the inducti ve component of PTR to account for such bias, both convergence speed and cross validation accurac yare substantially impro ved. Noisy exemplars.Wehav eassumed that it is only the domain theory which is in need of revision, but that the e xemplars are all correctly classied. Often this is not the case. Thus, it is necessary to modify PTR to tak einto account the possibility of reclassifying e xemplars on the basis of the theory rather than vice v ersa. The PTR algorithm Section suggests that misclassed e xemplars can sometimes be detected before processing. Briey,the idea is that an example which allows multiple proofs of some root is almost certainly IN for that root re gardless of the classication we ha ve been told. Thus, ifuE er i shigh, then Eis probably IN re gardless of what we are told analogously ,ifuE er i slow.Amodied version of PTR based on this observation has already been successfully implemented Koppel et al., . In conclusion, we belie ve the PTR system marks an important contrib ution to the domain theory revision problem. More specically ,the primary inno vations reported here are ,FELDMAN, SEGRE By assigning bias in the form of the probability that an element of a domain theory is awed, we can clearly dene the objecti ve ofatheory revision algorithm. By reformulating a domain theory as a weighted dt graph, we can numerically trace the owo faproof or refutation through the various elements of a domain theory. Proof owcan be used to efciently update the probability that an element is a wed on the basis of an e xemplar. By updating probabilities on the basis of e xemplars, we can efciently locate a wed elements of a theory. By using proof o w, wecan determine precisely on the basis of which e xemplars to re vise aawed element of the theory. Acknowledgments The authors wish to thank Hillel Walters of Bar Ilan Uni versity for his signicant contributions to the content of this paper .The authors also wish to thank the JAIR re viewers for their exceptionally prompt and helpful remarks. Support for this research w as provided in part by the Ofce of Na valResearch through grant J AMS, RF and the Air F orce Ofce of Scientic Research under contract C AMS . Appendix A Assigning Initial Weights In this appendix we gi ve one method for assigning initial weights to the elements of a domain theory.The method is based on the topology of the domain theory and assumes that no user provided information re garding the lik elihood of errors is a vailable. If such information is available, then it can be used to o verride the values determined by this method. The method works as follo ws. First, for each edge einwe dene the semantic impact ofe, e . e i smeant to signify the proportion of examples whose classication is directly affected by the presence of ein. One straightforward way of formally dening e i sthe following. Let Ibe the pair ,Isuch that Iassigns all root and ne gation edges the weight and all other edges the .LetI e b eidentical to Iexcept that eand all its ancestor edges ha ve been assigned the weight . LetEbe the example such that for each observable proposition Pin,E P i sthe apriori probability that Pis true in a randomly selected e xample. particular ,for the typical case in which observable propositions are Boolean and all e xample are equiprobable, E P . Ecan be thought of as the averageexample. Then, if no edge of has more than one parent edge, we formally dene the semantic signicance, e , of an edge einas follows e uI e E er ueI e E er . That is, e isthe difference of the o wofEthrough the root r,with and without the edge e. Note that e can be efciently computed by rst computing uI E e for every edgeein a single bottom up tra versal of,and then computing e for every edgeein a single top do wn traversal of,a sfollows For a root edge r, r E r . For all other edges, e f e E e uI E e ,wheref e i sthe parent edge of e. If some edge in has more than one parent edge then we dene e for an edge by using this method of computation, where in place of f e we use fmax f e . Finally,for a set,R,ofedges inG,w edene R eR e . Now, having computed e w ecompute the initial weight assignment to e,p e , in the following way .Choose some large C. we ha ve dened an example as a , truth assignment to each observable proposition, we have already noted in Footnote that we can just as easily process examples which assign to observ ables anyvalue in the interval , . the number of examples reclassied as a result of edge deletion is, in f act, superaddi tive,afact not reected by this last denition. hav enot tested ho wt ochooseCoptimally .Inthe experiments reported in Section , the v al ueC . ,FELDMAN, SEGRE p e C e C e . Now, reg ardless of ho w e i sdened, the virtue of this method of computing p e from e is the following for such an initial assignment, p,if two sets of edg es,pareo fequal total strength then as r evision sets the yare ofequal radicality. This means that all re vision sets of equal strength are a priori equally probable. Foraset of edges of ,dene S e eS e S Then the abo ve can be formalized as follows Theorem IfRandSare sets of elements of such that R S then it follows that Rad R Rad S . Proof of Theorem LetRandSbe sets of edges such that R S . Recall that Rad S log e e S e p e e . Then exp Rad S exp Rad R e e S e p e e e R e p e e e p e e R e S e e C e R e S e C R S . It follows immediately that Rad R Rad S . Asimple consequence which illustrates the intuiti veness of this theorem is the follo wing suppose we ha ve two possible revisions of ,each of which entails deleting a simple literal. Suppose further that one literal, ,i sdeep in the tree and the other ,,i shigher in the tree so that . Then, using def ault initial weights as assigned abo ve,the radicality of times as great as the radicality of deleting . Appendix B Updated Weights as Conditional Probabilities In this appendix we pro ve that under certain limiting conditions, the algorithm computes the conditional probabilities of the edges gi venthe classication of the example. Our rst assumption for the purpose of this appendix is that the correct dt graph is known to be a subgraph of the gi vendt graph.This means that for e very nodenin,w n and, consequently ,for every edgeein,p e w e . Apair,wwith this property is said to bedeletion only . Although we informally dened probabilities directly on edges, for the purposes of this appendix we formally dene our probability function on the space of all subgraphs of .That is, the elementary e vents are of the form where.Then the probability that e is simply p e . We say that a deletion only ,weighted dt graph ,pisedge independent if for any , p ep e e e . Finally,wesay thatistree likeif no edge ehas more than one parent edge. Observethat anydt graph which is connected and tree lik ehas only one root. We will prove results for deletion only ,edge independent, tree lik eweighted dt graphs. First we introduce some more terminology .Recall that e very node in is labeled by one of the literals in and that by denition, this literal is true if not all of its children in are true. Recall also that the dt graph represents the sets of N ANDequations, .Aliterallin forces its parent in to be true, gi venthe set of equations and the exampleE,iflappears in and is false gi venandE. This follo ws from the denition of N AND. Thuswe say that an edgeeinisusedbyEinifeand Ene. Ifeis not used by Einwe write N E e . Note that N E er ifand only if E . Note that, gi venthe probabilities of the elementary e vents ,the probability p N E e that the edge eis not used by Ein the target domain theory is simply p N E e .Where there is no ambiguity we will use NE e torefer toN E e . Theorem If,wis a deletion only ,edge independent, tree lik eweighted dt graph, then for e very edgeein,uE e p NE e . Proof of Theorem W euse induction on the distance of nefrom its deepest descendant. If neis an observable proposition Ptheneis used by Ein precisely if eandPis false in E.Thus the probability that eis not used by E inis e P uE e . results sho wthat our algorithm yields reasonable approximations of the conditional prob abilities e venwhen these conditions do not hold. ,FELDMAN, SEGRE Ifneis not a observable proposition then Eneprecisely if all its children in are true in ,that is, if all its children are unused in .But then edge independence p NE e p e p Ene induction hypothesis p e schildren e p NE s p e schildren e uE s uE e . This justies the bottom up part of the algorithm. In order to justify the top down part we need one more denition. Letp e E, E b ethe probability that egiven,pand the e xemplar E, E .Then p e E, E p e, E E p E E . Noww ehav e Theorem If,wis deletion only ,edge independent and tree like, then for ev ery edgeein,pnew e p e E, E . In order to pro ve the theorem we need se veral lemmas Lemma For every example Eand every edgeein p NE e p NE e ,NE f e p NE e NE f e p NE f e . This follows immediately from the fact that if an edge, e,i sused, then its parent edge, f e , is not used. Lemma For every example Eand every edgeein, p NE E NE f e ,E, E p NE e NE f e . This lemma states that NE e andE, E are conditionally independent gi venNE f e Pearl, . That is, once NE f e is kno wn,E, E adds no information re garding NE e . This is immediate from the f act thatp E, E NE f e can be expressed in terms of the probabilities associated with non descendants of f e , whilep NE e can be e xpressed in terms of the probabilities associated with descendants of r e . Lemma For every example Eand every edgeein, vE e p NE e E, E . Proof of Lemma The proof is by induction on the depth of the edge, e.For the root edge, er,wehav e vE er E p E E, E p NE er E, E . Assuming that the theorem is known for f e , we sho wthat it holds for eas follows denition of v e e vE f e uE f e Theorem p NE e vE f e p NE f e induction hypothesis p NE e E, E p NE e p NE f e Lemma p NE e E, E p NE e NE f e Lemma p NE e E, E p NE e NE f e ,E, E Bayes rule p NE e ,NE f e E, E Lemma p NE e E, E NE e E, E . Letebe short for the e vente .Then we ha ve Lemma For every example Eand every edgeein, p e p e,NE e p e NE e p NE e . This lemma, which is analogous to Lemma , follows from the fact that if eis deleted, then eis unused. Lemma For every example Eand every edgeein, p e NE e ,E, E p e NE e . This lemma, which is analogous to Lemma , states that eandE, E are conditionally independent gi venNE e . Thatis, onceNE e i sknown,E, E adds no information regarding the probability of e.This is immediate from the fact that p E, E NE e can be expressed in terms of the probabilities of edges other than e. We now hav eall the pieces to pro ve Theorem . Proof of Theorem denition of p new e e vE e uE e Theorem p e vE e p NE e ,FELDMAN, SEGRE Lemma p NE e E, E p e p NE e Lemma p NE e E, E p e NE e Lemma p NE e E, E p e NE e ,E, E Bayes rule p e,NE e E, E Lemma p e E, E e E, E . Appendix C Proof of Con vergence We hav eseen in Section that PTR al ways terminates. We wish to sho wthat when it does, all exemplars are classied correctly .Wewill prove this for domain theories which satisfy certain conditions which will be made precise belo w. The general idea of the proof is the following by denition, the algorithm terminates either when all e xemplars are correctly classied or when all edges have weight . Thus, it is only necessary to sho wthat it is not possible to reach a state in which all edges ha ve weight and some e xemplar is misclassied. We will prove that such a state fails to possess the property of consistency which is assumed to hold for the initial weighted dt graph ,and which is preserved at all times by the algorithm. Denition Consistency The weighted dt graph ,pisconsistent with exemplarE, E if, for every rootriin,either i i E E ri ,or ii i E E ri . Recall that an edge eis dened to be e veni fi ti so fe vendepth along e very path from a root and odd if is of odd depth along e very path from a root. Adomain theory is said to be unambiguous if ev ery edge is either odd or e ven. Notethat negation free domain theories are unambiguous. We will prove our main theorem for unambiguous, single root domain theories. Recall that the only operations performed by PTR are updating weights, deleting ev enedges, deleting odd edges, adding asubtree beneath an e venedge, and adding asubtree beneath an odd edge. We shall showthat each of these operations is performed in such a way as to preserv e consistenc y. Theorem Consistency If ,pis a single rooted, unambiguous weighted dt graph which is consistent with the e xemplarE, E and ,pis obtained from via a single operation performed by PTR, then is also a single rooted, unambiguous dt graph which is consistent with E. Before we pro ve this theorem we sho wthat it easily implies con vergence of the algorithm. Theorem Convergence Giv enasingle rooted, unambiguous weighted dt graphand a set of e xemplarssuch that is consistent with e very exemplar in ,PTR terminates and produces a dt graph which classies e very exemplar in correctly. Proof of Theorem I fPTR terminates prior to each edge being assigned the weight , then by denition, all e xemplars are correctly classied. Suppose then that PTR produces a weighted dt graph ,psuch that p e every e.Assume, contrary to the theorem, that some e xemplarE, E is misclassied by for the root r.Without loss of generality ,assume that E, E is an IN e xemplar ofr.Sincep e every edge, this means that u E er . But this is impossible since the consistenc yofimplies that uK E er and thus it follows from Theorem that for an yobtainable form ,FELDMAN, SEGRE ,u E er .This contradicts the assumption that Eis misclassied by . Let us no wturn to the proof of Theorem . We will use the following four lemmas, slight variants of which are pro vedi n Feldman, . Lemma If ,pis obtained from ,pvia updating of weights, then for e very edgeesuch that p e ,wehav p e . Lemma Let ,pbe a weighted dt graph such that u E er and let ,p.Then if for e very edgeeinsuch that p e ,w ehav e p e ,i tfollows that u E er . Lemma Let ,pbe a weighted dt graph such that u E er and let ,p.The, if for e very edgeein,itholds that either i p e p e , or ii depth e isodd andu E e ,or iii depth e isevenandu E e thenu E e . An analogous lemma holds where the roles of reversed. Lemma Ifeis evenedge in,thenue E er u E er ue E r . Inaddition, if eis an odd edge in ,thenue E er u E er ue E r . We can nowprove consistency Theorem . We assume, without loss of generality ,that E, E is an IN e xemplar of the root rand prove that for each one of the v eoperations updating and four revision operators of PTR, that if is obtained by that operation from and u E er ,thenu E er . Proof of Theorem The proof consists of v eseparate cases, each corresponding to one of the operations performed by PTR. Case is obtained from via updating of weights. By Lemma , for e very edgeein,i p e then p e .But then by Lemma , if u E er E er . Case is obtained from via deletion of an e venedge,e. From Lemma i , we ha veue E er u E er . Case is obtained from via deletion of an odd edge, e. The edge eis deleted only if it is not needed for an yexemplar.Suppose that, contrary to the theorem, there is an IN e xemplarE, E such that u E er butu E er . Then that in the updating algorithm we dened vE eri E ifi E . The somewhat annoying presence of necessary for the proof of Lemma . R E, E ,e, ue E er ue E er ue E er u E er ue E er . But then eis needed for E,contradicting the fact that eis not needed for an y exemplar. Case is obtained from via appending a subtree beneath an e venedge,e. Ifp e ,then the result is immediate from Lemma . Otherwise, let fbe the root edge of the subtree awhich is appended to ,beneathe.Then f e. Suppose that, contrary to the theorem, there is some IN e xemplarE, E such thatu E er b utu E er . Then by Lemma ii , ue E er u e E er u E er . But then, R E, E ,e, ue E er ue E er ue E er . Thuseis destructi ve forEin.But then, by the construction of a,u E f . Thus,u E e .The result follows immediately from Lemma . Case is obtained from via appending a subtree to beneath the odd edge, e. Suppose that, contrary to the theorem, some IN e xemplarE, E ,u E er butu E er . Sincee e,itfollows that R E, E ,e, ue E er ue E er ue E er ue E er . Now, using Lemma ii on both numerator and denominator ,w ehav e ue E er ue E er u E er u E er . Thus,eis needed for Ein.Now,letfbe the root edge of the appended subtree, a.Then, by the construction of a,i tfollows thatu E f and, therefore u E e .The result is immediate from Lemma . ,FELDMAN, SEGRE This completes the proof of the theorem. It is instructi ve tonote whythe proof of Theorem fails if is not restricted to unambiguous single rooted dt graphs. In case of the proof of Theorem , we use the f act that if an edge eis destructi ve for an exemplarE, E then the revision algorithm used to construct the subgraph, a,appended to ewill be such that u E f . However, this fact does not hold in the case where eis simultaneously needed and destructi ve.This can occur if eis a descendant of tw oroots where Eis IN for one root and OUT for another root. It can also occur when one path from eto the root ris of evenlength and another path is of odd length. Appendix D Guide to Notation Adomain theory consisting of a set of clauses of the form Ci HiBi. Ci Aclause label. Hi Aclause head it consists of a single positi ve literal. Bi Aclause body it consists of a conjunction of positi ve orneg ative literals. E An example it is a set of observable propositions. i E T he classication of the e xampleEfor theith root according to domain theory. i E T he correct classication of the example Efor theith root. E, E An exemplar,aclassied example. The set of N ANDclauses equi valent to. The dt graph representation of . ne The node to which the edge eleads. neThe node from which the edge ecomes. p e T he weight of the edge e i trepresents the probability that the edge e needs to be deleted or that edges need to be appended to the node ne. ,p Aweighted dt graph. e Same asbutwith the weight of the edge eequal to . e Same asbutwith the edge edeleted. uE e T he ow ofproof from the example Ethrough the edge e. vE e T he adjusted o wo fproof through etaking into account the correct classication of the example E. Ri E, E ,e, The extent ranging from to t owhich the edge ein the weighted dt graphcontributes to the correct classication of the e xampleEfor the ith root. If Riis less more than , then eis harmful helpful if Ri eis irrelevant. The revision threshold if p e theneis revised. The weight assigned to a re vised edge and to the root of an appended component. The revision threshold increment. The revised edge weight increment. Rad T he radicality of the changes required to in order to obtain a re vised theory. ,FELDMAN, SEGRE References Buchanan, B. Shortliffe, E.H. . Rule Based Expert Systems The MYCIN Experiments of the Stanfor dHeuristic Pr ogramming Project .Reading, MA Addison Wesle y. Feldman, R. . Probabilistic Revision of Logical Domain Theories .Ithaca, NY Ph.D. Thesis, Department of Computer Science, Cornell Uni versity. Feldman, R., Koppel, M. Segre, A.M. August . The Relevance of Bias in the Re vision of Approximate Domain Theories. Working Notes of the IJCAI Workshop on Mac hine Learning and Knowledg eAcquisition Common Issues, Contrasting Methods, and Inte grated Approaches , . Ginsberg, A. July . Theory Reduction, Theory Revision, and Retranslation. Proceedings of the National Conference on Articial Intelligence , . Koppel, M., Feldman, R. Segre, A.M. December . Theory Revision Using Noisy Exemplars. Proceedings of the Tenth Israeli Symposium on Articial Intellig ence and Computer Vision, . Mahoney, J. Mooney, R. . Combining Connectionist and Symbolic Learning to Rene Certainty Factor Rule Bases. Connection Science ,, . Murphy, P.M. Aha, D.W . .UCI Repository of Machine Learning Databases Mac hine readable data r epository .Irvine, CA Department of Information and Computer Science, University of California at Irvine. Ourston, D. August . Using Explanation Based and Empirical Methods in Theory Revision.Austin, TX Ph.D. Thesis, Uni versity of Texas at Austin. Ourston, D. Moone y, R. in press . Theory Renement Combining Analytical and Empirical Methods. Articial Intelligence . Pazzani, M. Brunk, C. June . Detecting and Correcting Errors in Rule Based Expert Systems An Integration of Empirical and Explanation Based Learning. Knowledg eAcquisition, , . Pearl, J. . Probabilistic Reasoning in Intelligent Systems .San Mateo, CA Mor gan Kaufmann. Quinlan, J.R. . Induction of Decision Trees. Machine Learning , , . To well, G.G. Sha vlik, J.W. October . Extracting Rened Rules From Kno wledge Based Neural Networks. Machine Learning , , . Wilkins, D.C. July . Knowledge Base Renement Using Apprenticeship Learning Techniques. Proceedings of the National Conference on Articial Intelligence , . Wogulis, J. Pazzani, M.J. August . AMethodology for Evaluating Theory Re vision Systems Results with Audre yII.Proceedings of the Thirteenth International J oint Confer ence on Articial Intelligence , . "
